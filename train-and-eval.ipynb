{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Library imports and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\pyhealth\\trainer.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1ae065445b0>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyhealth.data import Visit\n",
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.medcode import InnerMap\n",
    "from pyhealth.metrics.binary import binary_metrics_fn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "from model.bitenet import BiteNet\n",
    "from model.baseline import RNN, BRNN, RETAIN, Deepr\n",
    "import pickle\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "BATCH_SIZE = 32\n",
    "KS = list(range(5, 31, 5))\n",
    "SEQ_LENS = list(range(6, 17, 2))\n",
    "N_TRIALS=10\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(RANDOM_SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T11:40:36.906203Z",
     "end_time": "2023-05-08T11:40:46.350013Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "with open(\"mimic3_dataset.pkl\", \"rb\") as dataset_file:\n",
    "    mimic3_ds = pickle.load(dataset_file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T11:40:46.352012Z",
     "end_time": "2023-05-08T11:40:47.791013Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fgrnO7KkWDBY",
    "ExecuteTime": {
     "start_time": "2023-05-08T11:40:48.922345Z",
     "end_time": "2023-05-08T11:40:48.969185Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the tasks\n",
    "\n",
    "DIAGNOSES_KEY = \"conditions\"\n",
    "PROCEDURES_KEY = \"procedures\"\n",
    "INTERVAL_DAYS_KEY = \"days_since_first_visit\"\n",
    "\n",
    "icd9cm = InnerMap.load(\"ICD9CM\")\n",
    "\n",
    "def flatten(l: List):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def patient_level_readmission_prediction(patient, time_window: int = 30, max_length_visits: int = None):\n",
    "    \"\"\"\n",
    "    patient is a <pyhealth.data.Patient> object\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    sorted_visits = sorted(patient, key=lambda visit: visit.encounter_time)\n",
    "\n",
    "    # Clip the patient visits to the most recent max_length_visits + 1 if max_length_visits is not None\n",
    "    if max_length_visits is not None:\n",
    "        n_visits = len(sorted_visits)\n",
    "        if n_visits > max_length_visits + 1:\n",
    "            sorted_visits = sorted_visits[n_visits - (max_length_visits + 1):]\n",
    "\n",
    "    feature_visits: List[Visit] = sorted_visits[:-1]\n",
    "    last_visit: Visit = sorted_visits[-1]\n",
    "    second_to_last_visit: Visit = feature_visits[-1]\n",
    "    first_visit: Visit = feature_visits[0]\n",
    "\n",
    "    # step 1 a: define readmission label\n",
    "    time_diff = (last_visit.encounter_time - second_to_last_visit.encounter_time).days\n",
    "    readmission_label = 1 if time_diff <= time_window else 0\n",
    "\n",
    "    # step 1 b: define diagnosis prediction label\n",
    "    diagnosis_label = list(set([icd9cm.get_ancestors(code)[1] for code in last_visit.get_code_list(\"DIAGNOSES_ICD\")]))\n",
    "\n",
    "    # step 2: obtain features\n",
    "    visits_diagnoses = []\n",
    "    visits_procedures = []\n",
    "    visits_intervals = []\n",
    "    for idx, visit in enumerate(feature_visits):\n",
    "        diagnoses = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "        procedures = visit.get_code_list(table=\"PROCEDURES_ICD\")\n",
    "        time_diff_from_first_visit = (visit.encounter_time - first_visit.encounter_time).days\n",
    "\n",
    "        # Exclude visits that are missing either diagnoses or procedures.\n",
    "        # BiteNet can handle missing procedures, but other PyHealth models like RNN\n",
    "        # require all features have a length greater than 0.\n",
    "        if len(diagnoses) == 0:\n",
    "            continue\n",
    "\n",
    "        visits_diagnoses.append(diagnoses)\n",
    "        visits_procedures.append(procedures)\n",
    "        visits_intervals.append([str(time_diff_from_first_visit)])\n",
    "\n",
    "    unique_diagnoses = list(set(flatten(visits_diagnoses)))\n",
    "\n",
    "    # step 3: exclusion criteria\n",
    "    if len(unique_diagnoses) == 0:\n",
    "        return []\n",
    "\n",
    "    # step 4: assemble the sample\n",
    "    samples.append(\n",
    "        {\n",
    "            \"patient_id\": patient.patient_id,\n",
    "            \"visit_id\": visit.visit_id,\n",
    "            \"diagnoses\": visits_diagnoses,\n",
    "            \"procedures\": visits_procedures,\n",
    "            \"intervals\": visits_intervals,\n",
    "            \"readmission_label\": readmission_label,\n",
    "            \"diagnosis_label\": diagnosis_label\n",
    "        }\n",
    "    )\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "RESULTS_FILE = \"./results/baseline_comparison.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T11:40:50.055185Z",
     "end_time": "2023-05-08T11:40:50.073183Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def train_and_inference(model, train_loader, val_loader, test_loader, lr=0.0005, monitor=\"pr_auc\", optim = torch.optim.Adam):\n",
    "    trainer = Trainer(model=model, device=device)\n",
    "    trainer.train(\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        epochs=10,\n",
    "        monitor=monitor,\n",
    "        optimizer_class=optim,\n",
    "        optimizer_params = {\"lr\" : lr},\n",
    "        load_best_model_at_last=False\n",
    "    )\n",
    "\n",
    "    return trainer.inference(test_loader)\n",
    "\n",
    "def precision_at_k(y_true: np.ndarray, y_prob: np.ndarray):\n",
    "\n",
    "    y_pred: np.ndarray = (y_prob > 0.5).astype(int)\n",
    "    desc_idx: np.ndarray = np.flip(np.argsort(y_prob, axis=-1), axis=-1)\n",
    "\n",
    "    y_true = np.take_along_axis(y_true, desc_idx, axis=-1).astype(int)\n",
    "    y_pred = np.take_along_axis(y_pred, desc_idx, axis=-1)\n",
    "\n",
    "    num_cat_labels = y_true.sum(axis=-1)\n",
    "\n",
    "    precisions: List[float] = []\n",
    "    for k in KS:\n",
    "        y_true_k = y_true[:, :k]\n",
    "        y_pred_k = y_pred[:, :k]\n",
    "\n",
    "        num_correct_preds_k = np.logical_and(y_true_k, y_pred_k).astype(int).sum(axis=-1)\n",
    "        ks = np.repeat(k, num_correct_preds_k.shape[0])\n",
    "        denominator = np.minimum(num_cat_labels, ks).astype(float)\n",
    "        precision_k = num_correct_preds_k.astype(float) / denominator\n",
    "        precisions.append(precision_k.mean())\n",
    "\n",
    "    precisions: Dict[str, float] = {\n",
    "        f\"precision@{k}\": p for k, p in zip(KS, precisions)\n",
    "    }\n",
    "    return precisions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T11:40:52.179187Z",
     "end_time": "2023-05-08T11:40:52.211182Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T11:40:52.815160Z",
     "end_time": "2023-05-08T11:40:52.832159Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_record_metrics(model_readm, model_diag, df, row_fields, train_loader, val_loader, test_loader, lr=0.0005, readm_optim=torch.optim.Adam, diag_optim=torch.optim.Adam):\n",
    "    y_true, y_prob, _ = train_and_inference(\n",
    "        model_readm,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        lr=lr,\n",
    "        optim=readm_optim\n",
    "    )\n",
    "    binary_metrics = binary_metrics_fn(y_true, y_prob, metrics=[\"pr_auc\"])\n",
    "\n",
    "    y_true, y_prob, _ = train_and_inference(\n",
    "        model_diag,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        lr=lr,\n",
    "        monitor=\"pr_auc_samples\",\n",
    "        optim=diag_optim\n",
    "    )\n",
    "    precisions = precision_at_k(y_true, y_prob)\n",
    "\n",
    "    row = binary_metrics | precisions | row_fields\n",
    "    row = {\n",
    "        k: [v] for k, v in row.items()\n",
    "    }\n",
    "\n",
    "    df = pd.concat([df, pd.DataFrame.from_dict(row)], ignore_index=True)\n",
    "\n",
    "    # Save df for checkpoint\n",
    "    df.to_csv(RESULTS_FILE, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# %%capture\n",
    "#\n",
    "# # Compare BiteNet performance to baselines\n",
    "#\n",
    "# metrics_df = pd.DataFrame(columns=['model_name', 'feature_set', 'seq_len', 'trial', 'pr_auc'] + [f\"precision@{k}\" for k in KS])\n",
    "#\n",
    "# for seq_len in SEQ_LENS:\n",
    "#\n",
    "#     dataset = mimic3_ds.set_task(\n",
    "#         task_fn=lambda p: patient_level_readmission_prediction(p, max_length_visits=seq_len)\n",
    "#     )\n",
    "#\n",
    "#     for trial in range(1, N_TRIALS+1):\n",
    "#\n",
    "#         train, val, test = split_by_patient(dataset, [0.8, 0.1, 0.1])\n",
    "#\n",
    "#         train_loader = get_dataloader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#         val_loader = get_dataloader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "#         test_loader = get_dataloader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "#\n",
    "#         #################### BITENET ####################\n",
    "#         metrics_df = train_and_record_metrics(\n",
    "#             model_readm=BiteNet(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "#                 label_key = \"readmission_label\",\n",
    "#                 mode = \"binary\",\n",
    "#             ).to(device),\n",
    "#             model_diag=BiteNet(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "#                 label_key = \"diagnosis_label\",\n",
    "#                 mode = \"multilabel\",\n",
    "#             ).to(device),\n",
    "#             df=metrics_df,\n",
    "#             row_fields={\n",
    "#                 \"model_name\": \"bitenet\",\n",
    "#                 \"feature_set\": \"dxtx\",\n",
    "#                 \"seq_len\": seq_len,\n",
    "#                 \"trial\": trial\n",
    "#             },\n",
    "#             train_loader=train_loader,\n",
    "#             val_loader=val_loader,\n",
    "#             test_loader=test_loader,\n",
    "#         )\n",
    "#\n",
    "#         metrics_df = train_and_record_metrics(\n",
    "#             model_readm=BiteNet(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "#                 label_key = \"readmission_label\",\n",
    "#                 mode = \"binary\",\n",
    "#             ).to(device),\n",
    "#             model_diag=BiteNet(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "#                 label_key = \"diagnosis_label\",\n",
    "#                 mode = \"multilabel\",\n",
    "#             ).to(device),\n",
    "#             df=metrics_df,\n",
    "#             row_fields={\n",
    "#                 \"model_name\": \"bitenet\",\n",
    "#                 \"feature_set\": \"dx\",\n",
    "#                 \"seq_len\": seq_len,\n",
    "#                 \"trial\": trial\n",
    "#             },\n",
    "#             train_loader=train_loader,\n",
    "#             val_loader=val_loader,\n",
    "#             test_loader=test_loader\n",
    "#         )\n",
    "#\n",
    "#         #################### RNN ####################\n",
    "#         metrics_df = train_and_record_metrics(\n",
    "#                 model_readm=RNN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "#                 label_key = \"readmission_label\",\n",
    "#                 mode = \"binary\",\n",
    "#             ).to(device),\n",
    "#             model_diag=RNN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "#                 label_key = \"diagnosis_label\",\n",
    "#                 mode = \"multilabel\",\n",
    "#             ).to(device),\n",
    "#             df=metrics_df,\n",
    "#             row_fields={\n",
    "#                 \"model_name\": \"rnn\",\n",
    "#                 \"feature_set\": \"dxtx\",\n",
    "#                 \"seq_len\": seq_len,\n",
    "#                 \"trial\": trial\n",
    "#             },\n",
    "#             train_loader=train_loader,\n",
    "#             val_loader=val_loader,\n",
    "#             test_loader=test_loader\n",
    "#         )\n",
    "#\n",
    "#         metrics_df = train_and_record_metrics(\n",
    "#                 model_readm=RNN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\"],\n",
    "#                 label_key = \"readmission_label\",\n",
    "#                 mode = \"binary\",\n",
    "#             ).to(device),\n",
    "#             model_diag=RNN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\"],\n",
    "#                 label_key = \"diagnosis_label\",\n",
    "#                 mode = \"multilabel\",\n",
    "#             ).to(device),\n",
    "#             df=metrics_df,\n",
    "#             row_fields={\n",
    "#                 \"model_name\": \"rnn\",\n",
    "#                 \"feature_set\": \"dx\",\n",
    "#                 \"seq_len\": seq_len,\n",
    "#                 \"trial\": trial\n",
    "#             },\n",
    "#             train_loader=train_loader,\n",
    "#             val_loader=val_loader,\n",
    "#             test_loader=test_loader,\n",
    "#         )\n",
    "#\n",
    "#         #################### BRNN ####################\n",
    "#         metrics_df = train_and_record_metrics(\n",
    "#                 model_readm=BRNN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "#                 label_key = \"readmission_label\",\n",
    "#                 mode = \"binary\",\n",
    "#                 bidirectional=True\n",
    "#             ).to(device),\n",
    "#             model_diag=RNN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "#                 label_key = \"diagnosis_label\",\n",
    "#                 mode = \"multilabel\",\n",
    "#                 bidirectional=True\n",
    "#             ).to(device),\n",
    "#             df=metrics_df,\n",
    "#             row_fields={\n",
    "#                 \"model_name\": \"brnn\",\n",
    "#                 \"feature_set\": \"dxtx\",\n",
    "#                 \"seq_len\": seq_len,\n",
    "#                 \"trial\": trial\n",
    "#             },\n",
    "#             train_loader=train_loader,\n",
    "#             val_loader=val_loader,\n",
    "#             test_loader=test_loader\n",
    "#         )\n",
    "#\n",
    "#         metrics_df = train_and_record_metrics(\n",
    "#                 model_readm=BRNN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\"],\n",
    "#                 label_key = \"readmission_label\",\n",
    "#                 mode = \"binary\",\n",
    "#                 bidirectional=True\n",
    "#             ).to(device),\n",
    "#             model_diag=RNN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\"],\n",
    "#                 label_key = \"diagnosis_label\",\n",
    "#                 mode = \"multilabel\",\n",
    "#                 bidirectional=True\n",
    "#             ).to(device),\n",
    "#             df=metrics_df,\n",
    "#             row_fields={\n",
    "#                 \"model_name\": \"brnn\",\n",
    "#                 \"feature_set\": \"dx\",\n",
    "#                 \"seq_len\": seq_len,\n",
    "#                 \"trial\": trial\n",
    "#             },\n",
    "#             train_loader=train_loader,\n",
    "#             val_loader=val_loader,\n",
    "#             test_loader=test_loader\n",
    "#         )\n",
    "#\n",
    "#         #################### RETAIN ####################\n",
    "#         metrics_df = train_and_record_metrics(\n",
    "#                 model_readm=RETAIN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "#                 label_key = \"readmission_label\",\n",
    "#                 mode = \"binary\"\n",
    "#             ).to(device),\n",
    "#             model_diag=RETAIN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "#                 label_key = \"diagnosis_label\",\n",
    "#                 mode = \"multilabel\"\n",
    "#             ).to(device),\n",
    "#             df=metrics_df,\n",
    "#             row_fields={\n",
    "#                 \"model_name\": \"retain\",\n",
    "#                 \"feature_set\": \"dxtx\",\n",
    "#                 \"seq_len\": seq_len,\n",
    "#                 \"trial\": trial\n",
    "#             },\n",
    "#             train_loader=train_loader,\n",
    "#             val_loader=val_loader,\n",
    "#             test_loader=test_loader,\n",
    "#         )\n",
    "#\n",
    "#         metrics_df = train_and_record_metrics(\n",
    "#                 model_readm=RETAIN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\"],\n",
    "#                 label_key = \"readmission_label\",\n",
    "#                 mode = \"binary\"\n",
    "#             ).to(device),\n",
    "#             model_diag=RETAIN(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\"],\n",
    "#                 label_key = \"diagnosis_label\",\n",
    "#                 mode = \"multilabel\"\n",
    "#             ).to(device),\n",
    "#             df=metrics_df,\n",
    "#             row_fields={\n",
    "#                 \"model_name\": \"retain\",\n",
    "#                 \"feature_set\": \"dx\",\n",
    "#                 \"seq_len\": seq_len,\n",
    "#                 \"trial\": trial\n",
    "#             },\n",
    "#             train_loader=train_loader,\n",
    "#             val_loader=val_loader,\n",
    "#             test_loader=test_loader\n",
    "#         )\n",
    "#\n",
    "#         #################### Deepr ####################\n",
    "#         metrics_df = train_and_record_metrics(\n",
    "#                 model_readm=Deepr(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "#                 label_key = \"readmission_label\",\n",
    "#                 mode = \"binary\"\n",
    "#             ).to(device),\n",
    "#             model_diag=Deepr(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "#                 label_key = \"diagnosis_label\",\n",
    "#                 mode = \"multilabel\"\n",
    "#             ).to(device),\n",
    "#             df=metrics_df,\n",
    "#             row_fields={\n",
    "#                 \"model_name\": \"deepr\",\n",
    "#                 \"feature_set\": \"dxtx\",\n",
    "#                 \"seq_len\": seq_len,\n",
    "#                 \"trial\": trial\n",
    "#             },\n",
    "#             train_loader=train_loader,\n",
    "#             val_loader=val_loader,\n",
    "#             test_loader=test_loader\n",
    "#         )\n",
    "#\n",
    "#         metrics_df = train_and_record_metrics(\n",
    "#                 model_readm=Deepr(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\"],\n",
    "#                 label_key = \"readmission_label\",\n",
    "#                 mode = \"binary\"\n",
    "#             ).to(device),\n",
    "#             model_diag=Deepr(\n",
    "#                 dataset = dataset,\n",
    "#                 feature_keys = [\"diagnoses\"],\n",
    "#                 label_key = \"diagnosis_label\",\n",
    "#                 mode = \"multilabel\"\n",
    "#             ).to(device),\n",
    "#             df=metrics_df,\n",
    "#             row_fields={\n",
    "#                 \"model_name\": \"deepr\",\n",
    "#                 \"feature_set\": \"dx\",\n",
    "#                 \"seq_len\": seq_len,\n",
    "#                 \"trial\": trial\n",
    "#             },\n",
    "#             train_loader=train_loader,\n",
    "#             val_loader=val_loader,\n",
    "#             test_loader=test_loader\n",
    "#         )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T11:43:41.904182Z",
     "end_time": "2023-05-08T11:43:41.955181Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3432, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1359, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1726, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000001AE12F0F4F0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5321\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2646\n",
      "roc_auc: 0.5592\n",
      "f1: 0.0000\n",
      "loss: 0.5263\n",
      "New best pr_auc score (0.2646) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.5143\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.2722\n",
      "roc_auc: 0.5567\n",
      "f1: 0.0000\n",
      "loss: 0.5198\n",
      "New best pr_auc score (0.2722) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4773\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3265\n",
      "roc_auc: 0.5798\n",
      "f1: 0.1413\n",
      "loss: 0.5118\n",
      "New best pr_auc score (0.3265) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4519\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3279\n",
      "roc_auc: 0.5701\n",
      "f1: 0.1474\n",
      "loss: 0.5302\n",
      "New best pr_auc score (0.3279) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.4259\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3197\n",
      "roc_auc: 0.5621\n",
      "f1: 0.1619\n",
      "loss: 0.5420\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.3984\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3264\n",
      "roc_auc: 0.5690\n",
      "f1: 0.2335\n",
      "loss: 0.5803\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.3695\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3326\n",
      "roc_auc: 0.5663\n",
      "f1: 0.1818\n",
      "loss: 0.6260\n",
      "New best pr_auc score (0.3326) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.3462\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3323\n",
      "roc_auc: 0.5595\n",
      "f1: 0.3224\n",
      "loss: 0.6532\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.3095\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3292\n",
      "roc_auc: 0.5566\n",
      "f1: 0.2688\n",
      "loss: 0.7216\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.2939\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3332\n",
      "roc_auc: 0.5579\n",
      "f1: 0.1921\n",
      "loss: 0.7861\n",
      "New best pr_auc score (0.3332) at epoch-9, step-1880\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3432, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1359, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1726, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000001AE12F0F4F0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1877\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3337\n",
      "loss: 0.1184\n",
      "New best pr_auc_samples score (0.3337) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.1102\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3418\n",
      "loss: 0.1031\n",
      "New best pr_auc_samples score (0.3418) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0970\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3436\n",
      "loss: 0.0925\n",
      "New best pr_auc_samples score (0.3436) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0896\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.3564\n",
      "loss: 0.0869\n",
      "New best pr_auc_samples score (0.3564) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0855\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.3676\n",
      "loss: 0.0839\n",
      "New best pr_auc_samples score (0.3676) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0833\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.3781\n",
      "loss: 0.0828\n",
      "New best pr_auc_samples score (0.3781) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0820\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.3939\n",
      "loss: 0.0816\n",
      "New best pr_auc_samples score (0.3939) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0808\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4036\n",
      "loss: 0.0808\n",
      "New best pr_auc_samples score (0.4036) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0799\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4149\n",
      "loss: 0.0801\n",
      "New best pr_auc_samples score (0.4149) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0790\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4161\n",
      "loss: 0.0797\n",
      "New best pr_auc_samples score (0.4161) at epoch-9, step-1880\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3432, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1726, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000001AE12F0F4F0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5322\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2513\n",
      "roc_auc: 0.5338\n",
      "f1: 0.0000\n",
      "loss: 0.5336\n",
      "New best pr_auc score (0.2513) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.5124\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3343\n",
      "roc_auc: 0.5836\n",
      "f1: 0.1136\n",
      "loss: 0.5141\n",
      "New best pr_auc score (0.3343) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4750\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3468\n",
      "roc_auc: 0.5943\n",
      "f1: 0.1405\n",
      "loss: 0.5097\n",
      "New best pr_auc score (0.3468) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4589\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3410\n",
      "roc_auc: 0.5832\n",
      "f1: 0.1809\n",
      "loss: 0.5205\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.4383\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3445\n",
      "roc_auc: 0.5901\n",
      "f1: 0.2130\n",
      "loss: 0.5318\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.4062\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3408\n",
      "roc_auc: 0.5774\n",
      "f1: 0.1818\n",
      "loss: 0.5835\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.3759\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3492\n",
      "roc_auc: 0.5922\n",
      "f1: 0.2115\n",
      "loss: 0.6257\n",
      "New best pr_auc score (0.3492) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.3533\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3560\n",
      "roc_auc: 0.5933\n",
      "f1: 0.2521\n",
      "loss: 0.6549\n",
      "New best pr_auc score (0.3560) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.3341\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3274\n",
      "roc_auc: 0.5860\n",
      "f1: 0.2890\n",
      "loss: 0.7164\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.3148\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3510\n",
      "roc_auc: 0.5828\n",
      "f1: 0.2634\n",
      "loss: 0.7320\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3432, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1726, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000001AE12F0F4F0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1883\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3379\n",
      "loss: 0.1163\n",
      "New best pr_auc_samples score (0.3379) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.1063\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3432\n",
      "loss: 0.0981\n",
      "New best pr_auc_samples score (0.3432) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0927\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3462\n",
      "loss: 0.0888\n",
      "New best pr_auc_samples score (0.3462) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0870\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.3575\n",
      "loss: 0.0847\n",
      "New best pr_auc_samples score (0.3575) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0840\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.3635\n",
      "loss: 0.0831\n",
      "New best pr_auc_samples score (0.3635) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0825\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.3819\n",
      "loss: 0.0818\n",
      "New best pr_auc_samples score (0.3819) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0813\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.3997\n",
      "loss: 0.0810\n",
      "New best pr_auc_samples score (0.3997) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0805\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4062\n",
      "loss: 0.0806\n",
      "New best pr_auc_samples score (0.4062) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0795\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4118\n",
      "loss: 0.0799\n",
      "New best pr_auc_samples score (0.4118) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0789\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4175\n",
      "loss: 0.0798\n",
      "New best pr_auc_samples score (0.4175) at epoch-9, step-1880\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3432, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1359, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1726, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000001AE12F0F4F0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5280\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2381\n",
      "roc_auc: 0.5194\n",
      "f1: 0.0000\n",
      "loss: 0.5317\n",
      "New best pr_auc score (0.2381) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.5216\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.2513\n",
      "roc_auc: 0.5454\n",
      "f1: 0.0000\n",
      "loss: 0.5352\n",
      "New best pr_auc score (0.2513) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4905\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3242\n",
      "roc_auc: 0.5550\n",
      "f1: 0.1405\n",
      "loss: 0.5169\n",
      "New best pr_auc score (0.3242) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4667\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3443\n",
      "roc_auc: 0.5844\n",
      "f1: 0.1333\n",
      "loss: 0.5144\n",
      "New best pr_auc score (0.3443) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.4301\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3343\n",
      "roc_auc: 0.5781\n",
      "f1: 0.1592\n",
      "loss: 0.5553\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.3985\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3413\n",
      "roc_auc: 0.5966\n",
      "f1: 0.2510\n",
      "loss: 0.5705\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.3589\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3435\n",
      "roc_auc: 0.5953\n",
      "f1: 0.1972\n",
      "loss: 0.6167\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 17\u001B[0m\n\u001B[0;32m     13\u001B[0m n_layers_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_name\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeature_set\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_layers\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpr_auc\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprecision@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m KS])\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m n_layers \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m9\u001B[39m):\n\u001B[1;32m---> 17\u001B[0m     n_layers_df \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_record_metrics\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_readm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBiteNet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfeature_keys\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdiagnoses\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprocedures\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mintervals\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlabel_key\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreadmission_label\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbinary\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_mask_enc_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_layers\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_diag\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBiteNet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfeature_keys\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdiagnoses\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mprocedures\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mintervals\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlabel_key\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdiagnosis_label\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     29\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmultilabel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     30\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn_mask_enc_layers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_layers\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     32\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_layers_df\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     33\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrow_fields\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mbitenet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     35\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfeature_set\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdxtx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mn_layers\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     43\u001B[0m     n_layers_df \u001B[38;5;241m=\u001B[39m train_and_record_metrics(\n\u001B[0;32m     44\u001B[0m         model_readm\u001B[38;5;241m=\u001B[39mBiteNet(\n\u001B[0;32m     45\u001B[0m             dataset \u001B[38;5;241m=\u001B[39m dataset,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     66\u001B[0m         test_loader\u001B[38;5;241m=\u001B[39mtest_loader\n\u001B[0;32m     67\u001B[0m     )\n\u001B[0;32m     69\u001B[0m \u001B[38;5;66;03m# Evaluate BiteNet performance as number of attention heads in MaskEnc layers changes\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m, in \u001B[0;36mtrain_and_record_metrics\u001B[1;34m(model_readm, model_diag, df, row_fields, train_loader, val_loader, test_loader, lr, readm_optim, diag_optim)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_and_record_metrics\u001B[39m(model_readm, model_diag, df, row_fields, train_loader, val_loader, test_loader, lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0005\u001B[39m, readm_optim\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam, diag_optim\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam):\n\u001B[1;32m----> 2\u001B[0m     y_true, y_prob, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_inference\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_readm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreadm_optim\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     binary_metrics \u001B[38;5;241m=\u001B[39m binary_metrics_fn(y_true, y_prob, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpr_auc\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m     12\u001B[0m     y_true, y_prob, _ \u001B[38;5;241m=\u001B[39m train_and_inference(\n\u001B[0;32m     13\u001B[0m         model_diag,\n\u001B[0;32m     14\u001B[0m         train_loader,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     19\u001B[0m         optim\u001B[38;5;241m=\u001B[39mdiag_optim\n\u001B[0;32m     20\u001B[0m     )\n",
      "Cell \u001B[1;32mIn[5], line 4\u001B[0m, in \u001B[0;36mtrain_and_inference\u001B[1;34m(model, train_loader, val_loader, test_loader, lr, monitor, optim)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain_and_inference\u001B[39m(model, train_loader, val_loader, test_loader, lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0005\u001B[39m, monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpr_auc\u001B[39m\u001B[38;5;124m\"\u001B[39m, optim \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam):\n\u001B[0;32m      3\u001B[0m     trainer \u001B[38;5;241m=\u001B[39m Trainer(model\u001B[38;5;241m=\u001B[39mmodel, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mval_dataloader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmonitor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptimizer_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptimizer_params\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[43mload_best_model_at_last\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[0;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m trainer\u001B[38;5;241m.\u001B[39minference(test_loader)\n",
      "File \u001B[1;32m~\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\pyhealth\\trainer.py:199\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, train_dataloader, val_dataloader, test_dataloader, epochs, optimizer_class, optimizer_params, weight_decay, max_grad_norm, monitor, monitor_criterion, load_best_model_at_last)\u001B[0m\n\u001B[0;32m    197\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(data_iterator)\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# forward\u001B[39;00m\n\u001B[1;32m--> 199\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdata)\n\u001B[0;32m    200\u001B[0m loss \u001B[38;5;241m=\u001B[39m output[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    201\u001B[0m \u001B[38;5;66;03m# backward\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\PycharmProjects\\CS598-DL4H-Final-Project\\model\\bitenet.py:393\u001B[0m, in \u001B[0;36mBiteNet.forward\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    390\u001B[0m pad_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeat_tokenizers[feature_key]\u001B[38;5;241m.\u001B[39mvocabulary(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m<pad>\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    392\u001B[0m \u001B[38;5;66;03m# Create the mask\u001B[39;00m\n\u001B[1;32m--> 393\u001B[0m mask \u001B[38;5;241m=\u001B[39m (\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mpad_idx\u001B[49m)\u001B[38;5;241m.\u001B[39mlong()\n\u001B[0;32m    394\u001B[0m embeds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings[feature_key](x)\n\u001B[0;32m    396\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m feature_key \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mintervals\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "dataset = mimic3_ds.set_task(\n",
    "    task_fn=lambda p: patient_level_readmission_prediction(p, max_length_visits=8)\n",
    ")\n",
    "\n",
    "train, val, test = split_by_patient(dataset, [0.8, 0.1, 0.1])\n",
    "\n",
    "train_loader = get_dataloader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = get_dataloader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = get_dataloader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Evaluate BiteNet performance as number of MaskEnc layers changes\n",
    "RESULTS_FILE = \"./results/changing_n_layers.csv\"\n",
    "n_layers_df = pd.DataFrame(columns=['model_name', 'feature_set', 'n_layers', 'pr_auc'] + [f\"precision@{k}\" for k in KS])\n",
    "\n",
    "for n_layers in range(9):\n",
    "\n",
    "    n_layers_df = train_and_record_metrics(\n",
    "        model_readm=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\",\n",
    "            n_mask_enc_layers=n_layers\n",
    "        ).to(device),\n",
    "        model_diag=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\",\n",
    "            n_mask_enc_layers=n_layers\n",
    "        ).to(device),\n",
    "        df=n_layers_df,\n",
    "        row_fields={\n",
    "            \"model_name\": \"bitenet\",\n",
    "            \"feature_set\": \"dxtx\",\n",
    "            \"n_layers\": n_layers,\n",
    "        },\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "    )\n",
    "\n",
    "    n_layers_df = train_and_record_metrics(\n",
    "        model_readm=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\",\n",
    "            n_mask_enc_layers=n_layers\n",
    "        ).to(device),\n",
    "        model_diag=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\",\n",
    "            n_mask_enc_layers=n_layers\n",
    "        ).to(device),\n",
    "        df=n_layers_df,\n",
    "        row_fields={\n",
    "            \"model_name\": \"bitenet\",\n",
    "            \"feature_set\": \"dx\",\n",
    "            \"n_layers\": n_layers,\n",
    "        },\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader\n",
    "    )\n",
    "\n",
    "# Evaluate BiteNet performance as number of attention heads in MaskEnc layers changes\n",
    "RESULTS_FILE = \"./results/changing_n_heads.csv\"\n",
    "n_heads_df = pd.DataFrame(columns=['model_name', 'feature_set', 'seq_len', 'n_heads', 'trial', 'pr_auc'] + [f\"precision@{k}\" for k in KS])\n",
    "\n",
    "for n_heads in [4, 8, 16, 32]:\n",
    "\n",
    "    n_heads_df = train_and_record_metrics(\n",
    "        model_readm=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\",\n",
    "            n_heads=n_heads\n",
    "        ).to(device),\n",
    "        model_diag=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\",\n",
    "            n_heads=n_heads\n",
    "        ).to(device),\n",
    "        df=n_heads_df,\n",
    "        row_fields={\n",
    "            \"model_name\": \"bitenet\",\n",
    "            \"feature_set\": \"dxtx\",\n",
    "            \"n_heads\": n_heads,\n",
    "        },\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader,\n",
    "    )\n",
    "\n",
    "    n_heads_df = train_and_record_metrics(\n",
    "        model_readm=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\",\n",
    "            n_heads=n_heads\n",
    "        ).to(device),\n",
    "        model_diag=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\",\n",
    "            n_heads=n_heads\n",
    "        ).to(device),\n",
    "        df=n_heads_df,\n",
    "        row_fields={\n",
    "            \"model_name\": \"bitenet\",\n",
    "            \"feature_set\": \"dx\",\n",
    "            \"n_heads\": n_heads,\n",
    "        },\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader\n",
    "    )\n",
    "\n",
    "\n",
    "# Ablations\n",
    "\n",
    "RESULTS_FILE = \"./results/ablations.csv\"\n",
    "ablations_df = pd.DataFrame(columns=['model_name', 'feature_set', 'ablation', 'pr_auc'] + [f\"precision@{k}\" for k in KS])\n",
    "\n",
    "#################### BITENET DXTX ####################\n",
    "ablations_df = train_and_record_metrics(\n",
    "    model_readm=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        use_attn_pooling=False\n",
    "    ).to(device),\n",
    "    model_diag=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        use_attn_pooling=False\n",
    "    ).to(device),\n",
    "    df=ablations_df,\n",
    "    row_fields={\n",
    "        \"model_name\": \"bitenet\",\n",
    "        \"feature_set\": \"dxtx\",\n",
    "        \"ablation\": 'Attention',\n",
    "    },\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "ablations_df = train_and_record_metrics(\n",
    "    model_readm=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        use_dir_masks=False\n",
    "    ).to(device),\n",
    "    model_diag=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        use_dir_masks=False\n",
    "    ).to(device),\n",
    "    df=ablations_df,\n",
    "    row_fields={\n",
    "        \"model_name\": \"bitenet\",\n",
    "        \"feature_set\": \"dxtx\",\n",
    "        \"ablation\": 'DireMask',\n",
    "    },\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "ablations_df = train_and_record_metrics(\n",
    "    model_readm=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "    ).to(device),\n",
    "    model_diag=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "    ).to(device),\n",
    "    df=ablations_df,\n",
    "    row_fields={\n",
    "        \"model_name\": \"bitenet\",\n",
    "        \"feature_set\": \"dxtx\",\n",
    "        \"ablation\": 'Interval',\n",
    "    },\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "ablations_df = train_and_record_metrics(\n",
    "    model_readm=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "    ).to(device),\n",
    "    model_diag=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "    ).to(device),\n",
    "    df=ablations_df,\n",
    "    row_fields={\n",
    "        \"model_name\": \"bitenet\",\n",
    "        \"feature_set\": \"dxtx\",\n",
    "        \"ablation\": 'BiteNet',\n",
    "    },\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#################### BITENET DX ####################\n",
    "\n",
    "ablations_df = train_and_record_metrics(\n",
    "    model_readm=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        use_attn_pooling=False\n",
    "    ).to(device),\n",
    "    model_diag=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        use_attn_pooling=False\n",
    "    ).to(device),\n",
    "    df=ablations_df,\n",
    "    row_fields={\n",
    "        \"model_name\": \"bitenet\",\n",
    "        \"feature_set\": \"dx\",\n",
    "        \"ablation\": 'Attention',\n",
    "    },\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "ablations_df = train_and_record_metrics(\n",
    "    model_readm=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        use_dir_masks=False\n",
    "    ).to(device),\n",
    "    model_diag=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        use_dir_masks=False\n",
    "    ).to(device),\n",
    "    df=ablations_df,\n",
    "    row_fields={\n",
    "        \"model_name\": \"bitenet\",\n",
    "        \"feature_set\": \"dx\",\n",
    "        \"ablation\": 'DireMask',\n",
    "    },\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "ablations_df = train_and_record_metrics(\n",
    "    model_readm=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "    ).to(device),\n",
    "    model_diag=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "    ).to(device),\n",
    "    df=ablations_df,\n",
    "    row_fields={\n",
    "        \"model_name\": \"bitenet\",\n",
    "        \"feature_set\": \"dx\",\n",
    "        \"ablation\": 'Interval',\n",
    "    },\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")\n",
    "\n",
    "ablations_df = train_and_record_metrics(\n",
    "    model_readm=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "    ).to(device),\n",
    "    model_diag=BiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "    ).to(device),\n",
    "    df=ablations_df,\n",
    "    row_fields={\n",
    "        \"model_name\": \"bitenet\",\n",
    "        \"feature_set\": \"dx\",\n",
    "        \"ablation\": 'BiteNet',\n",
    "    },\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T11:41:07.453185Z",
     "end_time": "2023-05-08T11:43:25.426133Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
