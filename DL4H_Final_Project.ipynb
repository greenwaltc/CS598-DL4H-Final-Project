{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Google Cloud authentication and data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=mA4KTl8iW7ExFCgiSIGV20WPRGNlqP&access_type=offline&code_challenge=xuy5gjuf9GwNlmobryR0GgFOlCXznHfpqWf2kC4oOvM&code_challenge_method=S256\n",
      "\n",
      "\n",
      "You are now logged in as [camerongreenwalt@gmail.com].\n",
      "Your current project is [dl4h-final-project-383605].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n",
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=VhRb04TAkTK1P44NMUbqMETl8LbKmJ&access_type=offline&code_challenge=kI_eC118DoXyOitFkk97dyveJMvPc3wJ6vZzl6sMbeE&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [C:\\Users\\camer\\AppData\\Roaming\\gcloud\\application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"dl4h-final-project-383605\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth login\n",
    "! gcloud auth application-default login\n",
    "! gcloud config set project dl4h-final-project-383605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pCHvVcifGcdr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (2.86.0)\n",
      "Requirement already satisfied: google-cloud-storage in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (2.17.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (2.11.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-cloud-storage) (2.28.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-cloud-storage) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-cloud-storage) (2.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.59.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (4.22.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade google-api-python-client google-cloud-storage\n",
    "from google.cloud import storage\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Replace these values with your project and bucket as needed\n",
    "project_id = \"dl4h-final-project-383605\"\n",
    "mimic3_bucket = \"mimiciii-1.4.physionet.org\"\n",
    "\n",
    "storage_client = storage.Client(project=project_id)\n",
    "bucket = storage_client.bucket(mimic3_bucket)\n",
    "data_folder = \"data\"\n",
    "for blob in bucket.list_blobs():\n",
    "    if \"CHARTEVENTS\" in blob.name:\n",
    "        continue\n",
    "\n",
    "    gz_path = f\"{data_folder}/{blob.name}\"\n",
    "    blob.download_to_filename(gz_path)\n",
    "\n",
    "    with gzip.open(gz_path, 'rb') as f_in:\n",
    "        with open(gz_path.replace(\".gz\", \"\"), 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    os.remove(gz_path)\n",
    "\n",
    "# # Extract all the files\n",
    "# ! gunzip {data_folder}/*.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall torch torchvision torchaudio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Library imports and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:31:37.476202Z",
     "end_time": "2023-04-29T20:31:41.073203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyhealth in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: pandas>=1.3.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyhealth) (2.0.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyhealth) (2.0.0+cu118)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyhealth) (1.2.2)\n",
      "Requirement already satisfied: networkx>=2.6.3 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyhealth) (3.0)\n",
      "Requirement already satisfied: rdkit>=2022.03.4 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyhealth) (2022.9.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyhealth) (4.65.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pandas>=1.3.2->pyhealth) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas>=1.3.2->pyhealth) (1.24.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pandas>=1.3.2->pyhealth) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pandas>=1.3.2->pyhealth) (2.8.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from rdkit>=2022.03.4->pyhealth) (9.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from scikit-learn>=0.24.2->pyhealth) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from scikit-learn>=0.24.2->pyhealth) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from scikit-learn>=0.24.2->pyhealth) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.8.0->pyhealth) (4.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.8.0->pyhealth) (3.1.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.8.0->pyhealth) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.8.0->pyhealth) (1.11.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from tqdm->pyhealth) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.2->pyhealth) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from jinja2->torch>=1.8.0->pyhealth) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sympy->torch>=1.8.0->pyhealth) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\pyhealth\\trainer.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "! pip install pyhealth\n",
    "from pyhealth.datasets import MIMIC3Dataset, SampleDataset\n",
    "from pyhealth.data import Patient, Visit, Event\n",
    "from pyhealth.tasks import readmission_prediction_mimic3_fn\n",
    "import pandas as pd\n",
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "from pyhealth.models import BaseModel, RNN, RETAIN, Deepr\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.metrics.binary import binary_metrics_fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Dict, Optional\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set this to the directory with all MIMIC-3 dataset files\n",
    "data_root = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-VgeMdJDYYK",
    "outputId": "9cb9c08a-9003-4836-a3b2-a23e7cd45b55",
    "ExecuteTime": {
     "start_time": "2023-04-29T20:31:42.061193Z",
     "end_time": "2023-04-29T20:31:59.021637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "mimic3_ds = MIMIC3Dataset(\n",
    "        root=data_root,\n",
    "        tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\", \"PRESCRIPTIONS\"],\n",
    "        dev=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "HQdeU1TLU6m_",
    "outputId": "590623d6-2917-4155-bf0a-5d75a3979c25",
    "ExecuteTime": {
     "start_time": "2023-04-29T20:32:07.784224Z",
     "end_time": "2023-04-29T20:32:08.087241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 46520\n",
      "\t- Number of visits: 58976\n",
      "\t- Number of visits per patient: 1.2678\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0711\n",
      "\t- Number of events per visit in PRESCRIPTIONS: 70.4013\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 46520\\n\\t- Number of visits: 58976\\n\\t- Number of visits per patient: 1.2678\\n\\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0711\\n\\t- Number of events per visit in PRESCRIPTIONS: 70.4013\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataset statistics\n",
    "\n",
    "mimic3_ds.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Find all diagnoses codes\n",
    "# Remove diagnoses codes with fewer than 5 occurences in the dataset\n",
    "\n",
    "all_diagnosis_codes = []\n",
    "for patient_id, patient in mimic3_ds.patients.items():\n",
    "  for i in range(len(patient)):\n",
    "    visit: Visit = patient[i]\n",
    "    conditions = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "    all_diagnosis_codes.extend(conditions)\n",
    "\n",
    "codes = pd.Series(all_diagnosis_codes)\n",
    "diag_code_counts = codes.value_counts()\n",
    "filtered_diag_codes = diag_code_counts[diag_code_counts > 4].index.values\n",
    "num_unique_diag_codes = len(filtered_diag_codes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:32:22.562176Z",
     "end_time": "2023-04-29T20:32:22.976175Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46520/46520 [01:16<00:00, 610.38it/s]\n"
     ]
    }
   ],
   "source": [
    "MIN_NUM_VISITS_PER_PATIENT = 2\n",
    "\n",
    "filtered_patients = {}\n",
    "for patient_id, patient in tqdm(mimic3_ds.patients.items()):\n",
    "\n",
    "    filtered_patient: Patient = Patient(\n",
    "        patient_id=patient.patient_id,\n",
    "        birth_datetime=patient.birth_datetime,\n",
    "        death_datetime=patient.death_datetime,\n",
    "        gender=patient.gender,\n",
    "        ethnicity=patient.ethnicity\n",
    "    )\n",
    "\n",
    "    for i_visit, visit in enumerate(patient):\n",
    "        filtered_visit: Visit = Visit(\n",
    "            visit_id=visit.visit_id,\n",
    "            patient_id=visit.patient_id,\n",
    "            encounter_time=visit.encounter_time,\n",
    "            discharge_time=visit.discharge_time,\n",
    "            discharge_status=visit.discharge_status\n",
    "        )\n",
    "\n",
    "        diagnoses_codes = visit.get_code_list(\"DIAGNOSES_ICD\")\n",
    "        procedures_codes = visit.get_code_list(\"PROCEDURES_ICD\")\n",
    "        prescriptions_codes = visit.get_code_list(\"PRESCRIPTIONS\")\n",
    "\n",
    "        if len(diagnoses_codes) > 0:\n",
    "            diagnosis_events = visit.event_list_dict[\"DIAGNOSES_ICD\"]\n",
    "            for i_event in range(len(diagnosis_events) - 1, -1, -1):\n",
    "                event: Event = diagnosis_events[i_event]\n",
    "                if event.code not in filtered_diag_codes:\n",
    "                    diagnosis_events.pop(i_event) # Remove the diagnosis code with fewer than the cutoff occurrences\n",
    "\n",
    "            if len(diagnosis_events) == 0: continue # Don't include visits with no diagnoses\n",
    "\n",
    "            filtered_visit.set_event_list(\"DIAGNOSES_ICD\", diagnosis_events)\n",
    "        else:\n",
    "            continue # Don't include visits with no diagnoses\n",
    "\n",
    "        if len(procedures_codes) > 0:\n",
    "           filtered_visit.set_event_list(\"PROCEDURES_ICD\", visit.event_list_dict[\"PROCEDURES_ICD\"])\n",
    "\n",
    "        if len(prescriptions_codes) > 0:\n",
    "            filtered_visit.set_event_list(\"PRESCRIPTIONS\", visit.event_list_dict[\"PRESCRIPTIONS\"])\n",
    "\n",
    "        filtered_patient.add_visit(filtered_visit)\n",
    "\n",
    "    if len(filtered_patient.visits) >= MIN_NUM_VISITS_PER_PATIENT:\n",
    "        filtered_patients[patient_id] = filtered_patient\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:32:23.605194Z",
     "end_time": "2023-04-29T20:33:39.840762Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 7496\n",
      "\t- Number of visits: 19905\n",
      "\t- Number of visits per patient: 2.6554\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0975\n",
      "\t- Number of events per visit in PRESCRIPTIONS: 82.0433\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 7496\\n\\t- Number of visits: 19905\\n\\t- Number of visits per patient: 2.6554\\n\\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0975\\n\\t- Number of events per visit in PRESCRIPTIONS: 82.0433\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic3_ds.patients = filtered_patients\n",
    "mimic3_ds.stat()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:33:44.990216Z",
     "end_time": "2023-04-29T20:33:45.999239Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "fgrnO7KkWDBY",
    "ExecuteTime": {
     "start_time": "2023-04-29T20:45:31.532216Z",
     "end_time": "2023-04-29T20:45:31.551217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the tasks\n",
    "\n",
    "DIAGNOSES_KEY = \"conditions\"\n",
    "PROCEDURES_KEY = \"procedures\"\n",
    "INTERVAL_DAYS_KEY = \"days_since_first_visit\"\n",
    "\n",
    "def flatten(l: List):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def patient_level_readmission_prediction(patient, time_window: int = 30, max_length_visits: int = None):\n",
    "    \"\"\"\n",
    "    patient is a <pyhealth.data.Patient> object\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    # # if the patient only has one visit, we drop it\n",
    "    # if len(patient) <= 1:\n",
    "    #     return []\n",
    "\n",
    "    sorted_visits = sorted(patient, key=lambda visit: visit.encounter_time)\n",
    "\n",
    "    # Clip the patient visits to the most recent max_length_visits + 1 if max_length_visits is not None\n",
    "    if max_length_visits is not None:\n",
    "        n_visits = len(sorted_visits)\n",
    "        if n_visits > max_length_visits + 1:\n",
    "            sorted_visits = sorted_visits[n_visits - (max_length_visits + 1):]\n",
    "\n",
    "    feature_visits: List[Visit] = sorted_visits[:-1]\n",
    "    last_visit: Visit = sorted_visits[-1]\n",
    "    second_to_last_visit: Visit = feature_visits[-1]\n",
    "    first_visit: Visit = feature_visits[0]\n",
    "\n",
    "    # step 1: define label\n",
    "    time_diff = (last_visit.encounter_time - second_to_last_visit.encounter_time).days\n",
    "    readmission_label = 1 if time_diff <= time_window else 0\n",
    "\n",
    "    # step 2: obtain features\n",
    "    visits_diagnoses = []\n",
    "    visits_procedures = []\n",
    "    visits_intervals = []\n",
    "    for idx, visit in enumerate(feature_visits):\n",
    "        diagnoses = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "        procedures = visit.get_code_list(table=\"PROCEDURES_ICD\")\n",
    "        time_diff_from_first_visit = (visit.encounter_time - first_visit.encounter_time).days\n",
    "\n",
    "        # Exclude visits that are missing either diagnoses or procedures.\n",
    "        # BiteNet can handle missing procedures, but other PyHealth models like RNN\n",
    "        # require all features have a length greater than 0.\n",
    "        if len(diagnoses) * len(procedures) == 0:\n",
    "            continue\n",
    "\n",
    "        visits_diagnoses.append(diagnoses)\n",
    "        visits_procedures.append(procedures)\n",
    "        visits_intervals.append([str(time_diff_from_first_visit)])\n",
    "\n",
    "    unique_diagnoses = list(set(flatten(visits_diagnoses)))\n",
    "\n",
    "    # step 3: exclusion criteria\n",
    "    if len(unique_diagnoses) == 0:\n",
    "        return []\n",
    "\n",
    "    # step 4: assemble the sample\n",
    "    samples.append(\n",
    "        {\n",
    "            \"patient_id\": patient.patient_id,\n",
    "            \"visit_id\": visit.visit_id,\n",
    "            \"diagnoses\": visits_diagnoses,\n",
    "            \"procedures\": visits_procedures,\n",
    "            \"intervals\": visits_intervals,\n",
    "            \"label\": readmission_label,\n",
    "        }\n",
    "    )\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:45:32.015450Z",
     "end_time": "2023-04-29T20:45:32.077448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define the models\n",
    "VERY_BIG_NUMBER = 1e30\n",
    "VERY_SMALL_NUMBER = 1e-30\n",
    "VERY_POSITIVE_NUMBER = VERY_BIG_NUMBER\n",
    "VERY_NEGATIVE_NUMBER = -VERY_BIG_NUMBER\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "class MaskDirection(Enum):\n",
    "    FORWARD = 'forward'\n",
    "    BACKWARD = 'backward'\n",
    "    DIAGONAL = 'diagonal'\n",
    "    NONE = 'none'\n",
    "\n",
    "class MaskedLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape: int):\n",
    "        super().__init__()\n",
    "        self.scale = nn.parameter.Parameter(torch.ones(normalized_shape, dtype=torch.float32, device=device))\n",
    "        self.bias = nn.parameter.Parameter(torch.zeros(normalized_shape, dtype=torch.float32, device=device))\n",
    "        self.normalized_shape = normalized_shape\n",
    "\n",
    "    def forward(self, x: torch.Tensor, eps=1e-5):\n",
    "        mean = torch.mean(x, dim=-1, keepdim=True)\n",
    "        variance = torch.mean(torch.square(x - mean), dim=-1, keepdim=True)\n",
    "        norm_x = (x - mean) * torch.rsqrt(variance + eps)\n",
    "        return norm_x * self.scale + self.bias\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, keep: int):\n",
    "        fixed_shape = list(x.size())\n",
    "        start = len(fixed_shape) - keep\n",
    "        left = reduce(mul, [fixed_shape[i] or x.shape[i] for i in range(start)])\n",
    "        out_shape = [left] + [fixed_shape[i] or x.shape[i] for i in range(start, len(fixed_shape))]\n",
    "        return torch.reshape(x, out_shape)\n",
    "\n",
    "\n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, v: torch.Tensor, ref: torch.Tensor, embedding_dim):\n",
    "        batch_size = ref.shape[0]\n",
    "        n_visits = ref.shape[1]\n",
    "        out = torch.reshape(v, [batch_size, n_visits, embedding_dim])\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, embedding_size: int):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_size, embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, mask = inputs\n",
    "        x = self.fc(x)\n",
    "        x[mask] = VERY_NEGATIVE_NUMBER\n",
    "        soft = F.softmax(x, dim=1)\n",
    "        x[mask] = 0\n",
    "        attn_output = torch.sum(soft * x, 1)\n",
    "        return attn_output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, direction, dropout, num_units, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.direction = direction\n",
    "        self.num_units = num_units\n",
    "        self.q_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.k_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.v_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # because of self-attention, queries and keys is equal to inputs\n",
    "        input_tensor, input_mask = inputs\n",
    "        queries = input_tensor\n",
    "        keys = input_tensor\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.q_linear(queries)  # (N, L_q, d)\n",
    "        K = self.k_linear(keys)  # (N, L_k, d)\n",
    "        V = self.v_linear(keys)  # (N, L_k, d)\n",
    "\n",
    "        # print('Q shape: ', Q.get_shape())\n",
    "\n",
    "        # Split and concat\n",
    "        assert self.num_units % self.num_heads == 0\n",
    "        Q_ = torch.cat(torch.split(Q, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_q, d/h)\n",
    "        K_ = torch.cat(torch.split(K, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_k, d/h)\n",
    "        V_ = torch.cat(torch.split(V, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_k, d/h)\n",
    "\n",
    "        # Multiplication\n",
    "        outputs = torch.matmul(Q_, torch.permute(K_, [0, 2, 1]))  # (h*N, L_q, L_k)\n",
    "\n",
    "        # Scale\n",
    "        outputs = outputs / (list(K_.shape)[-1] ** 0.5)  # (h*N, L_q, L_k)\n",
    "\n",
    "        # Key Masking\n",
    "        key_masks = torch.sign(torch.sum(torch.abs(K_), dim=-1))  # (h*N, T_k)\n",
    "        key_masks = torch.unsqueeze(key_masks, 1)  # (h*N, 1, T_k)\n",
    "        key_masks = torch.tile(key_masks, [1, list(Q_.shape)[1], 1])  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Apply masks to outputs\n",
    "        paddings = torch.ones_like(outputs, device=device) * (-2 ** 32 + 1)  # exp mask\n",
    "        outputs = torch.where(key_masks == 0, paddings, outputs)  # (h*N, T_q, T_k)\n",
    "\n",
    "        n_visits = list(input_tensor.shape)[1]\n",
    "        sw_indices = torch.arange(0, n_visits, dtype=torch.int32, device=device)\n",
    "        sw_col, sw_row = torch.meshgrid(sw_indices, sw_indices)\n",
    "        if self.direction == MaskDirection.DIAGONAL:\n",
    "            # shape of (n_visits, n_visits)\n",
    "            attention_mask = (torch.diag(- torch.ones([n_visits], dtype=torch.int32, device=device)) + 1).bool()\n",
    "        elif self.direction == MaskDirection.FORWARD:\n",
    "            attention_mask = torch.greater(sw_row, sw_col)  # shape of (n_visits, n_visits)\n",
    "        else: # MaskDirection.BACKWARD\n",
    "            attention_mask = torch.greater(sw_col, sw_row)  # shape of (n_visits, n_visits)\n",
    "        adder = (1.0 - attention_mask.type(outputs.dtype)) * -10000.0\n",
    "        outputs += adder\n",
    "\n",
    "        # softmax\n",
    "        outputs = F.softmax(outputs, -1)  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Query Masking\n",
    "        query_masks = torch.sign(torch.sum(torch.abs(Q_), dim=-1))  # (h*N, T_q)\n",
    "        query_masks = torch.unsqueeze(query_masks, -1)  # (h*N, T_q, 1)\n",
    "        query_masks = torch.tile(query_masks, [1, 1, list(K_.shape)[1]])  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Apply masks to outputs\n",
    "        outputs = outputs * query_masks\n",
    "\n",
    "        # Dropouts\n",
    "        outputs = self.dropout(outputs)\n",
    "        # Weighted sum\n",
    "        outputs = torch.matmul(outputs, V_)  # ( h*N, T_q, C/h)\n",
    "\n",
    "        # Restore shape\n",
    "        outputs = torch.cat(torch.split(outputs, outputs.shape[0] // self.num_heads, dim=0), dim=2)  # (N, L_q, d)\n",
    "\n",
    "        # input padding\n",
    "        val_mask = torch.unsqueeze(input_mask, -1)\n",
    "        outputs = torch.multiply(outputs, (~val_mask).float())\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class MaskEnc(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int,\n",
    "            num_heads: int,\n",
    "            dropout: float = 0.1,\n",
    "            temporal_mask_direction: MaskDirection = MaskDirection.NONE,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.temporal_mask_direction = temporal_mask_direction\n",
    "\n",
    "        self.attention = MultiHeadAttention(\n",
    "            direction=temporal_mask_direction,\n",
    "            dropout=dropout,\n",
    "            num_units=embedding_dim,\n",
    "            num_heads=num_heads\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embedding_dim, embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.layer_norm1 = MaskedLayerNorm(embedding_dim)\n",
    "        self.layer_norm2 = MaskedLayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, key_padding_mask = inputs\n",
    "\n",
    "        attn_output = self.attention((x, key_padding_mask))\n",
    "        attn_output = self.layer_norm1(x + attn_output)\n",
    "        out = self.fc(attn_output)\n",
    "        out = out * (~key_padding_mask.unsqueeze(-1)).float()\n",
    "        out = self.layer_norm2(out + attn_output)\n",
    "        out = out * (~key_padding_mask.unsqueeze(-1)).float()\n",
    "\n",
    "        return out, key_padding_mask\n",
    "\n",
    "    def _make_temporal_mask(self, n: int) -> Optional[torch.Tensor]:\n",
    "        if self.temporal_mask_direction == MaskDirection.NONE:\n",
    "            return None\n",
    "        if self.temporal_mask_direction == MaskDirection.FORWARD:\n",
    "            return torch.tril(torch.full((n, n), -10000, device=device)).fill_diagonal_(0).float()\n",
    "        if self.temporal_mask_direction == MaskDirection.BACKWARD:\n",
    "            return torch.triu(torch.full((n, n), -10000, device=device)).fill_diagonal_(0).float()\n",
    "        if self.temporal_mask_direction == MaskDirection.DIAGONAL:\n",
    "            return torch.zeros(n, n, device=device).fill_diagonal_(-10000).float()\n",
    "\n",
    "\n",
    "class BiteNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int = 128,\n",
    "            num_heads: int = 4,\n",
    "            dropout: float = 0.1,\n",
    "            n_mask_enc_layers: int = 2,\n",
    "            use_procedures: bool = True,\n",
    "            use_intervals: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_intervals = use_intervals\n",
    "        self.use_procedures = use_procedures\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.unflatten = Unflatten()\n",
    "\n",
    "        def _make_mask_enc_block(temporal_mask_direction: MaskDirection = MaskDirection.NONE):\n",
    "            return MaskEnc(\n",
    "                embedding_dim = embedding_dim,\n",
    "                num_heads = num_heads,\n",
    "                dropout = dropout,\n",
    "                temporal_mask_direction = temporal_mask_direction,\n",
    "            )\n",
    "\n",
    "        self.code_attn = nn.Sequential()\n",
    "        self.visit_attn_fw = nn.Sequential()\n",
    "        self.visit_attn_bw = nn.Sequential()\n",
    "        for _ in range(n_mask_enc_layers):\n",
    "            self.code_attn.append(_make_mask_enc_block(MaskDirection.DIAGONAL))\n",
    "            self.visit_attn_fw.append(_make_mask_enc_block(MaskDirection.FORWARD))\n",
    "            self.visit_attn_bw.append(_make_mask_enc_block(MaskDirection.BACKWARD))\n",
    "\n",
    "        # Attention pooling layers\n",
    "        self.code_attn.append(AttentionPooling(embedding_dim))\n",
    "        self.visit_attn_fw.append(AttentionPooling(embedding_dim))\n",
    "        self.visit_attn_bw.append(AttentionPooling(embedding_dim))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*embedding_dim, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            embedded_codes: torch.Tensor,\n",
    "            embedded_intervals: torch.Tensor,\n",
    "            codes_mask: torch.Tensor,\n",
    "            visits_mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        codes_mask = ~(codes_mask.bool())\n",
    "\n",
    "        # input tensor, reshape 4 dimension to 3\n",
    "        flattened_codes = self.flatten(embedded_codes, 2)\n",
    "\n",
    "        # input mask, reshape 3 dimension to 2\n",
    "        flattened_codes_mask = self.flatten(codes_mask, 1)\n",
    "\n",
    "        code_attn = self.code_attn((flattened_codes, flattened_codes_mask))\n",
    "        code_attn = self.unflatten(code_attn, embedded_codes, self.embedding_dim)\n",
    "\n",
    "        if self.use_intervals:\n",
    "            code_attn += embedded_intervals\n",
    "\n",
    "        visits_mask = ~(visits_mask.bool())\n",
    "\n",
    "        u_fw = self.visit_attn_fw((code_attn, visits_mask))\n",
    "        u_bw = self.visit_attn_bw((code_attn, visits_mask))\n",
    "        u_bi = torch.cat([u_fw, u_bw], dim=-1)\n",
    "\n",
    "        s = self.fc(u_bi)\n",
    "        return s\n",
    "\n",
    "class PyHealthBiteNet(BaseModel):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: SampleDataset,\n",
    "            feature_keys: List[str],\n",
    "            label_key: str,\n",
    "            mode: str,\n",
    "            embedding_dim: int = 128,\n",
    "            n_mask_enc_layers: int = 2,\n",
    "            use_intervals: bool = True,\n",
    "            use_procedures: bool = True,\n",
    "            num_heads: int = 4,\n",
    "            dropout: float = 0.1,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(dataset, feature_keys, label_key, mode)\n",
    "\n",
    "        self.use_intervals = use_intervals\n",
    "        self.use_procedures = use_procedures\n",
    "\n",
    "        # Any BaseModel should have these attributes, as functions like add_feature_transform_layer uses them\n",
    "        self.feat_tokenizers = {}\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        self.linear_layers = nn.ModuleDict()\n",
    "        self.label_tokenizer = self.get_label_tokenizer()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # self.add_feature_transform_layer will create a transformation layer for each feature\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "            self.add_feature_transform_layer(\n",
    "                feature_key, input_info, special_tokens=[\"<pad>\", \"<unk>\"]\n",
    "            )\n",
    "\n",
    "        # final output layer\n",
    "        output_size = self.get_output_size(self.label_tokenizer)\n",
    "        self.bite_net = BiteNet(\n",
    "            embedding_dim = embedding_dim,\n",
    "            num_heads = num_heads,\n",
    "            dropout = dropout,\n",
    "            use_intervals=use_intervals,\n",
    "            use_procedures=use_procedures,\n",
    "            n_mask_enc_layers=n_mask_enc_layers,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(self.embedding_dim, output_size)\n",
    "\n",
    "    def forward(self, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        embeddings = {}\n",
    "        masks = {}\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "\n",
    "            # each patient's feature is represented by [[code1, code2],[code3]]\n",
    "            assert input_info[\"dim\"] == 3 and input_info[\"type\"] == str\n",
    "            feature_vals = kwargs[feature_key]\n",
    "\n",
    "            x = self.feat_tokenizers[feature_key].batch_encode_3d(feature_vals, truncation=(False, False))\n",
    "            x = torch.tensor(x, dtype=torch.long, device=self.device)\n",
    "            pad_idx = self.feat_tokenizers[feature_key].vocabulary(\"<pad>\")\n",
    "            #create the mask\n",
    "            mask = (x != pad_idx).long()\n",
    "            embeds = self.embeddings[feature_key](x)\n",
    "            embeddings[feature_key] = embeds\n",
    "            masks[feature_key] = mask\n",
    "\n",
    "        embedded_codes = embeddings['diagnoses']\n",
    "        codes_mask = masks['diagnoses']\n",
    "        if self.use_procedures:\n",
    "            embedded_codes = torch.cat((embedded_codes, embeddings['procedures']), dim=2)\n",
    "            codes_mask = torch.cat((codes_mask, masks['procedures']), dim=2)\n",
    "\n",
    "        output = self.bite_net(embedded_codes, embeddings['intervals'].squeeze(2), codes_mask, masks['intervals'].squeeze(-1))\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        # obtain y_true, loss, y_prob\n",
    "        y_true = self.prepare_labels(kwargs[self.label_key], self.label_tokenizer)\n",
    "        loss = self.get_loss_function()(logits, y_true)\n",
    "        y_prob = self.prepare_y_prob(logits)\n",
    "\n",
    "        return {\"loss\": loss, \"y_prob\": y_prob, \"y_true\": y_true}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, train_loader, val_loader, test_loader, lr=0.001):\n",
    "    trainer = Trainer(model=model, device=device)\n",
    "    trainer.train(\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        epochs=10,\n",
    "        monitor=\"pr_auc\",\n",
    "        optimizer_class=torch.optim.RMSprop,\n",
    "        optimizer_params = {\"lr\" : lr},\n",
    "        load_best_model_at_last=False\n",
    "    )\n",
    "\n",
    "    # Run inference and evaluate\n",
    "    # option 1: use our built-in evaluation metric\n",
    "    score = trainer.evaluate(test_loader)\n",
    "    print (score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:45:34.482218Z",
     "end_time": "2023-04-29T20:45:34.508213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples for patient_level_readmission_prediction: 100%|██████████| 7496/7496 [00:00<00:00, 50993.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6930\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset and data loaders\n",
    "# Create the task datasets\n",
    "dataset = mimic3_ds.set_task(task_fn=patient_level_readmission_prediction)\n",
    "print(len(dataset))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train, val, test = split_by_patient(dataset, [0.8, 0.1, 0.1])\n",
    "\n",
    "train_loader = get_dataloader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = get_dataloader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = get_dataloader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:45:34.839436Z",
     "end_time": "2023-04-29T20:45:35.137432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:45:37.086252Z",
     "end_time": "2023-04-29T20:46:44.403347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyHealthBiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1756, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000211A794E700>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5c6b8c209f942459a8be2b8940e6fe9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5055\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 62.30it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.3660\n",
      "roc_auc: 0.5995\n",
      "f1: 0.1863\n",
      "loss: 0.4864\n",
      "New best pr_auc score (0.3660) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ada9cebec73c4f0b86b2dd9b33630836"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.4785\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 62.86it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.3754\n",
      "roc_auc: 0.6035\n",
      "f1: 0.1840\n",
      "loss: 0.4827\n",
      "New best pr_auc score (0.3754) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34029d7a8c5e4b579e6b519103b511ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.4700\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 62.15it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.3902\n",
      "roc_auc: 0.6223\n",
      "f1: 0.2012\n",
      "loss: 0.4836\n",
      "New best pr_auc score (0.3902) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae83b14a5d8a468195429059ecb89757"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.4601\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.80it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.3963\n",
      "roc_auc: 0.6316\n",
      "f1: 0.2000\n",
      "loss: 0.4823\n",
      "New best pr_auc score (0.3963) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "390c380efe0c48d6941128f3e5c7032a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.4522\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 62.15it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.4007\n",
      "roc_auc: 0.6363\n",
      "f1: 0.2473\n",
      "loss: 0.4992\n",
      "New best pr_auc score (0.4007) at epoch-4, step-870\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e4cfa79d6524b70a28e05719e909872"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.4419\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 62.32it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3943\n",
      "roc_auc: 0.6256\n",
      "f1: 0.2708\n",
      "loss: 0.5125\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ff9a9b2352b4f1da63db655fe992a39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.4319\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.97it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3931\n",
      "roc_auc: 0.6294\n",
      "f1: 0.1860\n",
      "loss: 0.5042\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c776806fff34671b9fbf355313332bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.4188\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.97it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.3965\n",
      "roc_auc: 0.6319\n",
      "f1: 0.1932\n",
      "loss: 0.5323\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12f9a66f40b74d8c8a5e2a2618848d82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.4060\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.28it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.3863\n",
      "roc_auc: 0.6277\n",
      "f1: 0.1734\n",
      "loss: 0.5277\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12544e076e0b4ef2bbfc2c669d41686e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.3925\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.62it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.3840\n",
      "roc_auc: 0.6262\n",
      "f1: 0.2996\n",
      "loss: 0.5548\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 65.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.4163112201085489, 'roc_auc': 0.6811761546723952, 'f1': 0.3466666666666666, 'loss': 0.5100423598831351}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    PyHealthBiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"label\",\n",
    "        mode = \"binary\",\n",
    "        use_procedures=True,\n",
    "        use_intervals=True\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (rnn): ModuleDict(\n",
      "    (diagnoses): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "    (procedures): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000211A794E700>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c39a0e26caa54b54a244148081980d32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5060\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 147.66it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.4103\n",
      "roc_auc: 0.6276\n",
      "f1: 0.2275\n",
      "loss: 0.4788\n",
      "New best pr_auc score (0.4103) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35a2dd9827c94598ae7a7d529149d253"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.4188\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 141.03it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.4115\n",
      "roc_auc: 0.6165\n",
      "f1: 0.2712\n",
      "loss: 0.4967\n",
      "New best pr_auc score (0.4115) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebc794e42eb948e48d8cd64b81d36873"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.3401\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 140.13it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.4139\n",
      "roc_auc: 0.6251\n",
      "f1: 0.3021\n",
      "loss: 0.5159\n",
      "New best pr_auc score (0.4139) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7d86e59b14c46c49ac4ac97b08bac62"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.2591\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 147.65it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.3980\n",
      "roc_auc: 0.6171\n",
      "f1: 0.2817\n",
      "loss: 0.5742\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb97d74b914b4689aaee1093b339c091"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.1863\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 131.74it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.4049\n",
      "roc_auc: 0.6146\n",
      "f1: 0.3529\n",
      "loss: 0.6299\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe575c0d8d9447bfb03ce45de6cfaee4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.1322\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 120.22it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3986\n",
      "roc_auc: 0.6215\n",
      "f1: 0.2909\n",
      "loss: 0.6772\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "839a28a956924d108ae90dec3f114211"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0958\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 146.67it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3949\n",
      "roc_auc: 0.6128\n",
      "f1: 0.3291\n",
      "loss: 0.7314\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a891b77978dc443a9e7b62c4711b6768"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0665\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 144.74it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.3848\n",
      "roc_auc: 0.6095\n",
      "f1: 0.2715\n",
      "loss: 0.8290\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50c106bfcd154010a4d31d5ea8725a4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0481\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 147.65it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.3936\n",
      "roc_auc: 0.6116\n",
      "f1: 0.3226\n",
      "loss: 0.8718\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2d388316062433f9bb0270f7dd3c070"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0369\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 148.65it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.3827\n",
      "roc_auc: 0.6051\n",
      "f1: 0.2918\n",
      "loss: 0.9339\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 161.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.3738644161210829, 'roc_auc': 0.6120972073039742, 'f1': 0.3047619047619048, 'loss': 0.8288188739256426}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    RNN(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.001\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:46:52.089218Z",
     "end_time": "2023-04-29T20:47:14.874291Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (retain): ModuleDict(\n",
      "    (diagnoses): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (procedures): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000211A794E700>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da114fef9a3741ed93305ae321406ec4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5355\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 84.29it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.3553\n",
      "roc_auc: 0.5890\n",
      "f1: 0.1775\n",
      "loss: 0.5163\n",
      "New best pr_auc score (0.3553) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19ab54a5c3d24e64a00ce07a0a1fc3d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.3683\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 80.88it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.3871\n",
      "roc_auc: 0.6180\n",
      "f1: 0.2737\n",
      "loss: 0.5194\n",
      "New best pr_auc score (0.3871) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b8653603baa45198d9d87e5b46c6850"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.2285\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 77.19it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.3715\n",
      "roc_auc: 0.6024\n",
      "f1: 0.2526\n",
      "loss: 0.6153\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "636f0e32c1b8480398726c1d5f797817"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.1225\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 78.01it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.3835\n",
      "roc_auc: 0.5939\n",
      "f1: 0.3097\n",
      "loss: 0.6973\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "622878b58c6c49679eb914c3363eb6ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0688\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 79.42it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.3848\n",
      "roc_auc: 0.6013\n",
      "f1: 0.3117\n",
      "loss: 0.8054\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "044414be83e64fee887417ac1bad62f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0419\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 76.39it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3802\n",
      "roc_auc: 0.5960\n",
      "f1: 0.3084\n",
      "loss: 0.9247\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64d18c3bb15e4d83a949b36fb72ad5dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0313\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 80.29it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3778\n",
      "roc_auc: 0.6086\n",
      "f1: 0.3070\n",
      "loss: 0.9865\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dec59a7cbdc547518aa36f45093dcbf5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0186\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 79.71it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.3776\n",
      "roc_auc: 0.5983\n",
      "f1: 0.2857\n",
      "loss: 1.1027\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31f1037a0d4c435a8f0a2cd7ba1e9f40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0181\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 73.83it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.3936\n",
      "roc_auc: 0.6030\n",
      "f1: 0.3004\n",
      "loss: 1.1505\n",
      "New best pr_auc score (0.3936) at epoch-8, step-1566\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f4e9978d31c40aeb47ffbeea1d37c56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0158\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 78.29it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.3926\n",
      "roc_auc: 0.6023\n",
      "f1: 0.3064\n",
      "loss: 1.2158\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 82.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.3606033694496517, 'roc_auc': 0.5797932330827067, 'f1': 0.29729729729729726, 'loss': 1.2300627353516491}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    RETAIN(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:47:49.609222Z",
     "end_time": "2023-04-29T20:48:50.110635Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3375, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1363, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (cnn): ModuleDict(\n",
      "    (diagnoses): DeeprLayer(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "    )\n",
      "    (procedures): DeeprLayer(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000211A794E700>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "673342986c5e4c0295bf0e0ec5b994b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5101\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 183.33it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.4078\n",
      "roc_auc: 0.6345\n",
      "f1: 0.1863\n",
      "loss: 0.4984\n",
      "New best pr_auc score (0.4078) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "464186425d54491c8f1885b8f5649a78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.3764\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 268.29it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.4154\n",
      "roc_auc: 0.6332\n",
      "f1: 0.2755\n",
      "loss: 0.4897\n",
      "New best pr_auc score (0.4154) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41e917c3f5fa498f8212a0856e712d81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.2655\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 258.82it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.3905\n",
      "roc_auc: 0.6049\n",
      "f1: 0.3258\n",
      "loss: 0.5340\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da8179e0bf92441c88515e0c8f16028a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.1544\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 249.96it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.4250\n",
      "roc_auc: 0.6310\n",
      "f1: 0.3577\n",
      "loss: 0.5696\n",
      "New best pr_auc score (0.4250) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a553e71e82b34f9fb80bc9ad954bb79a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0791\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 244.44it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.3979\n",
      "roc_auc: 0.6118\n",
      "f1: 0.2922\n",
      "loss: 0.6220\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7da574cacc34ac7a662d3c5e38123da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0389\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 261.87it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3990\n",
      "roc_auc: 0.6011\n",
      "f1: 0.2842\n",
      "loss: 0.7871\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec6ddf3d75c0469caaebae5e4ff2a3b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0175\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 255.79it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3948\n",
      "roc_auc: 0.6088\n",
      "f1: 0.2737\n",
      "loss: 0.8633\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "352248d3b17446648e1e80119d035c39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0168\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 255.82it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.4105\n",
      "roc_auc: 0.6164\n",
      "f1: 0.2932\n",
      "loss: 0.9251\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25cad53f6c2d4a05befd0155688da302"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0055\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 255.81it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.3957\n",
      "roc_auc: 0.6097\n",
      "f1: 0.3136\n",
      "loss: 0.8593\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91dfe39e991e4f45a2cad324ee804bd3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0027\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 252.87it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.4183\n",
      "roc_auc: 0.6189\n",
      "f1: 0.3349\n",
      "loss: 0.9303\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 224.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.39479580130583247, 'roc_auc': 0.6421455424274973, 'f1': 0.303030303030303, 'loss': 0.8376922133294019}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    Deepr(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:49:23.296202Z",
     "end_time": "2023-04-29T20:49:36.578089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
