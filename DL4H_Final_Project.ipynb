{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Google Cloud authentication and data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=mA4KTl8iW7ExFCgiSIGV20WPRGNlqP&access_type=offline&code_challenge=xuy5gjuf9GwNlmobryR0GgFOlCXznHfpqWf2kC4oOvM&code_challenge_method=S256\n",
      "\n",
      "\n",
      "You are now logged in as [camerongreenwalt@gmail.com].\n",
      "Your current project is [dl4h-final-project-383605].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n",
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=VhRb04TAkTK1P44NMUbqMETl8LbKmJ&access_type=offline&code_challenge=kI_eC118DoXyOitFkk97dyveJMvPc3wJ6vZzl6sMbeE&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [C:\\Users\\camer\\AppData\\Roaming\\gcloud\\application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"dl4h-final-project-383605\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth login\n",
    "! gcloud auth application-default login\n",
    "! gcloud config set project dl4h-final-project-383605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pCHvVcifGcdr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (2.86.0)\n",
      "Requirement already satisfied: google-cloud-storage in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (2.17.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (2.11.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-cloud-storage) (2.28.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-cloud-storage) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-cloud-storage) (2.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.59.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (4.22.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade google-api-python-client google-cloud-storage\n",
    "from google.cloud import storage\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Replace these values with your project and bucket as needed\n",
    "project_id = \"dl4h-final-project-383605\"\n",
    "mimic3_bucket = \"mimiciii-1.4.physionet.org\"\n",
    "\n",
    "storage_client = storage.Client(project=project_id)\n",
    "bucket = storage_client.bucket(mimic3_bucket)\n",
    "data_folder = \"data\"\n",
    "for blob in bucket.list_blobs():\n",
    "    if \"CHARTEVENTS\" in blob.name:\n",
    "        continue\n",
    "\n",
    "    gz_path = f\"{data_folder}/{blob.name}\"\n",
    "    blob.download_to_filename(gz_path)\n",
    "\n",
    "    with gzip.open(gz_path, 'rb') as f_in:\n",
    "        with open(gz_path.replace(\".gz\", \"\"), 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    os.remove(gz_path)\n",
    "\n",
    "# # Extract all the files\n",
    "# ! gunzip {data_folder}/*.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall torch torchvision torchaudio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Library imports and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T18:10:43.315000Z",
     "end_time": "2023-04-22T18:10:43.318219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyhealth\n",
      "  Using cached pyhealth-1.1.3-py2.py3-none-any.whl (113 kB)\n",
      "Collecting pandas>=1.3.2\n",
      "  Downloading pandas-2.0.1-cp39-cp39-win_amd64.whl (10.7 MB)\n",
      "     --------------------------------------- 10.7/10.7 MB 23.4 MB/s eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting scikit-learn>=0.24.2\n",
      "  Downloading scikit_learn-1.2.2-cp39-cp39-win_amd64.whl (8.4 MB)\n",
      "     ---------------------------------------- 8.4/8.4 MB 28.2 MB/s eta 0:00:00\n",
      "Collecting rdkit>=2022.03.4\n",
      "  Downloading rdkit-2022.9.5-cp39-cp39-win_amd64.whl (20.5 MB)\n",
      "     ---------------------------------------- 20.5/20.5 MB 9.0 MB/s eta 0:00:00\n",
      "Collecting torch>=1.8.0\n",
      "  Downloading torch-2.0.0-cp39-cp39-win_amd64.whl (172.3 MB)\n",
      "     ------------------------------------- 172.3/172.3 MB 19.3 MB/s eta 0:00:00\n",
      "Collecting networkx>=2.6.3\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting numpy>=1.20.3\n",
      "  Downloading numpy-1.24.3-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "     --------------------------------------- 14.9/14.9 MB 36.4 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pandas>=1.3.2->pyhealth) (2.8.2)\n",
      "Collecting Pillow\n",
      "  Downloading Pillow-9.5.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 40.1 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.10.1-cp39-cp39-win_amd64.whl (42.5 MB)\n",
      "     --------------------------------------- 42.5/42.5 MB 29.7 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from torch>=1.8.0->pyhealth) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from torch>=1.8.0->pyhealth) (4.5.0)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "Requirement already satisfied: colorama in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from tqdm->pyhealth) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.2->pyhealth) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from jinja2->torch>=1.8.0->pyhealth) (2.1.2)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: pytz, mpmath, tzdata, tqdm, threadpoolctl, sympy, Pillow, numpy, networkx, joblib, filelock, torch, scipy, rdkit, pandas, scikit-learn, pyhealth\n",
      "Successfully installed Pillow-9.5.0 filelock-3.12.0 joblib-1.2.0 mpmath-1.3.0 networkx-3.1 numpy-1.24.3 pandas-2.0.1 pyhealth-1.1.3 pytz-2023.3 rdkit-2022.9.5 scikit-learn-1.2.2 scipy-1.10.1 sympy-1.11.1 threadpoolctl-3.1.0 torch-2.0.0 tqdm-4.65.0 tzdata-2023.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (2.0.0)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.1%2Bcu118-cp39-cp39-win_amd64.whl (4.9 MB)\n",
      "     ---------------------------------------- 4.9/4.9 MB 9.0 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.1%2Bcu118-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 31.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: sympy in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Collecting requests\n",
      "  Using cached https://download.pytorch.org/whl/requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://download.pytorch.org/whl/certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached https://download.pytorch.org/whl/urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Using cached https://download.pytorch.org/whl/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: urllib3, charset-normalizer, certifi, requests, torchvision, torchaudio\n",
      "Successfully installed certifi-2022.12.7 charset-normalizer-2.1.1 requests-2.28.1 torchaudio-2.0.1+cu118 torchvision-0.15.1+cu118 urllib3-1.26.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\pyhealth\\trainer.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "! pip install pyhealth\n",
    "! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "from pyhealth.datasets import MIMIC3Dataset, SampleDataset\n",
    "from pyhealth.data import Visit\n",
    "import pandas as pd\n",
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "from pyhealth.models import BaseModel\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.metrics.binary import binary_metrics_fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Dict, Optional\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "\n",
    "# Set this to the directory with all MIMIC-3 dataset files\n",
    "data_root = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-VgeMdJDYYK",
    "outputId": "9cb9c08a-9003-4836-a3b2-a23e7cd45b55",
    "ExecuteTime": {
     "start_time": "2023-04-22T18:11:57.435144Z",
     "end_time": "2023-04-22T18:12:00.244064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "mimic3_ds = MIMIC3Dataset(\n",
    "        root=data_root,\n",
    "        tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\"],\n",
    "        dev=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "HQdeU1TLU6m_",
    "outputId": "590623d6-2917-4155-bf0a-5d75a3979c25",
    "ExecuteTime": {
     "start_time": "2023-04-22T18:12:02.232818Z",
     "end_time": "2023-04-22T18:12:02.326272Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 46520\n",
      "\t- Number of visits: 58976\n",
      "\t- Number of visits per patient: 1.2678\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0711\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 46520\\n\\t- Number of visits: 58976\\n\\t- Number of visits per patient: 1.2678\\n\\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0711\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataset statistics\n",
    "\n",
    "mimic3_ds.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Find all diagnoses codes\n",
    "# Find all procedure codes\n",
    "# Remove diagnoses codes with fewer than 5 occurences in the dataset\n",
    "\n",
    "all_diag_codes = []\n",
    "for patient_id, patient in mimic3_ds.patients.items():\n",
    "  for i in range(len(patient)):\n",
    "    visit: Visit = patient[i]\n",
    "    conditions = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "    all_diag_codes.extend(conditions)\n",
    "\n",
    "codes = pd.Series(all_diag_codes)\n",
    "diag_code_counts = codes.value_counts()\n",
    "filtered_diag_codes = diag_code_counts[diag_code_counts > 4].index.values\n",
    "num_unique_diag_codes = len(filtered_diag_codes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-22T18:12:03.817269Z",
     "end_time": "2023-04-22T18:12:04.048432Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "fgrnO7KkWDBY",
    "ExecuteTime": {
     "start_time": "2023-04-24T15:09:39.002985Z",
     "end_time": "2023-04-24T15:09:39.007622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the tasks\n",
    "\n",
    "DIAGNOSES_KEY = \"conditions\"\n",
    "PROCEDURES_KEY = \"procedures\"\n",
    "INTERVAL_DAYS_KEY = \"days_since_first_visit\"\n",
    "\n",
    "def flatten(l: List):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def patient_level_readmission_prediction(patient, time_window=30):\n",
    "    \"\"\"\n",
    "    patient is a <pyhealth.data.Patient> object\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    # if the patient only has one visit, we drop it\n",
    "    if len(patient) <= 1:\n",
    "        return []\n",
    "\n",
    "    sorted_visits = sorted(patient, key=lambda visit: visit.encounter_time)\n",
    "\n",
    "    # step 1: define label\n",
    "    idx_last_visit = len(sorted_visits)-1\n",
    "    last_visit: Visit = sorted_visits[idx_last_visit]\n",
    "    second_to_last_visit: Visit = sorted_visits[idx_last_visit - 1]\n",
    "    first_visit: Visit = sorted_visits[0]\n",
    "\n",
    "    time_diff = (last_visit.encounter_time - second_to_last_visit.encounter_time).days\n",
    "    readmission_label = 1 if time_diff < time_window else 0\n",
    "\n",
    "    # step 2: obtain features\n",
    "    visits_conditions = []\n",
    "    visits_procedures = []\n",
    "    visits_intervals = []\n",
    "    for idx, visit in enumerate(sorted_visits):\n",
    "        if idx == len(sorted_visits) - 1: break # Don't include the last visit\n",
    "        conditions = [c for c in visit.get_code_list(table=\"DIAGNOSES_ICD\") if c in filtered_diag_codes]\n",
    "        procedures = visit.get_code_list(table=\"PROCEDURES_ICD\")\n",
    "        time_diff_from_first_visit = (visit.encounter_time - first_visit.encounter_time).days\n",
    "\n",
    "        if len(conditions) * len(procedures) == 0:\n",
    "            continue\n",
    "\n",
    "        visits_conditions.append(conditions)\n",
    "        visits_procedures.append(procedures)\n",
    "        visits_intervals.append([str(time_diff_from_first_visit)])\n",
    "\n",
    "    unique_conditions = list(set(flatten(visits_conditions)))\n",
    "    unique_procedures = list(set(flatten(visits_procedures)))\n",
    "\n",
    "    # step 3: exclusion criteria\n",
    "    if len(unique_conditions) * len(unique_procedures) == 0:\n",
    "        return []\n",
    "\n",
    "    # step 4: assemble the sample\n",
    "    samples.append(\n",
    "        {\n",
    "            \"patient_id\": patient.patient_id,\n",
    "            \"visit_id\": visit.visit_id,\n",
    "            \"conditions\": visits_conditions,\n",
    "            \"procedures\": visits_procedures,\n",
    "            \"intervals\": visits_intervals,\n",
    "            \"label\": readmission_label,\n",
    "        }\n",
    "    )\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "IMD0MvgA8e8Z",
    "outputId": "11b7f21f-9f3b-419c-ee21-69ec1e3e02fe",
    "ExecuteTime": {
     "start_time": "2023-04-24T15:09:39.525972Z",
     "end_time": "2023-04-24T15:09:46.186242Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples for patient_level_readmission_prediction: 100%|██████████| 46520/46520 [00:58<00:00, 800.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6966\n"
     ]
    }
   ],
   "source": [
    "# Create the task datasets\n",
    "mimic3_dxtx = mimic3_ds.set_task(task_fn=patient_level_readmission_prediction)\n",
    "print(len(mimic3_dxtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train, val, test = split_by_patient(mimic3_dxtx, [0.8, 0.1, 0.1])\n",
    "\n",
    "train_loader = get_dataloader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = get_dataloader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = get_dataloader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T17:31:19.818129Z",
     "end_time": "2023-04-24T17:31:19.833491Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T11:51:51.384927Z",
     "end_time": "2023-04-25T11:51:53.075534Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'loss': tensor(0.7139, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n 'y_prob': tensor([[0.5203],\n         [0.5223],\n         [0.5352],\n         [0.5096],\n         [0.5221],\n         [0.5216],\n         [0.5194],\n         [0.5191],\n         [0.5206],\n         [0.5181],\n         [0.5205],\n         [0.5268],\n         [0.5210],\n         [0.5188],\n         [0.5221],\n         [0.5313],\n         [0.5125],\n         [0.5128],\n         [0.5200],\n         [0.5198],\n         [0.5203],\n         [0.5214],\n         [0.5192],\n         [0.5071],\n         [0.5250],\n         [0.5192],\n         [0.5231],\n         [0.5218],\n         [0.5202],\n         [0.5207],\n         [0.5212],\n         [0.5148]], grad_fn=<SigmoidBackward0>),\n 'y_true': tensor([[0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.],\n         [1.]])}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the models\n",
    "VERY_BIG_NUMBER = 1e30\n",
    "VERY_SMALL_NUMBER = 1e-30\n",
    "VERY_POSITIVE_NUMBER = VERY_BIG_NUMBER\n",
    "VERY_NEGATIVE_NUMBER = -VERY_BIG_NUMBER\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MaskDirection(Enum):\n",
    "    FORWARD = 'forward'\n",
    "    BACKWARD = 'backward'\n",
    "    DIAGONAL = 'diagonal'\n",
    "    NONE = 'none'\n",
    "\n",
    "class MaskedLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape: int):\n",
    "        super().__init__()\n",
    "        self.scale = nn.parameter.Parameter(torch.ones(normalized_shape, dtype=torch.float32, device=device))\n",
    "        self.bias = nn.parameter.Parameter(torch.zeros(normalized_shape, dtype=torch.float32, device=device))\n",
    "        self.normalized_shape = normalized_shape\n",
    "\n",
    "    def forward(self, x: torch.Tensor, eps=1e-5):\n",
    "        mean = torch.mean(x, dim=-1, keepdim=True)\n",
    "        variance = torch.mean(torch.square(x - mean), dim=-1, keepdim=True)\n",
    "        norm_x = (x - mean) * torch.rsqrt(variance + eps)\n",
    "        return norm_x * self.scale + self.bias\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, keep: int):\n",
    "        fixed_shape = list(x.size())\n",
    "        start = len(fixed_shape) - keep\n",
    "        left = reduce(mul, [fixed_shape[i] or x.shape[i] for i in range(start)])\n",
    "        out_shape = [left] + [fixed_shape[i] or x.shape[i] for i in range(start, len(fixed_shape))]\n",
    "        return torch.reshape(x, out_shape)\n",
    "\n",
    "\n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, v: torch.Tensor, ref: torch.Tensor, embedding_dim):\n",
    "        batch_size = ref.shape[0]\n",
    "        n_visits = ref.shape[1]\n",
    "        out = torch.reshape(v, [batch_size, n_visits, embedding_dim])\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, embedding_size: int):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_size, embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, mask = inputs\n",
    "        x = self.fc(x)\n",
    "        x[mask] = VERY_NEGATIVE_NUMBER\n",
    "        soft = F.softmax(x, dim=1)\n",
    "        x[mask] = 0\n",
    "        attn_output = torch.sum(soft * x, 1)\n",
    "        return attn_output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, direction, dropout, num_units, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.direction = direction\n",
    "        self.dropout = dropout\n",
    "        self.num_units = num_units\n",
    "        self.q_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.k_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.v_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # because of self-attention, queries and keys is equal to inputs\n",
    "        input_tensor, input_mask = inputs\n",
    "        queries = input_tensor\n",
    "        keys = input_tensor\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.q_linear(queries)  # (N, L_q, d)\n",
    "        K = self.k_linear(keys)  # (N, L_k, d)\n",
    "        V = self.v_linear(keys)  # (N, L_k, d)\n",
    "\n",
    "        # print('Q shape: ', Q.get_shape())\n",
    "\n",
    "        # Split and concat\n",
    "        assert self.num_units % self.num_heads == 0\n",
    "        Q_ = torch.cat(torch.split(Q, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_q, d/h)\n",
    "        K_ = torch.cat(torch.split(K, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_k, d/h)\n",
    "        V_ = torch.cat(torch.split(V, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_k, d/h)\n",
    "\n",
    "        # Multiplication\n",
    "        outputs = torch.matmul(Q_, torch.permute(K_, [0, 2, 1]))  # (h*N, L_q, L_k)\n",
    "\n",
    "        # Scale\n",
    "        outputs = outputs / (list(K_.shape)[-1] ** 0.5)  # (h*N, L_q, L_k)\n",
    "\n",
    "        # Key Masking\n",
    "        key_masks = torch.sign(torch.sum(torch.abs(K_), dim=-1))  # (h*N, T_k)\n",
    "        key_masks = torch.unsqueeze(key_masks, 1)  # (h*N, 1, T_k)\n",
    "        key_masks = torch.tile(key_masks, [1, list(Q_.shape)[1], 1])  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Apply masks to outputs\n",
    "        paddings = torch.ones_like(outputs, device=device) * (-2 ** 32 + 1)  # exp mask\n",
    "        outputs = torch.where(key_masks == 0, paddings, outputs)  # (h*N, T_q, T_k)\n",
    "\n",
    "        n_visits = list(input_tensor.shape)[1]\n",
    "        sw_indices = torch.arange(0, n_visits, dtype=torch.int32, device=device)\n",
    "        sw_col, sw_row = torch.meshgrid(sw_indices, sw_indices)\n",
    "        if self.direction == MaskDirection.DIAGONAL:\n",
    "            # shape of (n_visits, n_visits)\n",
    "            attention_mask = (torch.diag(- torch.ones([n_visits], dtype=torch.int32, device=device)) + 1).bool()\n",
    "        elif self.direction == MaskDirection.FORWARD:\n",
    "            attention_mask = torch.greater(sw_row, sw_col)  # shape of (n_visits, n_visits)\n",
    "        else: # MaskDirection.BACKWARD\n",
    "            attention_mask = torch.greater(sw_col, sw_row)  # shape of (n_visits, n_visits)\n",
    "        adder = (1.0 - attention_mask.type(outputs.dtype)) * -10000.0\n",
    "        outputs += adder\n",
    "\n",
    "        # softmax\n",
    "        outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Query Masking\n",
    "        query_masks = torch.sign(torch.sum(torch.abs(Q_), dim=-1))  # (h*N, T_q)\n",
    "        query_masks = torch.unsqueeze(query_masks, -1)  # (h*N, T_q, 1)\n",
    "        query_masks = torch.tile(query_masks, [1, 1, list(K_.shape)[1]])  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Apply masks to outputs\n",
    "        outputs = outputs * query_masks\n",
    "\n",
    "        # Dropouts\n",
    "        outputs = F.dropout(outputs, p=self.dropout)\n",
    "        # Weighted sum\n",
    "        outputs = torch.matmul(outputs, V_)  # ( h*N, T_q, C/h)\n",
    "\n",
    "        # Restore shape\n",
    "        outputs = torch.cat(torch.split(outputs, outputs.shape[0] // self.num_heads, dim=0), dim=2)  # (N, L_q, d)\n",
    "\n",
    "        # input padding\n",
    "        val_mask = torch.unsqueeze(input_mask, -1)\n",
    "        outputs = torch.multiply(outputs, (~val_mask).float())\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class MaskEnc(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int,\n",
    "            num_heads: int,\n",
    "            dropout: float = 0.1,\n",
    "            batch_first: bool = True,\n",
    "            temporal_mask_direction: MaskDirection = MaskDirection.NONE,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.temporal_mask_direction = temporal_mask_direction\n",
    "\n",
    "        # self.attention = nn.MultiheadAttention(\n",
    "        #         embed_dim=embedding_dim,\n",
    "        #         num_heads=num_heads,\n",
    "        #         dropout=dropout,\n",
    "        #         batch_first=batch_first\n",
    "        #     )\n",
    "\n",
    "        self.attention = MultiHeadAttention(\n",
    "            direction=temporal_mask_direction,\n",
    "            dropout=dropout,\n",
    "            num_units=embedding_dim,\n",
    "            num_heads=num_heads\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embedding_dim, embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.layer_norm1 = MaskedLayerNorm(embedding_dim)\n",
    "        self.layer_norm2 = MaskedLayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, key_padding_mask = inputs\n",
    "\n",
    "        attn_output = self.attention((x, key_padding_mask))\n",
    "        attn_output = self.layer_norm1(x + attn_output)\n",
    "        out = self.fc(attn_output)\n",
    "        out = out * (~key_padding_mask.unsqueeze(-1)).float()\n",
    "        out = self.layer_norm2(out + attn_output)\n",
    "        out = out * (~key_padding_mask.unsqueeze(-1)).float()\n",
    "\n",
    "        return out, key_padding_mask\n",
    "\n",
    "    def _make_temporal_mask(self, n: int) -> Optional[torch.Tensor]:\n",
    "        if self.temporal_mask_direction == MaskDirection.NONE:\n",
    "            return None\n",
    "        if self.temporal_mask_direction == MaskDirection.FORWARD:\n",
    "            return torch.tril(torch.full((n, n), -10000, device=device)).fill_diagonal_(0).float()\n",
    "        if self.temporal_mask_direction == MaskDirection.BACKWARD:\n",
    "            return torch.triu(torch.full((n, n), -10000, device=device)).fill_diagonal_(0).float()\n",
    "        if self.temporal_mask_direction == MaskDirection.DIAGONAL:\n",
    "            return torch.zeros(n, n, device=device).fill_diagonal_(-10000).float()\n",
    "\n",
    "\n",
    "class BiteNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int = 128,\n",
    "            num_heads: int = 4,\n",
    "            dropout: float = 0.1,\n",
    "            batch_first: bool = True,\n",
    "            n_mask_enc_layers: int = 2,\n",
    "            use_procedures: bool = True,\n",
    "            use_intervals: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_intervals = use_intervals\n",
    "        self.use_procedures = use_procedures\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.unflatten = Unflatten()\n",
    "\n",
    "        def _make_mask_enc_block(temporal_mask_direction: MaskDirection = MaskDirection.NONE):\n",
    "            return MaskEnc(\n",
    "                embedding_dim = embedding_dim,\n",
    "                num_heads = num_heads,\n",
    "                dropout = dropout,\n",
    "                batch_first = batch_first,\n",
    "                temporal_mask_direction = temporal_mask_direction,\n",
    "            )\n",
    "\n",
    "        self.code_attn = nn.Sequential()\n",
    "        self.visit_attn_fw = nn.Sequential()\n",
    "        self.visit_attn_bw = nn.Sequential()\n",
    "        for _ in range(n_mask_enc_layers):\n",
    "            self.code_attn.append(_make_mask_enc_block(MaskDirection.DIAGONAL))\n",
    "            self.visit_attn_fw.append(_make_mask_enc_block(MaskDirection.FORWARD))\n",
    "            self.visit_attn_bw.append(_make_mask_enc_block(MaskDirection.BACKWARD))\n",
    "\n",
    "        # Attention pooling layers\n",
    "        self.code_attn.append(AttentionPooling(embedding_dim))\n",
    "        self.visit_attn_fw.append(AttentionPooling(embedding_dim))\n",
    "        self.visit_attn_bw.append(AttentionPooling(embedding_dim))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*embedding_dim, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            embedded_codes: torch.Tensor,\n",
    "            embedded_intervals: torch.Tensor,\n",
    "            codes_mask: torch.Tensor,\n",
    "            visits_mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        codes_mask = ~(codes_mask.bool())\n",
    "\n",
    "        # input tensor, reshape 4 dimension to 3\n",
    "        flattened_codes = self.flatten(embedded_codes, 2)\n",
    "\n",
    "        # input mask, reshape 3 dimension to 2\n",
    "        flattened_codes_mask = self.flatten(codes_mask, 1)\n",
    "\n",
    "        code_attn = self.code_attn((flattened_codes, flattened_codes_mask))\n",
    "        code_attn = self.unflatten(code_attn, embedded_codes, self.embedding_dim)\n",
    "\n",
    "        if self.use_intervals:\n",
    "            code_attn += embedded_intervals\n",
    "\n",
    "        visits_mask = ~(visits_mask.bool())\n",
    "\n",
    "        u_fw = self.visit_attn_fw((code_attn, visits_mask))\n",
    "        u_bw = self.visit_attn_bw((code_attn, visits_mask))\n",
    "        u_bi = torch.cat([u_fw, u_bw], dim=-1)\n",
    "\n",
    "        s = self.fc(u_bi)\n",
    "        return s\n",
    "\n",
    "class PyHealthBiteNet(BaseModel):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: SampleDataset,\n",
    "            feature_keys: List[str],\n",
    "            label_key: str,\n",
    "            mode: str,\n",
    "            embedding_dim: int = 128,\n",
    "            n_mask_enc_layers: int = 2,\n",
    "            use_intervals: bool = True,\n",
    "            use_procedures: bool = True,\n",
    "            num_heads: int = 4,\n",
    "            dropout: float = 0.1,\n",
    "            batch_first: bool = True,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(dataset, feature_keys, label_key, mode)\n",
    "\n",
    "        self.use_intervals = use_intervals\n",
    "        self.use_procedures = use_procedures\n",
    "\n",
    "        # Any BaseModel should have these attributes, as functions like add_feature_transform_layer uses them\n",
    "        self.feat_tokenizers = {}\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        self.linear_layers = nn.ModuleDict()\n",
    "        self.label_tokenizer = self.get_label_tokenizer()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # self.add_feature_transform_layer will create a transformation layer for each feature\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "            self.add_feature_transform_layer(\n",
    "                feature_key, input_info, special_tokens=[\"<pad>\", \"<unk>\"]\n",
    "            )\n",
    "\n",
    "        # final output layer\n",
    "        output_size = self.get_output_size(self.label_tokenizer)\n",
    "        self.bite_net = BiteNet(\n",
    "            embedding_dim = embedding_dim,\n",
    "            num_heads = num_heads,\n",
    "            dropout = dropout,\n",
    "            batch_first = batch_first,\n",
    "            use_intervals=use_intervals,\n",
    "            use_procedures=use_procedures,\n",
    "            n_mask_enc_layers=n_mask_enc_layers\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(self.embedding_dim, output_size)\n",
    "\n",
    "    def forward(self, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        embeddings = {}\n",
    "        masks = {}\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "\n",
    "            # each patient's feature is represented by [[code1, code2],[code3]]\n",
    "            assert input_info[\"dim\"] == 3 and input_info[\"type\"] == str\n",
    "            feature_vals = kwargs[feature_key]\n",
    "\n",
    "            x = self.feat_tokenizers[feature_key].batch_encode_3d(feature_vals, truncation=(False, False))\n",
    "            x = torch.tensor(x, dtype=torch.long, device=self.device)\n",
    "            pad_idx = self.feat_tokenizers[feature_key].vocabulary(\"<pad>\")\n",
    "            #create the mask\n",
    "            mask = (x != pad_idx).long()\n",
    "            embeds = self.embeddings[feature_key](x)\n",
    "            embeddings[feature_key] = embeds\n",
    "            masks[feature_key] = mask\n",
    "\n",
    "        embedded_codes = embeddings['conditions']\n",
    "        codes_mask = masks['conditions']\n",
    "        if self.use_procedures:\n",
    "            embedded_codes = torch.cat((embedded_codes, embeddings['procedures']), dim=2)\n",
    "            codes_mask = torch.cat((codes_mask, masks['procedures']), dim=2)\n",
    "\n",
    "        output = self.bite_net(embedded_codes, embeddings['intervals'].squeeze(2), codes_mask, masks['intervals'].squeeze(-1))\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        # obtain y_true, loss, y_prob\n",
    "        y_true = self.prepare_labels(kwargs[self.label_key], self.label_tokenizer)\n",
    "        loss = self.get_loss_function()(logits, y_true)\n",
    "        y_prob = self.prepare_y_prob(logits)\n",
    "\n",
    "        return {\"loss\": loss, \"y_prob\": y_prob, \"y_true\": y_true}\n",
    "\n",
    "model_dxtx = PyHealthBiteNet(\n",
    "    dataset = mimic3_dxtx,\n",
    "    feature_keys = ['procedures', 'conditions', 'intervals'],\n",
    "    label_key = \"label\",\n",
    "    mode = \"binary\",\n",
    "    embedding_dim=128\n",
    ")\n",
    "\n",
    "data = next(iter(train_loader))\n",
    "model_dxtx(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T11:54:26.633007Z",
     "end_time": "2023-04-25T11:54:26.662744Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dxtx = PyHealthBiteNet(\n",
    "    dataset = mimic3_dxtx,\n",
    "    feature_keys = [\"conditions\", \"procedures\", \"intervals\"],\n",
    "    label_key = \"label\",\n",
    "    mode = \"binary\",\n",
    "    use_intervals=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T11:54:27.147449Z",
     "end_time": "2023-04-25T11:56:58.026243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyHealthBiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (conditions): Embedding(3383, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1366, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1758, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cpu\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000239FDCED1C0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/175 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21540881e7074e1994e615398482e6d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "--- Train epoch-0, step-175 ---\n",
      "loss: 0.5119\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  6.83it/s]\n",
      "--- Eval epoch-0, step-175 ---\n",
      "pr_auc: 0.4030\n",
      "roc_auc: 0.6136\n",
      "f1: 0.2604\n",
      "loss: 0.4876\n",
      "New best pr_auc score (0.4030) at epoch-0, step-175\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/175 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9338dcbb29c844c9848ba00e2c98b802"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "--- Train epoch-1, step-350 ---\n",
      "loss: 0.4651\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  6.85it/s]\n",
      "--- Eval epoch-1, step-350 ---\n",
      "pr_auc: 0.4383\n",
      "roc_auc: 0.6434\n",
      "f1: 0.2825\n",
      "loss: 0.5117\n",
      "New best pr_auc score (0.4383) at epoch-1, step-350\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/175 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d25cf723410b4b2b883094c057ed90b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "--- Train epoch-2, step-525 ---\n",
      "loss: 0.4555\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  6.90it/s]\n",
      "--- Eval epoch-2, step-525 ---\n",
      "pr_auc: 0.4151\n",
      "roc_auc: 0.6332\n",
      "f1: 0.2629\n",
      "loss: 0.5024\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/175 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ae9c7e854a84eafb8f8bf266bc6b09b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "--- Train epoch-3, step-700 ---\n",
      "loss: 0.4415\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  6.93it/s]\n",
      "--- Eval epoch-3, step-700 ---\n",
      "pr_auc: 0.4224\n",
      "roc_auc: 0.6333\n",
      "f1: 0.3011\n",
      "loss: 0.4806\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/175 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f5b438ff32b4944b123e197e375672e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "--- Train epoch-4, step-875 ---\n",
      "loss: 0.4228\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  7.00it/s]\n",
      "--- Eval epoch-4, step-875 ---\n",
      "pr_auc: 0.4383\n",
      "roc_auc: 0.6483\n",
      "f1: 0.3053\n",
      "loss: 0.4784\n",
      "New best pr_auc score (0.4383) at epoch-4, step-875\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/175 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdda6ddb598f4ff0bbbe40e70236155b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "--- Train epoch-5, step-1050 ---\n",
      "loss: 0.4002\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  7.00it/s]\n",
      "--- Eval epoch-5, step-1050 ---\n",
      "pr_auc: 0.4408\n",
      "roc_auc: 0.6423\n",
      "f1: 0.2674\n",
      "loss: 0.5595\n",
      "New best pr_auc score (0.4408) at epoch-5, step-1050\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/175 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7508904d25194499a2cf9d82cd31242e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "--- Train epoch-6, step-1225 ---\n",
      "loss: 0.3764\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  7.01it/s]\n",
      "--- Eval epoch-6, step-1225 ---\n",
      "pr_auc: 0.4206\n",
      "roc_auc: 0.6315\n",
      "f1: 0.3004\n",
      "loss: 0.5915\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/175 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad27b26d6d584e18b3ea79723336beff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "--- Train epoch-7, step-1400 ---\n",
      "loss: 0.3646\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  7.02it/s]\n",
      "--- Eval epoch-7, step-1400 ---\n",
      "pr_auc: 0.4157\n",
      "roc_auc: 0.6278\n",
      "f1: 0.2915\n",
      "loss: 0.5261\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/175 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2aebce1933774fce9c0129152b4c8f94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "--- Train epoch-8, step-1575 ---\n",
      "loss: 0.3458\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  7.00it/s]\n",
      "--- Eval epoch-8, step-1575 ---\n",
      "pr_auc: 0.4150\n",
      "roc_auc: 0.6273\n",
      "f1: 0.2814\n",
      "loss: 0.5048\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/175 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e3eff5f8c4541a68ba278b436dbe21b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "--- Train epoch-9, step-1750 ---\n",
      "loss: 0.3200\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  6.73it/s]\n",
      "--- Eval epoch-9, step-1750 ---\n",
      "pr_auc: 0.4398\n",
      "roc_auc: 0.6336\n",
      "f1: 0.3118\n",
      "loss: 0.5791\n",
      "Loaded best model\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "trainer_dxtx = Trainer(model=model_dxtx, device=device)\n",
    "trainer_dxtx.train(\n",
    "    train_dataloader=train_loader,\n",
    "    val_dataloader=val_loader,\n",
    "    epochs=10,\n",
    "    monitor=\"pr_auc\",\n",
    "    optimizer_class=torch.optim.RMSprop,\n",
    "    optimizer_params = {\"lr\" : 0.0005}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-24T17:33:57.152886Z",
     "end_time": "2023-04-24T17:33:58.129087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/22 [00:00<?, ?it/s]C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.38294873668605134, 'roc_auc': 0.601272572159818, 'f1': 0.16374269005847955, 'loss': 0.6431476853110574}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/22 [00:00<?, ?it/s]C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n",
      "Evaluation: 100%|██████████| 22/22 [00:03<00:00,  6.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'pr_auc': 0.382514915599601}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# option 1: use our built-in evaluation metric\n",
    "score_dxtx = trainer_dxtx.evaluate(test_loader)\n",
    "print (score_dxtx)\n",
    "\n",
    "# option 2: use our pyhealth.metrics to evaluate\n",
    "y_true_dxtx, y_prob_dxtx, loss_dxtx = trainer_dxtx.inference(test_loader)\n",
    "binary_metrics_fn(y_true_dxtx, y_prob_dxtx, metrics=[\"pr_auc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T11:57:02.763803Z",
     "end_time": "2023-04-25T11:57:02.910605Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Temp\\ipykernel_21628\\965784428.py:130: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs = F.softmax(outputs)  # (h*N, T_q, T_k)\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'loss': tensor(0.6077, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n 'y_prob': tensor([[0.2305],\n         [0.2184],\n         [0.1594],\n         [0.1707],\n         [0.1550],\n         [0.1514],\n         [0.1566],\n         [0.1493],\n         [0.1598],\n         [0.1874],\n         [0.1582],\n         [0.2617],\n         [0.1537],\n         [0.1613],\n         [0.2134],\n         [0.2247],\n         [0.2616],\n         [0.2554],\n         [0.1549],\n         [0.1507],\n         [0.1971],\n         [0.1496],\n         [0.2594],\n         [0.2351],\n         [0.2642],\n         [0.1560],\n         [0.1523],\n         [0.2607],\n         [0.1563],\n         [0.1488],\n         [0.4262],\n         [0.1522]], grad_fn=<SigmoidBackward0>),\n 'y_true': tensor([[0.],\n         [0.],\n         [0.],\n         [1.],\n         [1.],\n         [0.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]])}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_loader))\n",
    "model_dxtx(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
