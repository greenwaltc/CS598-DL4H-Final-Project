{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Library imports and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T17:41:13.120174Z",
     "end_time": "2023-05-03T17:41:13.136171Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install pyhealth\n",
    "from pyhealth.datasets import MIMIC3Dataset, SampleDataset\n",
    "from pyhealth.data import Patient, Visit, Event\n",
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "from pyhealth.models import BaseModel, RNN, RETAIN, Deepr\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.medcode import InnerMap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Dict, Optional\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "from tqdm import tqdm\n",
    "from pyhealth.metrics.binary import binary_metrics_fn\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set this to the directory with all MIMIC-3 dataset files\n",
    "data_root = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-VgeMdJDYYK",
    "outputId": "9cb9c08a-9003-4836-a3b2-a23e7cd45b55",
    "ExecuteTime": {
     "start_time": "2023-05-03T16:35:44.097646Z",
     "end_time": "2023-05-03T16:35:47.467645Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "mimic3_ds = MIMIC3Dataset(\n",
    "        root=data_root,\n",
    "        tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\"],\n",
    "        dev=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "HQdeU1TLU6m_",
    "outputId": "590623d6-2917-4155-bf0a-5d75a3979c25",
    "ExecuteTime": {
     "start_time": "2023-05-03T16:35:47.469644Z",
     "end_time": "2023-05-03T16:35:47.703643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 46520\n",
      "\t- Number of visits: 58976\n",
      "\t- Number of visits per patient: 1.2678\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0711\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 46520\\n\\t- Number of visits: 58976\\n\\t- Number of visits per patient: 1.2678\\n\\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0711\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataset statistics\n",
    "\n",
    "mimic3_ds.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Find all diagnoses codes\n",
    "# Remove diagnoses codes with fewer than 5 occurences in the dataset\n",
    "\n",
    "all_diagnosis_codes = []\n",
    "for patient_id, patient in mimic3_ds.patients.items():\n",
    "  for i in range(len(patient)):\n",
    "    visit: Visit = patient[i]\n",
    "    conditions = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "    all_diagnosis_codes.extend(conditions)\n",
    "\n",
    "codes = pd.Series(all_diagnosis_codes)\n",
    "diag_code_counts = codes.value_counts()\n",
    "filtered_diag_codes = diag_code_counts[diag_code_counts > 4].index.values\n",
    "n_unique_diag_codes = len(filtered_diag_codes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T16:35:47.687642Z",
     "end_time": "2023-05-03T16:35:48.090643Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46520/46520 [01:09<00:00, 666.78it/s]\n"
     ]
    }
   ],
   "source": [
    "MIN_N_VISITS_PER_PATIENT = 2\n",
    "\n",
    "# Filter Dataset to requirements specified in paper\n",
    "\n",
    "filtered_patients = {}\n",
    "for patient_id, patient in tqdm(mimic3_ds.patients.items()):\n",
    "\n",
    "    filtered_patient: Patient = Patient(\n",
    "        patient_id=patient.patient_id,\n",
    "        birth_datetime=patient.birth_datetime,\n",
    "        death_datetime=patient.death_datetime,\n",
    "        gender=patient.gender,\n",
    "        ethnicity=patient.ethnicity\n",
    "    )\n",
    "\n",
    "    for i_visit, visit in enumerate(patient):\n",
    "        filtered_visit: Visit = Visit(\n",
    "            visit_id=visit.visit_id,\n",
    "            patient_id=visit.patient_id,\n",
    "            encounter_time=visit.encounter_time,\n",
    "            discharge_time=visit.discharge_time,\n",
    "            discharge_status=visit.discharge_status\n",
    "        )\n",
    "\n",
    "        diagnoses_codes = visit.get_code_list(\"DIAGNOSES_ICD\")\n",
    "        procedures_codes = visit.get_code_list(\"PROCEDURES_ICD\")\n",
    "        prescriptions_codes = visit.get_code_list(\"PRESCRIPTIONS\")\n",
    "\n",
    "        if len(diagnoses_codes) > 0:\n",
    "            diagnosis_events = visit.event_list_dict[\"DIAGNOSES_ICD\"]\n",
    "            for i_event in range(len(diagnosis_events) - 1, -1, -1):\n",
    "                event: Event = diagnosis_events[i_event]\n",
    "                if event.code not in filtered_diag_codes:\n",
    "                    diagnosis_events.pop(i_event) # Remove the diagnosis code with fewer than the cutoff occurrences\n",
    "\n",
    "            if len(diagnosis_events) == 0: continue # Don't include visits with no diagnoses\n",
    "\n",
    "            filtered_visit.set_event_list(\"DIAGNOSES_ICD\", diagnosis_events)\n",
    "        else:\n",
    "            continue # Don't include visits with no diagnoses\n",
    "\n",
    "        if len(procedures_codes) > 0:\n",
    "           filtered_visit.set_event_list(\"PROCEDURES_ICD\", visit.event_list_dict[\"PROCEDURES_ICD\"])\n",
    "\n",
    "        if len(prescriptions_codes) > 0:\n",
    "            filtered_visit.set_event_list(\"PRESCRIPTIONS\", visit.event_list_dict[\"PRESCRIPTIONS\"])\n",
    "\n",
    "        filtered_patient.add_visit(filtered_visit)\n",
    "\n",
    "    if len(filtered_patient.visits) >= MIN_N_VISITS_PER_PATIENT:\n",
    "        filtered_patients[patient_id] = filtered_patient\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T16:35:48.090643Z",
     "end_time": "2023-05-03T16:36:57.870338Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 7496\n",
      "\t- Number of visits: 19905\n",
      "\t- Number of visits per patient: 2.6554\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0975\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 7496\\n\\t- Number of visits: 19905\\n\\t- Number of visits per patient: 2.6554\\n\\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0975\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic3_ds.patients = filtered_patients\n",
    "mimic3_ds.stat()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T16:36:57.870338Z",
     "end_time": "2023-05-03T16:36:58.071335Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7496/7496 [00:00<00:00, 277654.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max span (days) of a single patient's visits: 4221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the dataset span for encoding visit intervals\n",
    "# The lookup table for interval encoding will be of dimensions mxd,\n",
    "# where m is the length of the dataset span and d is the embedding\n",
    "# dimension. The lookup table needs to be as large as the dataset\n",
    "# time span because it could be possible for a patient to have his/her\n",
    "# first visit on the earliest day in the dataset and the last visit on\n",
    "# the latest day in the dataset. Thus, the index for this patient's visit\n",
    "# interval would be (last_visit.time - first_visit.time).days = m = dataset span.\n",
    "\n",
    "max_patient_span_days: int = 0\n",
    "\n",
    "for patient_id, patient in tqdm(mimic3_ds.patients.items()):\n",
    "\n",
    "    sorted_visits = sorted(patient, key=lambda v: v.encounter_time)\n",
    "    patient_span_days = (sorted_visits[-1].encounter_time - sorted_visits[0].encounter_time).days\n",
    "    if patient_span_days > max_patient_span_days:\n",
    "        max_patient_span_days = patient_span_days\n",
    "\n",
    "print(f\"Max span (days) of a single patient's visits: {max_patient_span_days}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T16:36:58.074335Z",
     "end_time": "2023-05-03T16:36:58.134337Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fgrnO7KkWDBY",
    "ExecuteTime": {
     "start_time": "2023-05-03T16:36:58.125336Z",
     "end_time": "2023-05-03T16:36:58.211333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the tasks\n",
    "\n",
    "DIAGNOSES_KEY = \"conditions\"\n",
    "PROCEDURES_KEY = \"procedures\"\n",
    "INTERVAL_DAYS_KEY = \"days_since_first_visit\"\n",
    "\n",
    "icd9cm = InnerMap.load(\"ICD9CM\")\n",
    "\n",
    "def flatten(l: List):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def patient_level_readmission_prediction(patient, time_window: int = 30, max_length_visits: int = None):\n",
    "    \"\"\"\n",
    "    patient is a <pyhealth.data.Patient> object\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    # # if the patient only has one visit, we drop it\n",
    "    # if len(patient) <= 1:\n",
    "    #     return []\n",
    "\n",
    "    sorted_visits = sorted(patient, key=lambda visit: visit.encounter_time)\n",
    "\n",
    "    # Clip the patient visits to the most recent max_length_visits + 1 if max_length_visits is not None\n",
    "    if max_length_visits is not None:\n",
    "        n_visits = len(sorted_visits)\n",
    "        if n_visits > max_length_visits + 1:\n",
    "            sorted_visits = sorted_visits[n_visits - (max_length_visits + 1):]\n",
    "\n",
    "    feature_visits: List[Visit] = sorted_visits[:-1]\n",
    "    last_visit: Visit = sorted_visits[-1]\n",
    "    second_to_last_visit: Visit = feature_visits[-1]\n",
    "    first_visit: Visit = feature_visits[0]\n",
    "\n",
    "    # step 1 a: define readmission label\n",
    "    time_diff = (last_visit.encounter_time - second_to_last_visit.encounter_time).days\n",
    "    readmission_label = 1 if time_diff <= time_window else 0\n",
    "\n",
    "    # step 1 b: define diagnosis prediction label\n",
    "    diagnosis_label = list(set([icd9cm.get_ancestors(code)[1] for code in last_visit.get_code_list(\"DIAGNOSES_ICD\")]))\n",
    "\n",
    "    # step 2: obtain features\n",
    "    visits_diagnoses = []\n",
    "    visits_procedures = []\n",
    "    visits_intervals = []\n",
    "    for idx, visit in enumerate(feature_visits):\n",
    "        diagnoses = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "        procedures = visit.get_code_list(table=\"PROCEDURES_ICD\")\n",
    "        time_diff_from_first_visit = (visit.encounter_time - first_visit.encounter_time).days\n",
    "\n",
    "        # Exclude visits that are missing either diagnoses or procedures.\n",
    "        # BiteNet can handle missing procedures, but other PyHealth models like RNN\n",
    "        # require all features have a length greater than 0.\n",
    "        if len(diagnoses) * len(procedures) == 0:\n",
    "            continue\n",
    "\n",
    "        visits_diagnoses.append(diagnoses)\n",
    "        visits_procedures.append(procedures)\n",
    "        visits_intervals.append([str(time_diff_from_first_visit)])\n",
    "\n",
    "    unique_diagnoses = list(set(flatten(visits_diagnoses)))\n",
    "\n",
    "    # step 3: exclusion criteria\n",
    "    if len(unique_diagnoses) == 0:\n",
    "        return []\n",
    "\n",
    "    # step 4: assemble the sample\n",
    "    samples.append(\n",
    "        {\n",
    "            \"patient_id\": patient.patient_id,\n",
    "            \"visit_id\": visit.visit_id,\n",
    "            \"diagnoses\": visits_diagnoses,\n",
    "            \"procedures\": visits_procedures,\n",
    "            \"intervals\": visits_intervals,\n",
    "            \"readmission_label\": readmission_label,\n",
    "            \"diagnosis_label\": diagnosis_label\n",
    "        }\n",
    "    )\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples for patient_level_readmission_prediction: 100%|██████████| 7496/7496 [00:04<00:00, 1855.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6930\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset and data loaders\n",
    "# Create the task datasets\n",
    "dataset = mimic3_ds.set_task(task_fn=patient_level_readmission_prediction)\n",
    "print(len(dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T17:18:05.766865Z",
     "end_time": "2023-05-03T17:18:09.978749Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T16:37:02.267333Z",
     "end_time": "2023-05-03T16:37:02.328335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define the models\n",
    "VERY_BIG_NUMBER = 1e30\n",
    "VERY_SMALL_NUMBER = 1e-30\n",
    "VERY_POSITIVE_NUMBER = VERY_BIG_NUMBER\n",
    "VERY_NEGATIVE_NUMBER = -VERY_BIG_NUMBER\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "class MaskDirection(Enum):\n",
    "    FORWARD = 'forward'\n",
    "    BACKWARD = 'backward'\n",
    "    DIAGONAL = 'diagonal'\n",
    "    NONE = 'none'\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape: int):\n",
    "        super().__init__()\n",
    "        self.scale = nn.parameter.Parameter(torch.ones(normalized_shape, dtype=torch.float32, device=device))\n",
    "        self.bias = nn.parameter.Parameter(torch.zeros(normalized_shape, dtype=torch.float32, device=device))\n",
    "        self.normalized_shape = normalized_shape\n",
    "\n",
    "    def forward(self, x: torch.Tensor, eps=1e-5):\n",
    "        mean = torch.mean(x, dim=-1, keepdim=True)\n",
    "        variance = torch.mean(torch.square(x - mean), dim=-1, keepdim=True)\n",
    "        norm_x = (x - mean) * torch.rsqrt(variance + eps)\n",
    "        return norm_x * self.scale + self.bias\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, keep: int):\n",
    "        fixed_shape = list(x.size())\n",
    "        start = len(fixed_shape) - keep\n",
    "        left = reduce(mul, [fixed_shape[i] or x.shape[i] for i in range(start)])\n",
    "        out_shape = [left] + [fixed_shape[i] or x.shape[i] for i in range(start, len(fixed_shape))]\n",
    "        return torch.reshape(x, out_shape)\n",
    "\n",
    "\n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, v: torch.Tensor, ref: torch.Tensor, embedding_dim):\n",
    "        batch_size = ref.shape[0]\n",
    "        n_visits = ref.shape[1]\n",
    "        out = torch.reshape(v, [batch_size, n_visits, embedding_dim])\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, embedding_size: int):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_size, embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, mask = inputs\n",
    "        x = self.fc(x)\n",
    "        x[~mask] = VERY_NEGATIVE_NUMBER\n",
    "        soft = F.softmax(x, dim=1)\n",
    "        x[~mask] = 0\n",
    "        attn_output = torch.sum(soft * x, 1)\n",
    "        return attn_output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, direction, dropout, n_units, n_heads=4):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.direction = direction\n",
    "        self.n_units = n_units\n",
    "        self.q_linear = nn.Linear(n_units, n_units, bias=False)\n",
    "        self.k_linear = nn.Linear(n_units, n_units, bias=False)\n",
    "        self.v_linear = nn.Linear(n_units, n_units, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # because of self-attention, queries and keys is equal to inputs\n",
    "        input_tensor, input_mask = inputs\n",
    "        queries = input_tensor\n",
    "        keys = input_tensor\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.q_linear(queries)  # (N, L_q, d)\n",
    "        K = self.k_linear(keys)  # (N, L_k, d)\n",
    "        V = self.v_linear(keys)  # (N, L_k, d)\n",
    "\n",
    "        # Split and concat\n",
    "        assert self.n_units % self.n_heads == 0\n",
    "        Q_ = torch.cat(torch.split(Q, self.n_units // self.n_heads, dim=2), dim=0)  # (h*N, L_q, d/h)\n",
    "        K_ = torch.cat(torch.split(K, self.n_units // self.n_heads, dim=2), dim=0)  # (h*N, L_k, d/h)\n",
    "        V_ = torch.cat(torch.split(V, self.n_units // self.n_heads, dim=2), dim=0)  # (h*N, L_k, d/h)\n",
    "\n",
    "        # Multiplication\n",
    "        outputs = torch.matmul(Q_, torch.permute(K_, [0, 2, 1]))  # (h*N, L_q, L_k)\n",
    "\n",
    "        # Scale\n",
    "        outputs = outputs / (list(K_.shape)[-1] ** 0.5)  # (h*N, L_q, L_k)\n",
    "\n",
    "        # Key Masking\n",
    "        key_masks = torch.sign(torch.sum(torch.abs(K_), dim=-1))  # (h*N, T_k)\n",
    "        key_masks = torch.unsqueeze(key_masks, 1)  # (h*N, 1, T_k)\n",
    "        key_masks = torch.tile(key_masks, [1, list(Q_.shape)[1], 1])  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Apply masks to outputs\n",
    "        paddings = torch.ones_like(outputs, device=device) * (-2 ** 32 + 1)  # exp mask\n",
    "        outputs = torch.where(key_masks == 0, paddings, outputs)  # (h*N, T_q, T_k)\n",
    "\n",
    "        n_visits = list(input_tensor.shape)[1]\n",
    "        sw_indices = torch.arange(0, n_visits, dtype=torch.int32, device=device)\n",
    "        sw_col, sw_row = torch.meshgrid(sw_indices, sw_indices)\n",
    "        if self.direction == MaskDirection.DIAGONAL:\n",
    "            # shape of (n_visits, n_visits)\n",
    "            attention_mask = (torch.diag(- torch.ones([n_visits], dtype=torch.int32, device=device)) + 1).bool()\n",
    "        elif self.direction == MaskDirection.FORWARD:\n",
    "            attention_mask = torch.greater(sw_row, sw_col)  # shape of (n_visits, n_visits)\n",
    "        else: # MaskDirection.BACKWARD\n",
    "            attention_mask = torch.greater(sw_col, sw_row)  # shape of (n_visits, n_visits)\n",
    "        adder = (1.0 - attention_mask.type(outputs.dtype)) * -10000.0\n",
    "        outputs += adder\n",
    "\n",
    "        # softmax\n",
    "        outputs = F.softmax(outputs, -1)  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Query Masking\n",
    "        query_masks = torch.sign(torch.sum(torch.abs(Q_), dim=-1))  # (h*N, T_q)\n",
    "        query_masks = torch.unsqueeze(query_masks, -1)  # (h*N, T_q, 1)\n",
    "        query_masks = torch.tile(query_masks, [1, 1, list(K_.shape)[1]])  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Apply masks to outputs\n",
    "        outputs = outputs * query_masks\n",
    "\n",
    "        # Dropouts\n",
    "        outputs = self.dropout(outputs)\n",
    "        # Weighted sum\n",
    "        outputs = torch.matmul(outputs, V_)  # ( h*N, T_q, C/h)\n",
    "\n",
    "        # Restore shape\n",
    "        outputs = torch.cat(torch.split(outputs, outputs.shape[0] // self.n_heads, dim=0), dim=2)  # (N, L_q, d)\n",
    "\n",
    "        # input padding\n",
    "        val_mask = torch.unsqueeze(input_mask, -1)\n",
    "        outputs = torch.multiply(outputs, val_mask.float())\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class PrePostProcessingWrapper(nn.Module):\n",
    "  \"\"\"Wrapper class that applies layer pre-processing and post-processing.\"\"\"\n",
    "\n",
    "  def __init__(self, module: nn.Module, normalized_shape: int):\n",
    "    super().__init__()\n",
    "    self.module = module\n",
    "    self.layer_norm = LayerNorm(normalized_shape)\n",
    "\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    \"\"\"Calls wrapped layer with same parameters.\"\"\"\n",
    "\n",
    "    x, mask = inputs\n",
    "    # Preprocessing: apply layer normalization\n",
    "    y = self.layer_norm(x)\n",
    "    # Get layer output\n",
    "    try:\n",
    "        y = self.module((y, mask))\n",
    "    except:\n",
    "        y = self.module(y)\n",
    "    # Postprocessing: residual connection\n",
    "    return x + y\n",
    "\n",
    "\n",
    "class MaskEnc(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int,\n",
    "            n_heads: int,\n",
    "            dropout: float = 0.1,\n",
    "            temporal_mask_direction: MaskDirection = MaskDirection.NONE,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.temporal_mask_direction = temporal_mask_direction\n",
    "\n",
    "        self.attention = PrePostProcessingWrapper(\n",
    "            module=MultiHeadAttention(\n",
    "                direction=temporal_mask_direction,\n",
    "                dropout=dropout,\n",
    "                n_units=embedding_dim,\n",
    "                n_heads=n_heads\n",
    "            ),\n",
    "            normalized_shape=embedding_dim\n",
    "        )\n",
    "\n",
    "        self.fc = PrePostProcessingWrapper(\n",
    "            module=nn.Sequential(\n",
    "                nn.Linear(embedding_dim, embedding_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(embedding_dim, embedding_dim)\n",
    "            ),\n",
    "            normalized_shape=embedding_dim\n",
    "        )\n",
    "\n",
    "        self.output_normalization = LayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, mask = inputs\n",
    "\n",
    "        out = self.attention((x, mask))\n",
    "        out = self.fc((out, mask))\n",
    "        out = self.output_normalization(out)\n",
    "        return out, mask\n",
    "\n",
    "    def _make_temporal_mask(self, n: int) -> Optional[torch.Tensor]:\n",
    "        if self.temporal_mask_direction == MaskDirection.NONE:\n",
    "            return None\n",
    "        if self.temporal_mask_direction == MaskDirection.FORWARD:\n",
    "            return torch.tril(torch.full((n, n), -10000, device=device)).fill_diagonal_(0).float()\n",
    "        if self.temporal_mask_direction == MaskDirection.BACKWARD:\n",
    "            return torch.triu(torch.full((n, n), -10000, device=device)).fill_diagonal_(0).float()\n",
    "        if self.temporal_mask_direction == MaskDirection.DIAGONAL:\n",
    "            return torch.zeros(n, n, device=device).fill_diagonal_(-10000).float()\n",
    "\n",
    "\n",
    "class BiteNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int = 128,\n",
    "            n_heads: int = 4,\n",
    "            dropout: float = 0.1,\n",
    "            n_mask_enc_layers: int = 2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.unflatten = Unflatten()\n",
    "\n",
    "        def _make_mask_enc_block(temporal_mask_direction: MaskDirection = MaskDirection.NONE):\n",
    "            return MaskEnc(\n",
    "                embedding_dim = embedding_dim,\n",
    "                n_heads = n_heads,\n",
    "                dropout = dropout,\n",
    "                temporal_mask_direction = temporal_mask_direction,\n",
    "            )\n",
    "\n",
    "        self.code_attn = nn.Sequential()\n",
    "        self.visit_attn_fw = nn.Sequential()\n",
    "        self.visit_attn_bw = nn.Sequential()\n",
    "        for _ in range(n_mask_enc_layers):\n",
    "            self.code_attn.append(_make_mask_enc_block(MaskDirection.DIAGONAL))\n",
    "            self.visit_attn_fw.append(_make_mask_enc_block(MaskDirection.FORWARD))\n",
    "            self.visit_attn_bw.append(_make_mask_enc_block(MaskDirection.BACKWARD))\n",
    "\n",
    "        # Attention pooling layers\n",
    "        self.code_attn.append(AttentionPooling(embedding_dim))\n",
    "        self.visit_attn_fw.append(AttentionPooling(embedding_dim))\n",
    "        self.visit_attn_bw.append(AttentionPooling(embedding_dim))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*embedding_dim, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            embedded_codes: torch.Tensor,\n",
    "            codes_mask: torch.Tensor,\n",
    "            visits_mask: torch.Tensor,\n",
    "            embedded_intervals: torch.Tensor = None,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        # input tensor, reshape 4 dimension to 3\n",
    "        flattened_codes = self.flatten(embedded_codes, 2)\n",
    "\n",
    "        # input mask, reshape 3 dimension to 2\n",
    "        flattened_codes_mask = self.flatten(codes_mask, 1)\n",
    "\n",
    "        code_attn = self.code_attn((flattened_codes, flattened_codes_mask))\n",
    "        code_attn = self.unflatten(code_attn, embedded_codes, self.embedding_dim)\n",
    "\n",
    "        if embedded_intervals is not None:\n",
    "            code_attn += embedded_intervals\n",
    "\n",
    "        u_fw = self.visit_attn_fw((code_attn, visits_mask))\n",
    "        u_bw = self.visit_attn_bw((code_attn, visits_mask))\n",
    "        u_bi = torch.cat([u_fw, u_bw], dim=-1)\n",
    "\n",
    "        s = self.fc(u_bi)\n",
    "        return s\n",
    "\n",
    "class PyHealthBiteNet(BaseModel):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: SampleDataset,\n",
    "            feature_keys: List[str],\n",
    "            label_key: str,\n",
    "            mode: str,\n",
    "            embedding_dim: int = 128,\n",
    "            n_mask_enc_layers: int = 2,\n",
    "            n_heads: int = 4,\n",
    "            dropout: float = 0.1,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(dataset, feature_keys, label_key, mode)\n",
    "\n",
    "        # Any BaseModel should have these attributes, as functions like add_feature_transform_layer uses them\n",
    "        self.feat_tokenizers = {}\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        self.linear_layers = nn.ModuleDict()\n",
    "        self.label_tokenizer = self.get_label_tokenizer()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # self.add_feature_transform_layer will create a transformation layer for each feature\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "            self.add_feature_transform_layer(\n",
    "                feature_key, input_info, special_tokens=[\"<pad>\", \"<unk>\"]\n",
    "            )\n",
    "\n",
    "        # final output layer\n",
    "        output_size = self.get_output_size(self.label_tokenizer)\n",
    "        self.bite_net = BiteNet(\n",
    "            embedding_dim = embedding_dim,\n",
    "            n_heads = n_heads,\n",
    "            dropout = dropout,\n",
    "            n_mask_enc_layers=n_mask_enc_layers,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(self.embedding_dim, output_size)\n",
    "\n",
    "    def forward(self, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        embeddings = []\n",
    "        masks = []\n",
    "        intervals_embeddings = None\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "\n",
    "            # each patient's feature is represented by [[code1, code2],[code3]]\n",
    "            assert input_info[\"dim\"] == 3 and input_info[\"type\"] == str\n",
    "            feature_vals = kwargs[feature_key]\n",
    "\n",
    "            x = self.feat_tokenizers[feature_key].batch_encode_3d(feature_vals, truncation=(False, False))\n",
    "            x = torch.tensor(x, dtype=torch.long, device=self.device)\n",
    "            pad_idx = self.feat_tokenizers[feature_key].vocabulary(\"<pad>\")\n",
    "\n",
    "            # Create the mask\n",
    "            mask = (x != pad_idx).long()\n",
    "            embeds = self.embeddings[feature_key](x)\n",
    "\n",
    "            if feature_key == \"intervals\":\n",
    "                intervals_embeddings = embeds\n",
    "            else:\n",
    "                embeddings.append(embeds)\n",
    "                masks.append(mask)\n",
    "\n",
    "        code_embeddings = torch.cat(embeddings, dim=2)\n",
    "        codes_mask = torch.cat(masks, dim=2)\n",
    "        visits_mask = torch.where(torch.sum(codes_mask, dim=-1) != 0, 1, 0)\n",
    "\n",
    "        output = self.bite_net(code_embeddings, codes_mask, visits_mask, intervals_embeddings.squeeze(2))\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        # obtain y_true, loss, y_prob\n",
    "        y_true = self.prepare_labels(kwargs[self.label_key], self.label_tokenizer)\n",
    "        loss = self.get_loss_function()(logits, y_true)\n",
    "        y_prob = self.prepare_y_prob(logits)\n",
    "\n",
    "        return {\"loss\": loss, \"y_prob\": y_prob, \"y_true\": y_true}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "KS = list(range(5, 31, 5))\n",
    "N_TRIALS = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T17:48:07.559590Z",
     "end_time": "2023-05-03T17:48:07.578616Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def train_and_inference(model, train_loader, val_loader, test_loader, lr=0.001, monitor=\"pr_auc\", optim = torch.optim.Adam):\n",
    "    trainer = Trainer(model=model, device=device)\n",
    "    trainer.train(\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        epochs=10,\n",
    "        monitor=monitor,\n",
    "        optimizer_class=optim,\n",
    "        optimizer_params = {\"lr\" : lr},\n",
    "        load_best_model_at_last=True\n",
    "    )\n",
    "\n",
    "    return trainer.inference(test_loader)\n",
    "\n",
    "def precision_at_k(Y_true, Y_prob):\n",
    "\n",
    "    Y_pred = (Y_prob > 0.5).astype(int)\n",
    "    desc_idx = np.flip(np.argsort(Y_prob, axis=-1), axis=-1)\n",
    "\n",
    "    Y_true = np.take(Y_true, desc_idx)\n",
    "    Y_pred = np.take(Y_pred, desc_idx)\n",
    "\n",
    "    precisions = [\n",
    "        [\n",
    "            precision_score(y_true_sample[:k], y_pred_sample[:k])\n",
    "            for y_true_sample, y_pred_sample in zip(Y_true, Y_pred)\n",
    "        ]\n",
    "        for k in KS\n",
    "    ]\n",
    "\n",
    "    precisions = np.asarray(precisions)\n",
    "    precisions = np.mean(precisions, axis=1)\n",
    "    precisions = {\n",
    "        str(k): p for k, p in zip(KS, precisions.tolist())\n",
    "    }\n",
    "    return precisions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T17:48:08.175077Z",
     "end_time": "2023-05-03T17:48:08.200074Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['trial', 'model_name', 'feature_set', 'pr_auc', 'roc_auc', 'f1', '5', '10', '15', '20', '25', '30'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T17:48:09.205420Z",
     "end_time": "2023-05-03T17:48:09.224417Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T17:39:16.593800Z",
     "end_time": "2023-05-03T17:39:37.564800Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyHealthBiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1756, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000002329A0365B0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5b7fcdef0a94a69885624b7d7745a03"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5226\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 57.44it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.1908\n",
      "roc_auc: 0.4781\n",
      "f1: 0.0000\n",
      "loss: 0.4992\n",
      "New best pr_auc score (0.1908) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1b4c86be595490d9fa60e07f783573d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.5172\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 60.11it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.1911\n",
      "roc_auc: 0.4786\n",
      "f1: 0.0000\n",
      "loss: 0.4894\n",
      "New best pr_auc score (0.1911) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cfc6b5ccb3f42509435d3a8b103e36f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.5147\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 56.70it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.2955\n",
      "roc_auc: 0.5761\n",
      "f1: 0.0000\n",
      "loss: 0.4885\n",
      "New best pr_auc score (0.2955) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a04f339521bd4dcaa379680566bf335e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.5071\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 55.70it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.3319\n",
      "roc_auc: 0.5488\n",
      "f1: 0.1918\n",
      "loss: 0.4633\n",
      "New best pr_auc score (0.3319) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72a6f9c11aeb4c0eb464c6393eab93fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.4969\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 57.59it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.3521\n",
      "roc_auc: 0.5442\n",
      "f1: 0.2384\n",
      "loss: 0.4608\n",
      "New best pr_auc score (0.3521) at epoch-4, step-870\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b49bc57eb2348a1890437313bffdac3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.4996\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 57.14it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3648\n",
      "roc_auc: 0.6061\n",
      "f1: 0.2041\n",
      "loss: 0.4499\n",
      "New best pr_auc score (0.3648) at epoch-5, step-1044\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "560a43f6017e47a191c0c21803f9dfe3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.5032\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.82it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.2110\n",
      "roc_auc: 0.5416\n",
      "f1: 0.0000\n",
      "loss: 0.4859\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1646243ab62649eabb04714f9e200176"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.5100\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 59.14it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.2285\n",
      "roc_auc: 0.5510\n",
      "f1: 0.0000\n",
      "loss: 0.4858\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd79df4592c246bc871e5d8b2324457a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.5098\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.35it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.1925\n",
      "roc_auc: 0.4798\n",
      "f1: 0.0000\n",
      "loss: 0.4863\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54ac8fcbb0714dae9418e73ee8e9df35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.5097\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.98it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.2038\n",
      "roc_auc: 0.4697\n",
      "f1: 0.0000\n",
      "loss: 0.4880\n",
      "Loaded best model\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 60.27it/s]\n",
      "PyHealthBiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1756, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=465, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000002329A0365B0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1344b92e1bfa4baea1cc51342c59de22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.1125\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 55.00it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc_samples: 0.3146\n",
      "loss: 0.0919\n",
      "New best pr_auc_samples score (0.3146) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e6d8bbd0f4d4d25a3b54588b16092d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.0889\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 54.59it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc_samples: 0.3209\n",
      "loss: 0.0861\n",
      "New best pr_auc_samples score (0.3209) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8af7d2abea2f4e5fb30ac6bd8896f205"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.0860\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 56.56it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc_samples: 0.3275\n",
      "loss: 0.0851\n",
      "New best pr_auc_samples score (0.3275) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f98cec8251342d4851673fd8e09df74"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.0848\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 56.41it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc_samples: 0.3357\n",
      "loss: 0.0845\n",
      "New best pr_auc_samples score (0.3357) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7c203cbee714f0683c32f2d73870538"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0839\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 57.74it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc_samples: 0.3477\n",
      "loss: 0.0828\n",
      "New best pr_auc_samples score (0.3477) at epoch-4, step-870\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d82bed111964874b0c0756321851d49"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0830\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 56.85it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc_samples: 0.3707\n",
      "loss: 0.0831\n",
      "New best pr_auc_samples score (0.3707) at epoch-5, step-1044\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2edf324b4da48f5a38f6d4ba3b97106"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0819\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.20it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc_samples: 0.3864\n",
      "loss: 0.0811\n",
      "New best pr_auc_samples score (0.3864) at epoch-6, step-1218\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20edbc707c4e48d0a2e5049eae9f53ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0812\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 57.90it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc_samples: 0.3904\n",
      "loss: 0.0811\n",
      "New best pr_auc_samples score (0.3904) at epoch-7, step-1392\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc7aeaf9d3124a7a9108c5c5f97a314e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0805\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 55.42it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc_samples: 0.3948\n",
      "loss: 0.0809\n",
      "New best pr_auc_samples score (0.3948) at epoch-8, step-1566\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd2ef129d71e497ba0f99bdc462dead6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0800\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 55.00it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc_samples: 0.3928\n",
      "loss: 0.0815\n",
      "Loaded best model\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.35it/s]\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "PyHealthBiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1756, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.adam.Adam'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000002329A036E80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b97c3653cfd84c8087f8ef160b929a90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5246\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.67it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.2277\n",
      "roc_auc: 0.5261\n",
      "f1: 0.0000\n",
      "loss: 0.5235\n",
      "New best pr_auc score (0.2277) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c02dc5454024995838c9187dfdc8f76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.5150\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 55.56it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.2262\n",
      "roc_auc: 0.4935\n",
      "f1: 0.0000\n",
      "loss: 0.5183\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88918e99da1f4fac8c4d2e05d4db9d82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.5107\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 59.14it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.2288\n",
      "roc_auc: 0.4913\n",
      "f1: 0.0000\n",
      "loss: 0.5178\n",
      "New best pr_auc score (0.2288) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f801e5cd2cb74551b7a4b56896f615c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.5107\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.83it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.2381\n",
      "roc_auc: 0.5174\n",
      "f1: 0.0000\n",
      "loss: 0.5185\n",
      "New best pr_auc score (0.2381) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2f0b313f79640c89ea660e513e15102"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.5024\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 59.95it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.2274\n",
      "roc_auc: 0.4998\n",
      "f1: 0.0000\n",
      "loss: 0.5261\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "133839544ed54fc4b8b984da4a20c147"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.4998\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 59.62it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.2416\n",
      "roc_auc: 0.5224\n",
      "f1: 0.0263\n",
      "loss: 0.5243\n",
      "New best pr_auc score (0.2416) at epoch-5, step-1044\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92b3aad4fd484eedba8449c0e190fa2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.4898\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 60.11it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.2608\n",
      "roc_auc: 0.5376\n",
      "f1: 0.0506\n",
      "loss: 0.5357\n",
      "New best pr_auc score (0.2608) at epoch-6, step-1218\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85f623bacb40438587ce0d4ef82e53b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DxTx with interval embeddings\n",
    "\n",
    "for trial in range(N_TRIALS):\n",
    "\n",
    "    train, val, test = split_by_patient(dataset, [0.8, 0.1, 0.1])\n",
    "\n",
    "    train_loader = get_dataloader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = get_dataloader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = get_dataloader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = PyHealthBiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128,\n",
    "        n_mask_enc_layers=2\n",
    "    ).to(device)\n",
    "\n",
    "    y_true, y_prob, _ = train_and_inference(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        lr=0.001\n",
    "    )\n",
    "    binary_metrics = binary_metrics_fn(y_true, y_prob, metrics=[\"pr_auc\", \"roc_auc\", \"f1\"])\n",
    "\n",
    "\n",
    "    model = PyHealthBiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        embedding_dim=128,\n",
    "        n_mask_enc_layers=2\n",
    "    ).to(device)\n",
    "\n",
    "    y_true, y_prob, _ = train_and_inference(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        lr=0.001,\n",
    "        monitor=\"pr_auc_samples\",\n",
    "        optim=torch.optim.RMSprop\n",
    "    )\n",
    "    precisions = precision_at_k(y_true, y_prob)\n",
    "\n",
    "    data = binary_metrics | precisions\n",
    "    row = data | {\n",
    "        \"trial\": trial,\n",
    "        \"model_name\": \"bitenet\",\n",
    "        \"feature_set\": \"dxtx\"\n",
    "    }\n",
    "    row = {\n",
    "        k: [v] for k, v in row.items()\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame.from_dict(row)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  trial model_name feature_set    pr_auc   roc_auc        f1    5   10   15   \n",
      "0     0    bitenet        dxtx  0.395678  0.614033  0.294118  0.0  0.0  0.0  \\\n",
      "\n",
      "    20   25   30  \n",
      "0  0.0  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "print(metrics_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T17:44:54.417535Z",
     "end_time": "2023-05-03T17:44:54.439531Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.5145, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'y_prob': tensor([[0.1884],\n",
      "        [0.1629],\n",
      "        [0.1886],\n",
      "        [0.1886],\n",
      "        [0.1884],\n",
      "        [0.1884],\n",
      "        [0.1885],\n",
      "        [0.1884],\n",
      "        [0.1648],\n",
      "        [0.1885],\n",
      "        [0.1756],\n",
      "        [0.1885],\n",
      "        [0.1688],\n",
      "        [0.1632],\n",
      "        [0.1885],\n",
      "        [0.1885],\n",
      "        [0.1884],\n",
      "        [0.1885],\n",
      "        [0.9666],\n",
      "        [0.0794],\n",
      "        [0.1711],\n",
      "        [0.1885],\n",
      "        [0.1885],\n",
      "        [0.1885],\n",
      "        [0.1075],\n",
      "        [0.1883],\n",
      "        [0.1886],\n",
      "        [0.1884],\n",
      "        [0.1689],\n",
      "        [0.1884],\n",
      "        [0.2081],\n",
      "        [0.2081]], device='cuda:0', grad_fn=<SigmoidBackward0>), 'y_true': tensor([[1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [0.]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "data = next(iter(train_loader))\n",
    "print(model(**data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T23:17:42.394227Z",
     "end_time": "2023-05-02T23:17:42.438224Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyHealthBiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000205CDD7ECD0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c29a9f6189b4eff9342f650a1e23df3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5248\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 62.32it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.2094\n",
      "roc_auc: 0.4681\n",
      "f1: 0.0000\n",
      "loss: 0.5548\n",
      "New best pr_auc score (0.2094) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cebc42affc7f4302ab513ef1a1ddaa46"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.5188\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.97it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.2180\n",
      "roc_auc: 0.4851\n",
      "f1: 0.0000\n",
      "loss: 0.5712\n",
      "New best pr_auc score (0.2180) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bfcdb3f88dc4f1c9618f3787a4c240e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.5201\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 57.90it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.2476\n",
      "roc_auc: 0.5423\n",
      "f1: 0.0000\n",
      "loss: 0.5551\n",
      "New best pr_auc score (0.2476) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f9d30b0de674634b1487fd964ad82bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.5181\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 60.94it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.2368\n",
      "roc_auc: 0.4975\n",
      "f1: 0.0000\n",
      "loss: 0.5688\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f087403ea0249ce90f446207acd5499"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.5117\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 60.11it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.2617\n",
      "roc_auc: 0.5465\n",
      "f1: 0.0000\n",
      "loss: 0.5415\n",
      "New best pr_auc score (0.2617) at epoch-4, step-870\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53897e6d462a4790a5d242b6eec671e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.5022\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.97it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3836\n",
      "roc_auc: 0.5864\n",
      "f1: 0.2404\n",
      "loss: 0.5308\n",
      "New best pr_auc score (0.3836) at epoch-5, step-1044\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6392e4c84923479f84e12619b5b777e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.4880\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.28it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3905\n",
      "roc_auc: 0.5981\n",
      "f1: 0.2444\n",
      "loss: 0.5069\n",
      "New best pr_auc score (0.3905) at epoch-6, step-1218\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c0bcf2f8d5241de9e133e3973c3280b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.4819\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 62.86it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.4057\n",
      "roc_auc: 0.6100\n",
      "f1: 0.2637\n",
      "loss: 0.5065\n",
      "New best pr_auc score (0.4057) at epoch-7, step-1392\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8c6f88754fb4b06b82b5cccdedcd6db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.4715\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.80it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.4033\n",
      "roc_auc: 0.6140\n",
      "f1: 0.2500\n",
      "loss: 0.5142\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f26732296554e3ca12627bcad8929b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.4670\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.28it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.4023\n",
      "roc_auc: 0.6072\n",
      "f1: 0.2618\n",
      "loss: 0.5057\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 57.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.3521874464960856, 'roc_auc': 0.5945835982199618, 'f1': 0.19653179190751446, 'loss': 0.49657205966385926}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# DxTx without interval embeddings\n",
    "\n",
    "model = PyHealthBiteNet(\n",
    "    dataset = dataset,\n",
    "    feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "    label_key = \"readmission_label\",\n",
    "    mode = \"binary\",\n",
    "    n_interval_embeddings=max_patient_span_days,\n",
    "    embedding_dim=128,\n",
    "    n_mask_enc_layers=2\n",
    ").to(device)\n",
    "\n",
    "train_and_evaluate_readm(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.0001\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T15:06:14.841030Z",
     "end_time": "2023-05-01T15:07:30.391057Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': tensor(0.6983, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>), 'y_prob': tensor([[0.5025],\n",
      "        [0.5035],\n",
      "        [0.5022],\n",
      "        [0.5026],\n",
      "        [0.5046],\n",
      "        [0.5077],\n",
      "        [0.5033],\n",
      "        [0.5042],\n",
      "        [0.5040],\n",
      "        [0.5024],\n",
      "        [0.5042],\n",
      "        [0.5033],\n",
      "        [0.5024],\n",
      "        [0.5034],\n",
      "        [0.5037],\n",
      "        [0.5047],\n",
      "        [0.5036],\n",
      "        [0.5035],\n",
      "        [0.5042],\n",
      "        [0.5053],\n",
      "        [0.5039],\n",
      "        [0.5037],\n",
      "        [0.5060],\n",
      "        [0.5030],\n",
      "        [0.5043],\n",
      "        [0.5043],\n",
      "        [0.5046],\n",
      "        [0.5029],\n",
      "        [0.5031],\n",
      "        [0.5029],\n",
      "        [0.5070],\n",
      "        [0.5070]], device='cuda:0', grad_fn=<SigmoidBackward0>), 'y_true': tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "data = next(iter(train_loader))\n",
    "print(model(**data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T15:01:48.247642Z",
     "end_time": "2023-05-01T15:01:48.638640Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyHealthBiteNet(\n",
      "  (interval_embedding): Embedding(4221, 128)\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict(\n",
      "    (intervals): Linear(in_features=1, out_features=128, bias=True)\n",
      "  )\n",
      "  (bite_net): BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=465, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000205CDD7ECD0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using visit interval embeddings\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11fca249685c41f3b3d1fa8204fc88e6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.1735\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.82it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc_samples: 0.3058\n",
      "loss: 0.1235\n",
      "New best pr_auc_samples score (0.3058) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "781fda5adda644389b6b7bd900f65727"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.1225\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.67it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc_samples: 0.3082\n",
      "loss: 0.1216\n",
      "New best pr_auc_samples score (0.3082) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1ae7ca073dd64282b359bc951054fb58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.1202\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.36it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc_samples: 0.3119\n",
      "loss: 0.1198\n",
      "New best pr_auc_samples score (0.3119) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f74994d7c37c49138619eec4183d7bcc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.1188\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.82it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc_samples: 0.3177\n",
      "loss: 0.1179\n",
      "New best pr_auc_samples score (0.3177) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e356e8292bd439bb57ea8946d35aaa8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.1165\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.51it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc_samples: 0.3201\n",
      "loss: 0.1154\n",
      "New best pr_auc_samples score (0.3201) at epoch-4, step-870\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85d62979f9f04a4ea49bf6f964a53469"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.1143\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 59.95it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc_samples: 0.3244\n",
      "loss: 0.1127\n",
      "New best pr_auc_samples score (0.3244) at epoch-5, step-1044\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b425f9b1d624c509e1a70e4531754e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.1115\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 59.46it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc_samples: 0.3263\n",
      "loss: 0.1102\n",
      "New best pr_auc_samples score (0.3263) at epoch-6, step-1218\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13cb64f2b6004bc8a2eaa74708c27a15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.1088\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 59.95it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc_samples: 0.3295\n",
      "loss: 0.1075\n",
      "New best pr_auc_samples score (0.3295) at epoch-7, step-1392\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e56c03a5843145a79bff899c6a104092"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.1060\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.67it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc_samples: 0.3554\n",
      "loss: 0.1046\n",
      "New best pr_auc_samples score (0.3554) at epoch-8, step-1566\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12a8d2ec51c841a48fafc6f2cdda4465"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.1030\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.05it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc_samples: 0.3580\n",
      "loss: 0.1018\n",
      "New best pr_auc_samples score (0.3580) at epoch-9, step-1740\n",
      "Loaded best model\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 54.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc_samples': 0.3462034725410505, 'loss': 0.10405040837147018}\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_readm(\n",
    "    PyHealthBiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        n_interval_embeddings=max_patient_span_days,\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.0001,\n",
    "    monitor=\"pr_auc_samples\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:43:04.560967Z",
     "end_time": "2023-05-01T14:44:20.421971Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (rnn): ModuleDict(\n",
      "    (diagnoses): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "    (procedures): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000205CDD7ECD0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b868e9281394499e85ebb3c253d8fc5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.4974\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 149.66it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.4121\n",
      "roc_auc: 0.6199\n",
      "f1: 0.2500\n",
      "loss: 0.5142\n",
      "New best pr_auc score (0.4121) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a7c23dcda4e410196af0d7669ee3da4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.4109\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 158.27it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.4283\n",
      "roc_auc: 0.6278\n",
      "f1: 0.2500\n",
      "loss: 0.5245\n",
      "New best pr_auc score (0.4283) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "019e81ffd3bc49d6920a6c4179161b4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.3374\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 158.27it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.4144\n",
      "roc_auc: 0.6105\n",
      "f1: 0.2609\n",
      "loss: 0.5536\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21ade36e0b994c67963b2205686a5786"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.2528\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 154.93it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.4217\n",
      "roc_auc: 0.6113\n",
      "f1: 0.2586\n",
      "loss: 0.6107\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0f5594c8f754cf1a6a2b3b122515abe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.1814\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 151.73it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.3882\n",
      "roc_auc: 0.5719\n",
      "f1: 0.2661\n",
      "loss: 0.7234\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c97bc840b5449fe9c1148bb3a6dcbbd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.1266\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 153.85it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3974\n",
      "roc_auc: 0.5835\n",
      "f1: 0.3125\n",
      "loss: 0.7652\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bce165361489499d87103db1ea11585f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0886\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 151.73it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3971\n",
      "roc_auc: 0.5769\n",
      "f1: 0.2881\n",
      "loss: 0.8607\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73671374e4ca4a5281f3b700877527ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0617\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 150.69it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.4137\n",
      "roc_auc: 0.5971\n",
      "f1: 0.3083\n",
      "loss: 0.8973\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f145c4eade74fa08a248f9bd37a6dde"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0426\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 150.69it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.4145\n",
      "roc_auc: 0.5898\n",
      "f1: 0.3154\n",
      "loss: 1.0103\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e34c8c7fb84b4949bb6000b414333525"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0324\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 150.68it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.4106\n",
      "roc_auc: 0.5906\n",
      "f1: 0.3033\n",
      "loss: 1.1282\n",
      "Loaded best model\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 169.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.4088044614253502, 'roc_auc': 0.6401017164653529, 'f1': 0.2573099415204678, 'loss': 0.4801513755863363}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_readm(\n",
    "    RNN(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.001\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:44:29.781190Z",
     "end_time": "2023-05-01T14:44:55.682522Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (rnn): ModuleDict(\n",
      "    (diagnoses): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "    (procedures): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=465, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000205CDD7ECD0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70d851505acb4221b3538b98d81a1b63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.1068\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 165.42it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc_samples: 0.3980\n",
      "loss: 0.0834\n",
      "New best pr_auc_samples score (0.3980) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6bb1af43611d4834b0cb99eb68216a9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.0816\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 162.97it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc_samples: 0.4224\n",
      "loss: 0.0797\n",
      "New best pr_auc_samples score (0.4224) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c93bfa0426646b2bb4790264c4c4e09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.0780\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 134.15it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc_samples: 0.4421\n",
      "loss: 0.0778\n",
      "New best pr_auc_samples score (0.4421) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "867186cfa8b047c48405d06dcd5edffe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.0752\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 130.18it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc_samples: 0.4508\n",
      "loss: 0.0767\n",
      "New best pr_auc_samples score (0.4508) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35f5847feabe496396c4b82be687a7dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0730\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 148.65it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc_samples: 0.4543\n",
      "loss: 0.0768\n",
      "New best pr_auc_samples score (0.4543) at epoch-4, step-870\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21aea2bee16542edbfc3051c6c603734"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0708\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 134.97it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc_samples: 0.4601\n",
      "loss: 0.0762\n",
      "New best pr_auc_samples score (0.4601) at epoch-5, step-1044\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c2dc186cc494dfa8aac5d5631d5d9dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0690\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 135.80it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc_samples: 0.4616\n",
      "loss: 0.0762\n",
      "New best pr_auc_samples score (0.4616) at epoch-6, step-1218\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50a5042c7d2f4be3abad420b108f3ba8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0673\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 141.03it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc_samples: 0.4633\n",
      "loss: 0.0764\n",
      "New best pr_auc_samples score (0.4633) at epoch-7, step-1392\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c091661d7424dceabe503affabb8847"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0657\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 136.65it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc_samples: 0.4635\n",
      "loss: 0.0766\n",
      "New best pr_auc_samples score (0.4635) at epoch-8, step-1566\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1cda87343e245f3b8e596ab1533353f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0642\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 131.74it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc_samples: 0.4627\n",
      "loss: 0.0771\n",
      "Loaded best model\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 144.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc_samples': 0.4410093371163336, 'loss': 0.08005004884167151}\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_readm(\n",
    "    RNN(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.001,\n",
    "    monitor=\"pr_auc_samples\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T14:45:21.292086Z",
     "end_time": "2023-05-01T14:45:49.566140Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (retain): ModuleDict(\n",
      "    (diagnoses): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (procedures): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000211A794E700>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da114fef9a3741ed93305ae321406ec4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5355\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 84.29it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.3553\n",
      "roc_auc: 0.5890\n",
      "f1: 0.1775\n",
      "loss: 0.5163\n",
      "New best pr_auc score (0.3553) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19ab54a5c3d24e64a00ce07a0a1fc3d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.3683\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 80.88it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.3871\n",
      "roc_auc: 0.6180\n",
      "f1: 0.2737\n",
      "loss: 0.5194\n",
      "New best pr_auc score (0.3871) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b8653603baa45198d9d87e5b46c6850"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.2285\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 77.19it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.3715\n",
      "roc_auc: 0.6024\n",
      "f1: 0.2526\n",
      "loss: 0.6153\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "636f0e32c1b8480398726c1d5f797817"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.1225\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 78.01it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.3835\n",
      "roc_auc: 0.5939\n",
      "f1: 0.3097\n",
      "loss: 0.6973\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "622878b58c6c49679eb914c3363eb6ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0688\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 79.42it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.3848\n",
      "roc_auc: 0.6013\n",
      "f1: 0.3117\n",
      "loss: 0.8054\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "044414be83e64fee887417ac1bad62f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0419\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 76.39it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3802\n",
      "roc_auc: 0.5960\n",
      "f1: 0.3084\n",
      "loss: 0.9247\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64d18c3bb15e4d83a949b36fb72ad5dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0313\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 80.29it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3778\n",
      "roc_auc: 0.6086\n",
      "f1: 0.3070\n",
      "loss: 0.9865\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dec59a7cbdc547518aa36f45093dcbf5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0186\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 79.71it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.3776\n",
      "roc_auc: 0.5983\n",
      "f1: 0.2857\n",
      "loss: 1.1027\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31f1037a0d4c435a8f0a2cd7ba1e9f40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0181\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 73.83it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.3936\n",
      "roc_auc: 0.6030\n",
      "f1: 0.3004\n",
      "loss: 1.1505\n",
      "New best pr_auc score (0.3936) at epoch-8, step-1566\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f4e9978d31c40aeb47ffbeea1d37c56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0158\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 78.29it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.3926\n",
      "roc_auc: 0.6023\n",
      "f1: 0.3064\n",
      "loss: 1.2158\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 82.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.3606033694496517, 'roc_auc': 0.5797932330827067, 'f1': 0.29729729729729726, 'loss': 1.2300627353516491}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_readm(\n",
    "    RETAIN(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:47:49.609222Z",
     "end_time": "2023-04-29T20:48:50.110635Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (retain): ModuleDict(\n",
      "    (diagnoses): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (procedures): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=465, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000001D43AC050D0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "046e1807c8044323bb31990dae349a3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.1180\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 81.18it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc_samples: 0.4010\n",
      "loss: 0.0930\n",
      "New best pr_auc_samples score (0.4010) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cadfd5cc17cb4e77925cb5899192268b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.0811\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 75.34it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc_samples: 0.4227\n",
      "loss: 0.0878\n",
      "New best pr_auc_samples score (0.4227) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eda4c62150344aef9effe0f1e9b02501"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.0747\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 70.29it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc_samples: 0.4304\n",
      "loss: 0.0862\n",
      "New best pr_auc_samples score (0.4304) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47dd6ba8186444feab1709c95224f5b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.0707\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 78.57it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc_samples: 0.4357\n",
      "loss: 0.0863\n",
      "New best pr_auc_samples score (0.4357) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9714af985065472d9c8ad30e614b2a3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0674\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 78.02it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc_samples: 0.4313\n",
      "loss: 0.0869\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a0e4757047944a8bd428e53d3a6114b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0648\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 77.74it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc_samples: 0.4356\n",
      "loss: 0.0875\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9350379029144084b5b36101e026d53c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0626\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 67.69it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc_samples: 0.4325\n",
      "loss: 0.0880\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "042c1af7f7a94992b5056cb68e2bc141"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0604\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 76.39it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc_samples: 0.4332\n",
      "loss: 0.0890\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbda2fc3abb9447ea4357744d47999c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0586\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 76.66it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc_samples: 0.4300\n",
      "loss: 0.0904\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54c3665d2f914bf4a8e49d42f931893c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0569\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 80.88it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc_samples: 0.4272\n",
      "loss: 0.0914\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 68.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc_samples': 0.4249831201075734, 'loss': 0.09086060625585643}\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_readm(\n",
    "    RETAIN(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.001,\n",
    "    monitor=\"pr_auc_samples\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:51:14.489202Z",
     "end_time": "2023-05-01T00:52:22.434249Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3375, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1363, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (cnn): ModuleDict(\n",
      "    (diagnoses): DeeprLayer(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "    )\n",
      "    (procedures): DeeprLayer(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000211A794E700>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "673342986c5e4c0295bf0e0ec5b994b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5101\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 183.33it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.4078\n",
      "roc_auc: 0.6345\n",
      "f1: 0.1863\n",
      "loss: 0.4984\n",
      "New best pr_auc score (0.4078) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "464186425d54491c8f1885b8f5649a78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.3764\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 268.29it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.4154\n",
      "roc_auc: 0.6332\n",
      "f1: 0.2755\n",
      "loss: 0.4897\n",
      "New best pr_auc score (0.4154) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41e917c3f5fa498f8212a0856e712d81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.2655\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 258.82it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.3905\n",
      "roc_auc: 0.6049\n",
      "f1: 0.3258\n",
      "loss: 0.5340\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da8179e0bf92441c88515e0c8f16028a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.1544\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 249.96it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.4250\n",
      "roc_auc: 0.6310\n",
      "f1: 0.3577\n",
      "loss: 0.5696\n",
      "New best pr_auc score (0.4250) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a553e71e82b34f9fb80bc9ad954bb79a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0791\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 244.44it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.3979\n",
      "roc_auc: 0.6118\n",
      "f1: 0.2922\n",
      "loss: 0.6220\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7da574cacc34ac7a662d3c5e38123da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0389\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 261.87it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3990\n",
      "roc_auc: 0.6011\n",
      "f1: 0.2842\n",
      "loss: 0.7871\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec6ddf3d75c0469caaebae5e4ff2a3b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0175\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 255.79it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3948\n",
      "roc_auc: 0.6088\n",
      "f1: 0.2737\n",
      "loss: 0.8633\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "352248d3b17446648e1e80119d035c39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0168\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 255.82it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.4105\n",
      "roc_auc: 0.6164\n",
      "f1: 0.2932\n",
      "loss: 0.9251\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25cad53f6c2d4a05befd0155688da302"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0055\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 255.81it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.3957\n",
      "roc_auc: 0.6097\n",
      "f1: 0.3136\n",
      "loss: 0.8593\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91dfe39e991e4f45a2cad324ee804bd3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0027\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 252.87it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.4183\n",
      "roc_auc: 0.6189\n",
      "f1: 0.3349\n",
      "loss: 0.9303\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 224.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.39479580130583247, 'roc_auc': 0.6421455424274973, 'f1': 0.303030303030303, 'loss': 0.8376922133294019}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_readm(\n",
    "    Deepr(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:49:23.296202Z",
     "end_time": "2023-04-29T20:49:36.578089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
