{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Library imports and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:56:33.092446Z",
     "end_time": "2023-05-03T22:56:35.370438Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\pyhealth\\trainer.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "# ! pip install pyhealth\n",
    "from pyhealth.datasets import MIMIC3Dataset\n",
    "from pyhealth.data import Patient, Visit, Event\n",
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.medcode import InnerMap\n",
    "from tqdm import tqdm\n",
    "from pyhealth.metrics.binary import binary_metrics_fn\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bitenet import BiteNet\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "# Set this to the directory with all MIMIC-3 dataset files\n",
    "data_root = \"data\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-VgeMdJDYYK",
    "outputId": "9cb9c08a-9003-4836-a3b2-a23e7cd45b55",
    "ExecuteTime": {
     "start_time": "2023-05-03T22:56:35.372439Z",
     "end_time": "2023-05-03T22:56:38.856416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "mimic3_ds = MIMIC3Dataset(\n",
    "        root=data_root,\n",
    "        tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\"],\n",
    "        dev=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "HQdeU1TLU6m_",
    "outputId": "590623d6-2917-4155-bf0a-5d75a3979c25",
    "ExecuteTime": {
     "start_time": "2023-05-03T22:56:38.858419Z",
     "end_time": "2023-05-03T22:56:39.060417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 46520\n",
      "\t- Number of visits: 58976\n",
      "\t- Number of visits per patient: 1.2678\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0711\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 46520\\n\\t- Number of visits: 58976\\n\\t- Number of visits per patient: 1.2678\\n\\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0711\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataset statistics\n",
    "\n",
    "mimic3_ds.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Find all diagnoses codes\n",
    "# Remove diagnoses codes with fewer than 5 occurences in the dataset\n",
    "\n",
    "all_diagnosis_codes = []\n",
    "for patient_id, patient in mimic3_ds.patients.items():\n",
    "  for i in range(len(patient)):\n",
    "    visit: Visit = patient[i]\n",
    "    conditions = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "    all_diagnosis_codes.extend(conditions)\n",
    "\n",
    "codes = pd.Series(all_diagnosis_codes)\n",
    "diag_code_counts = codes.value_counts()\n",
    "filtered_diag_codes = diag_code_counts[diag_code_counts > 4].index.values\n",
    "n_unique_diag_codes = len(filtered_diag_codes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:56:40.260476Z",
     "end_time": "2023-05-03T22:56:40.756474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46520/46520 [01:13<00:00, 635.62it/s]\n"
     ]
    }
   ],
   "source": [
    "MIN_N_VISITS_PER_PATIENT = 2\n",
    "\n",
    "# Filter Dataset to requirements specified in paper\n",
    "\n",
    "filtered_patients = {}\n",
    "for patient_id, patient in tqdm(mimic3_ds.patients.items()):\n",
    "\n",
    "    filtered_patient: Patient = Patient(\n",
    "        patient_id=patient.patient_id,\n",
    "        birth_datetime=patient.birth_datetime,\n",
    "        death_datetime=patient.death_datetime,\n",
    "        gender=patient.gender,\n",
    "        ethnicity=patient.ethnicity\n",
    "    )\n",
    "\n",
    "    for i_visit, visit in enumerate(patient):\n",
    "        filtered_visit: Visit = Visit(\n",
    "            visit_id=visit.visit_id,\n",
    "            patient_id=visit.patient_id,\n",
    "            encounter_time=visit.encounter_time,\n",
    "            discharge_time=visit.discharge_time,\n",
    "            discharge_status=visit.discharge_status\n",
    "        )\n",
    "\n",
    "        diagnoses_codes = visit.get_code_list(\"DIAGNOSES_ICD\")\n",
    "        procedures_codes = visit.get_code_list(\"PROCEDURES_ICD\")\n",
    "        prescriptions_codes = visit.get_code_list(\"PRESCRIPTIONS\")\n",
    "\n",
    "        if len(diagnoses_codes) > 0:\n",
    "            diagnosis_events = visit.event_list_dict[\"DIAGNOSES_ICD\"]\n",
    "            for i_event in range(len(diagnosis_events) - 1, -1, -1):\n",
    "                event: Event = diagnosis_events[i_event]\n",
    "                if event.code not in filtered_diag_codes:\n",
    "                    diagnosis_events.pop(i_event) # Remove the diagnosis code with fewer than the cutoff occurrences\n",
    "\n",
    "            if len(diagnosis_events) == 0: continue # Don't include visits with no diagnoses\n",
    "\n",
    "            filtered_visit.set_event_list(\"DIAGNOSES_ICD\", diagnosis_events)\n",
    "        else:\n",
    "            continue # Don't include visits with no diagnoses\n",
    "\n",
    "        if len(procedures_codes) > 0:\n",
    "           filtered_visit.set_event_list(\"PROCEDURES_ICD\", visit.event_list_dict[\"PROCEDURES_ICD\"])\n",
    "\n",
    "        if len(prescriptions_codes) > 0:\n",
    "            filtered_visit.set_event_list(\"PRESCRIPTIONS\", visit.event_list_dict[\"PRESCRIPTIONS\"])\n",
    "\n",
    "        filtered_patient.add_visit(filtered_visit)\n",
    "\n",
    "    if len(filtered_patient.visits) >= MIN_N_VISITS_PER_PATIENT:\n",
    "        filtered_patients[patient_id] = filtered_patient\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:56:40.788476Z",
     "end_time": "2023-05-03T22:57:53.995154Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 7496\n",
      "\t- Number of visits: 19905\n",
      "\t- Number of visits per patient: 2.6554\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0975\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 7496\\n\\t- Number of visits: 19905\\n\\t- Number of visits per patient: 2.6554\\n\\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0975\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic3_ds.patients = filtered_patients\n",
    "mimic3_ds.stat()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:57:58.153493Z",
     "end_time": "2023-05-03T22:57:58.359511Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# # Get the dataset span for encoding visit intervals\n",
    "# # The lookup table for interval encoding will be of dimensions mxd,\n",
    "# # where m is the length of the dataset span and d is the embedding\n",
    "# # dimension. The lookup table needs to be as large as the dataset\n",
    "# # time span because it could be possible for a patient to have his/her\n",
    "# # first visit on the earliest day in the dataset and the last visit on\n",
    "# # the latest day in the dataset. Thus, the index for this patient's visit\n",
    "# # interval would be (last_visit.time - first_visit.time).days = m = dataset span.\n",
    "#\n",
    "# max_patient_span_days: int = 0\n",
    "#\n",
    "# for patient_id, patient in tqdm(mimic3_ds.patients.items()):\n",
    "#\n",
    "#     sorted_visits = sorted(patient, key=lambda v: v.encounter_time)\n",
    "#     patient_span_days = (sorted_visits[-1].encounter_time - sorted_visits[0].encounter_time).days\n",
    "#     if patient_span_days > max_patient_span_days:\n",
    "#         max_patient_span_days = patient_span_days\n",
    "#\n",
    "# print(f\"Max span (days) of a single patient's visits: {max_patient_span_days}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:58:00.234414Z",
     "end_time": "2023-05-03T22:58:00.259293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fgrnO7KkWDBY",
    "ExecuteTime": {
     "start_time": "2023-05-03T22:58:01.501456Z",
     "end_time": "2023-05-03T22:58:01.540456Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the tasks\n",
    "\n",
    "DIAGNOSES_KEY = \"conditions\"\n",
    "PROCEDURES_KEY = \"procedures\"\n",
    "INTERVAL_DAYS_KEY = \"days_since_first_visit\"\n",
    "\n",
    "icd9cm = InnerMap.load(\"ICD9CM\")\n",
    "\n",
    "def flatten(l: List):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def patient_level_readmission_prediction(patient, time_window: int = 30, max_length_visits: int = None):\n",
    "    \"\"\"\n",
    "    patient is a <pyhealth.data.Patient> object\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    sorted_visits = sorted(patient, key=lambda visit: visit.encounter_time)\n",
    "\n",
    "    # Clip the patient visits to the most recent max_length_visits + 1 if max_length_visits is not None\n",
    "    if max_length_visits is not None:\n",
    "        n_visits = len(sorted_visits)\n",
    "        if n_visits > max_length_visits + 1:\n",
    "            sorted_visits = sorted_visits[n_visits - (max_length_visits + 1):]\n",
    "\n",
    "    feature_visits: List[Visit] = sorted_visits[:-1]\n",
    "    last_visit: Visit = sorted_visits[-1]\n",
    "    second_to_last_visit: Visit = feature_visits[-1]\n",
    "    first_visit: Visit = feature_visits[0]\n",
    "\n",
    "    # step 1 a: define readmission label\n",
    "    time_diff = (last_visit.encounter_time - second_to_last_visit.encounter_time).days\n",
    "    readmission_label = 1 if time_diff <= time_window else 0\n",
    "\n",
    "    # step 1 b: define diagnosis prediction label\n",
    "    diagnosis_label = list(set([icd9cm.get_ancestors(code)[1] for code in last_visit.get_code_list(\"DIAGNOSES_ICD\")]))\n",
    "\n",
    "    # step 2: obtain features\n",
    "    visits_diagnoses = []\n",
    "    visits_procedures = []\n",
    "    visits_intervals = []\n",
    "    for idx, visit in enumerate(feature_visits):\n",
    "        diagnoses = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "        procedures = visit.get_code_list(table=\"PROCEDURES_ICD\")\n",
    "        time_diff_from_first_visit = (visit.encounter_time - first_visit.encounter_time).days\n",
    "\n",
    "        # Exclude visits that are missing either diagnoses or procedures.\n",
    "        # BiteNet can handle missing procedures, but other PyHealth models like RNN\n",
    "        # require all features have a length greater than 0.\n",
    "        if len(diagnoses) == 0:\n",
    "            continue\n",
    "\n",
    "        visits_diagnoses.append(diagnoses)\n",
    "        visits_procedures.append(procedures)\n",
    "        visits_intervals.append([str(time_diff_from_first_visit)])\n",
    "\n",
    "    unique_diagnoses = list(set(flatten(visits_diagnoses)))\n",
    "\n",
    "    # step 3: exclusion criteria\n",
    "    if len(unique_diagnoses) == 0:\n",
    "        return []\n",
    "\n",
    "    # step 4: assemble the sample\n",
    "    samples.append(\n",
    "        {\n",
    "            \"patient_id\": patient.patient_id,\n",
    "            \"visit_id\": visit.visit_id,\n",
    "            \"diagnoses\": visits_diagnoses,\n",
    "            \"procedures\": visits_procedures,\n",
    "            \"intervals\": visits_intervals,\n",
    "            \"readmission_label\": readmission_label,\n",
    "            \"diagnosis_label\": diagnosis_label\n",
    "        }\n",
    "    )\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "KS = list(range(5, 31, 5))\n",
    "# N_TRIALS = 10\n",
    "SEQ_LENS = list(range(6, 17, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:58:02.161431Z",
     "end_time": "2023-05-03T22:58:02.183429Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def train_and_inference(model, train_loader, val_loader, test_loader, lr=0.001, monitor=\"pr_auc\", optim = torch.optim.RMSprop):\n",
    "    trainer = Trainer(model=model, device=device)\n",
    "    trainer.train(\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        epochs=10,\n",
    "        monitor=monitor,\n",
    "        optimizer_class=optim,\n",
    "        optimizer_params = {\"lr\" : lr},\n",
    "        load_best_model_at_last=False\n",
    "    )\n",
    "\n",
    "    return trainer.inference(test_loader)\n",
    "\n",
    "def precision_at_k(Y_true, Y_prob):\n",
    "\n",
    "    Y_pred = (Y_prob > 0.5).astype(int)\n",
    "    desc_idx = np.flip(np.argsort(Y_prob, axis=-1), axis=-1)\n",
    "\n",
    "    Y_true = np.take(Y_true, desc_idx)\n",
    "    Y_pred = np.take(Y_pred, desc_idx)\n",
    "\n",
    "    precisions = [\n",
    "        [\n",
    "            precision_score(y_true_sample[:k], y_pred_sample[:k])\n",
    "            for y_true_sample, y_pred_sample in zip(Y_true, Y_pred)\n",
    "        ]\n",
    "        for k in KS\n",
    "    ]\n",
    "\n",
    "    precisions = np.asarray(precisions)\n",
    "    precisions = np.mean(precisions, axis=1)\n",
    "    precisions = {\n",
    "        str(k): p for k, p in zip(KS, precisions.tolist())\n",
    "    }\n",
    "    return precisions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:58:05.948199Z",
     "end_time": "2023-05-03T22:58:05.971712Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:58:06.489863Z",
     "end_time": "2023-05-03T22:58:06.521885Z"
    }
   },
   "outputs": [],
   "source": [
    "# DxTx with interval embeddings\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=['model_name', 'feature_set', 'seq_len', 'pr_auc', 'roc_auc', 'f1', '5', '10', '15', '20', '25', '30'])\n",
    "\n",
    "def train_and_record_metrics(model_readm, model_diag, model_name, feature_set, seq_len, train_loader, val_loader, test_loader):\n",
    "    global metrics_df\n",
    "\n",
    "    y_true, y_prob, _ = train_and_inference(\n",
    "        model_readm,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        lr=0.001\n",
    "    )\n",
    "    binary_metrics = binary_metrics_fn(y_true, y_prob, metrics=[\"pr_auc\", \"roc_auc\", \"f1\"])\n",
    "\n",
    "    y_true, y_prob, _ = train_and_inference(\n",
    "        model_diag,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        lr=0.001,\n",
    "        monitor=\"pr_auc_samples\",\n",
    "        optim=torch.optim.RMSprop\n",
    "    )\n",
    "    precisions = precision_at_k(y_true, y_prob)\n",
    "\n",
    "    row = binary_metrics | precisions | {\n",
    "        \"model_name\": model_name,\n",
    "        \"feature_set\": feature_set,\n",
    "        \"seq_len\": seq_len\n",
    "    }\n",
    "    row = {\n",
    "        k: [v] for k, v in row.items()\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame.from_dict(row)], ignore_index=True)\n",
    "\n",
    "    # Save df for checkpoint\n",
    "    metrics_df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000023D4DF5ADC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5371\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2221\n",
      "roc_auc: 0.5331\n",
      "f1: 0.0000\n",
      "loss: 0.5548\n",
      "New best pr_auc score (0.2221) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.5167\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.2449\n",
      "roc_auc: 0.5508\n",
      "f1: 0.0000\n",
      "loss: 0.5652\n",
      "New best pr_auc score (0.2449) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4856\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3638\n",
      "roc_auc: 0.5714\n",
      "f1: 0.2316\n",
      "loss: 0.4933\n",
      "New best pr_auc score (0.3638) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4466\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3553\n",
      "roc_auc: 0.5542\n",
      "f1: 0.2280\n",
      "loss: 0.5045\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.4047\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3723\n",
      "roc_auc: 0.5794\n",
      "f1: 0.2383\n",
      "loss: 0.5327\n",
      "New best pr_auc score (0.3723) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.3559\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3597\n",
      "roc_auc: 0.5585\n",
      "f1: 0.2475\n",
      "loss: 0.5487\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.3136\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3411\n",
      "roc_auc: 0.5385\n",
      "f1: 0.2255\n",
      "loss: 0.7520\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.2820\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3319\n",
      "roc_auc: 0.5261\n",
      "f1: 0.2329\n",
      "loss: 0.8002\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.2599\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3523\n",
      "roc_auc: 0.5571\n",
      "f1: 0.2460\n",
      "loss: 0.7387\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.2331\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3238\n",
      "roc_auc: 0.5421\n",
      "f1: 0.2403\n",
      "loss: 0.9335\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000023D4DF5ADC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1082\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3167\n",
      "loss: 0.0914\n",
      "New best pr_auc_samples score (0.3167) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0867\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3399\n",
      "loss: 0.0859\n",
      "New best pr_auc_samples score (0.3399) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0839\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3680\n",
      "loss: 0.0841\n",
      "New best pr_auc_samples score (0.3680) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0820\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.3796\n",
      "loss: 0.0823\n",
      "New best pr_auc_samples score (0.3796) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0808\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.3820\n",
      "loss: 0.0819\n",
      "New best pr_auc_samples score (0.3820) at epoch-4, step-940\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from rnn import RNN\n",
    "from retain import RETAIN\n",
    "from deepr import Deepr\n",
    "\n",
    "for seq_len in SEQ_LENS:\n",
    "\n",
    "    dataset = mimic3_ds.set_task(\n",
    "        task_fn=lambda p: patient_level_readmission_prediction(p, max_length_visits=seq_len)\n",
    "    )\n",
    "    train, val, test = split_by_patient(dataset, [0.8, 0.1, 0.1])\n",
    "\n",
    "    train_loader = get_dataloader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = get_dataloader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = get_dataloader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    #################### BITENET ####################\n",
    "    train_and_record_metrics(\n",
    "        model_readm=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\",\n",
    "        ).to(device),\n",
    "        model_diag=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\",\n",
    "        ).to(device),\n",
    "        model_name=\"bitenet\",\n",
    "        feature_set=\"dxtx\",\n",
    "        seq_len=seq_len,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader\n",
    "    )\n",
    "\n",
    "    train_and_record_metrics(\n",
    "        model_readm=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\",\n",
    "        ).to(device),\n",
    "        model_diag=BiteNet(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\",\n",
    "        ).to(device),\n",
    "        model_name=\"bitenet\",\n",
    "        feature_set=\"dx\",\n",
    "        seq_len=seq_len,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader\n",
    "    )\n",
    "\n",
    "    #################### RNN ####################\n",
    "    train_and_record_metrics(\n",
    "            model_readm=RNN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\",\n",
    "        ).to(device),\n",
    "        model_diag=RNN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\",\n",
    "        ).to(device),\n",
    "        model_name=\"rnn\",\n",
    "        feature_set=\"dxtx\",\n",
    "        seq_len=seq_len,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader\n",
    "    )\n",
    "\n",
    "    train_and_record_metrics(\n",
    "            model_readm=RNN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\",\n",
    "        ).to(device),\n",
    "        model_diag=RNN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\",\n",
    "        ).to(device),\n",
    "        model_name=\"rnn\",\n",
    "        feature_set=\"dx\",\n",
    "        seq_len=seq_len,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader\n",
    "    )\n",
    "\n",
    "    #################### BRNN ####################\n",
    "    train_and_record_metrics(\n",
    "            model_readm=RNN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\",\n",
    "            bidirectional=True\n",
    "        ).to(device),\n",
    "        model_diag=RNN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\",\n",
    "            bidirectional=True\n",
    "        ).to(device),\n",
    "        model_name=\"brnn\",\n",
    "        feature_set=\"dxtx\",\n",
    "        seq_len=seq_len,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader\n",
    "    )\n",
    "\n",
    "    train_and_record_metrics(\n",
    "            model_readm=RNN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\",\n",
    "            bidirectional=True\n",
    "        ).to(device),\n",
    "        model_diag=RNN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\",\n",
    "            bidirectional=True\n",
    "        ).to(device),\n",
    "        model_name=\"brnn\",\n",
    "        feature_set=\"dx\",\n",
    "        seq_len=seq_len,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader\n",
    "    )\n",
    "\n",
    "    #################### RETAIN ####################\n",
    "    train_and_record_metrics(\n",
    "            model_readm=RETAIN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\"\n",
    "        ).to(device),\n",
    "        model_diag=RETAIN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\"\n",
    "        ).to(device),\n",
    "        model_name=\"retain\",\n",
    "        feature_set=\"dxtx\",\n",
    "        seq_len=seq_len,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader\n",
    "    )\n",
    "\n",
    "    train_and_record_metrics(\n",
    "            model_readm=RETAIN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\"],\n",
    "            label_key = \"readmission_label\",\n",
    "            mode = \"binary\"\n",
    "        ).to(device),\n",
    "        model_diag=RETAIN(\n",
    "            dataset = dataset,\n",
    "            feature_keys = [\"diagnoses\"],\n",
    "            label_key = \"diagnosis_label\",\n",
    "            mode = \"multilabel\"\n",
    "        ).to(device),\n",
    "        model_name=\"retain\",\n",
    "        feature_set=\"dx\",\n",
    "        seq_len=seq_len,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        test_loader=test_loader\n",
    "    )\n",
    "\n",
    "    # #################### Deepr ####################\n",
    "    # train_and_record_metrics(\n",
    "    #         model_readm=Deepr(\n",
    "    #         dataset = dataset,\n",
    "    #         feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "    #         label_key = \"readmission_label\",\n",
    "    #         mode = \"binary\"\n",
    "    #     ).to(device),\n",
    "    #     model_diag=Deepr(\n",
    "    #         dataset = dataset,\n",
    "    #         feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "    #         label_key = \"diagnosis_label\",\n",
    "    #         mode = \"multilabel\"\n",
    "    #     ).to(device),\n",
    "    #     model_name=\"deepr\",\n",
    "    #     feature_set=\"dxtx\",\n",
    "    #     seq_len=seq_len,\n",
    "    #     train_loader=train_loader,\n",
    "    #     val_loader=val_loader,\n",
    "    #     test_loader=test_loader\n",
    "    # )\n",
    "    #\n",
    "    # train_and_record_metrics(\n",
    "    #         model_readm=Deepr(\n",
    "    #         dataset = dataset,\n",
    "    #         feature_keys = [\"diagnoses\"],\n",
    "    #         label_key = \"readmission_label\",\n",
    "    #         mode = \"binary\"\n",
    "    #     ).to(device),\n",
    "    #     model_diag=Deepr(\n",
    "    #         dataset = dataset,\n",
    "    #         feature_keys = [\"diagnoses\"],\n",
    "    #         label_key = \"diagnosis_label\",\n",
    "    #         mode = \"multilabel\"\n",
    "    #     ).to(device),\n",
    "    #     model_name=\"deepr\",\n",
    "    #     feature_set=\"dx\",\n",
    "    #     seq_len=seq_len,\n",
    "    #     train_loader=train_loader,\n",
    "    #     val_loader=val_loader,\n",
    "    #     test_loader=test_loader\n",
    "    # )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T22:53:17.642271Z",
     "end_time": "2023-05-03T22:53:23.533806Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "print(metrics_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-03T18:47:15.418650Z",
     "end_time": "2023-05-03T18:47:15.418650Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
