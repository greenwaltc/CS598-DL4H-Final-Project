{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Library imports and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:35:15.509201Z",
     "end_time": "2023-05-01T00:35:15.530200Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install pyhealth\n",
    "from pyhealth.datasets import MIMIC3Dataset, SampleDataset\n",
    "from pyhealth.data import Patient, Visit, Event\n",
    "import pandas as pd\n",
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "from pyhealth.models import BaseModel, RNN, RETAIN, Deepr\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.medcode import InnerMap\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Dict, Optional\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Set this to the directory with all MIMIC-3 dataset files\n",
    "data_root = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-VgeMdJDYYK",
    "outputId": "9cb9c08a-9003-4836-a3b2-a23e7cd45b55",
    "ExecuteTime": {
     "start_time": "2023-05-01T00:20:43.728297Z",
     "end_time": "2023-05-01T00:21:01.995301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "mimic3_ds = MIMIC3Dataset(\n",
    "        root=data_root,\n",
    "        tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\", \"PRESCRIPTIONS\"],\n",
    "        dev=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "HQdeU1TLU6m_",
    "outputId": "590623d6-2917-4155-bf0a-5d75a3979c25",
    "ExecuteTime": {
     "start_time": "2023-05-01T00:21:04.974202Z",
     "end_time": "2023-05-01T00:21:05.278200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 46520\n",
      "\t- Number of visits: 58976\n",
      "\t- Number of visits per patient: 1.2678\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0711\n",
      "\t- Number of events per visit in PRESCRIPTIONS: 70.4013\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 46520\\n\\t- Number of visits: 58976\\n\\t- Number of visits per patient: 1.2678\\n\\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0711\\n\\t- Number of events per visit in PRESCRIPTIONS: 70.4013\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataset statistics\n",
    "\n",
    "mimic3_ds.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Find all diagnoses codes\n",
    "# Remove diagnoses codes with fewer than 5 occurences in the dataset\n",
    "\n",
    "all_diagnosis_codes = []\n",
    "for patient_id, patient in mimic3_ds.patients.items():\n",
    "  for i in range(len(patient)):\n",
    "    visit: Visit = patient[i]\n",
    "    conditions = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "    all_diagnosis_codes.extend(conditions)\n",
    "\n",
    "codes = pd.Series(all_diagnosis_codes)\n",
    "diag_code_counts = codes.value_counts()\n",
    "filtered_diag_codes = diag_code_counts[diag_code_counts > 4].index.values\n",
    "num_unique_diag_codes = len(filtered_diag_codes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:21:08.828964Z",
     "end_time": "2023-05-01T00:21:09.504959Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46520/46520 [01:17<00:00, 597.46it/s]\n"
     ]
    }
   ],
   "source": [
    "MIN_NUM_VISITS_PER_PATIENT = 2\n",
    "\n",
    "# Filter Dataset to requirements specified in paper\n",
    "\n",
    "filtered_patients = {}\n",
    "for patient_id, patient in tqdm(mimic3_ds.patients.items()):\n",
    "\n",
    "    filtered_patient: Patient = Patient(\n",
    "        patient_id=patient.patient_id,\n",
    "        birth_datetime=patient.birth_datetime,\n",
    "        death_datetime=patient.death_datetime,\n",
    "        gender=patient.gender,\n",
    "        ethnicity=patient.ethnicity\n",
    "    )\n",
    "\n",
    "    for i_visit, visit in enumerate(patient):\n",
    "        filtered_visit: Visit = Visit(\n",
    "            visit_id=visit.visit_id,\n",
    "            patient_id=visit.patient_id,\n",
    "            encounter_time=visit.encounter_time,\n",
    "            discharge_time=visit.discharge_time,\n",
    "            discharge_status=visit.discharge_status\n",
    "        )\n",
    "\n",
    "        diagnoses_codes = visit.get_code_list(\"DIAGNOSES_ICD\")\n",
    "        procedures_codes = visit.get_code_list(\"PROCEDURES_ICD\")\n",
    "        prescriptions_codes = visit.get_code_list(\"PRESCRIPTIONS\")\n",
    "\n",
    "        if len(diagnoses_codes) > 0:\n",
    "            diagnosis_events = visit.event_list_dict[\"DIAGNOSES_ICD\"]\n",
    "            for i_event in range(len(diagnosis_events) - 1, -1, -1):\n",
    "                event: Event = diagnosis_events[i_event]\n",
    "                if event.code not in filtered_diag_codes:\n",
    "                    diagnosis_events.pop(i_event) # Remove the diagnosis code with fewer than the cutoff occurrences\n",
    "\n",
    "            if len(diagnosis_events) == 0: continue # Don't include visits with no diagnoses\n",
    "\n",
    "            filtered_visit.set_event_list(\"DIAGNOSES_ICD\", diagnosis_events)\n",
    "        else:\n",
    "            continue # Don't include visits with no diagnoses\n",
    "\n",
    "        if len(procedures_codes) > 0:\n",
    "           filtered_visit.set_event_list(\"PROCEDURES_ICD\", visit.event_list_dict[\"PROCEDURES_ICD\"])\n",
    "\n",
    "        if len(prescriptions_codes) > 0:\n",
    "            filtered_visit.set_event_list(\"PRESCRIPTIONS\", visit.event_list_dict[\"PRESCRIPTIONS\"])\n",
    "\n",
    "        filtered_patient.add_visit(filtered_visit)\n",
    "\n",
    "    if len(filtered_patient.visits) >= MIN_NUM_VISITS_PER_PATIENT:\n",
    "        filtered_patients[patient_id] = filtered_patient\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:21:23.340197Z",
     "end_time": "2023-05-01T00:22:41.212740Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 7496\n",
      "\t- Number of visits: 19905\n",
      "\t- Number of visits per patient: 2.6554\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0975\n",
      "\t- Number of events per visit in PRESCRIPTIONS: 82.0433\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 7496\\n\\t- Number of visits: 19905\\n\\t- Number of visits per patient: 2.6554\\n\\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0975\\n\\t- Number of events per visit in PRESCRIPTIONS: 82.0433\\n'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic3_ds.patients = filtered_patients\n",
    "mimic3_ds.stat()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:23:03.169217Z",
     "end_time": "2023-05-01T00:23:04.520215Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "fgrnO7KkWDBY",
    "ExecuteTime": {
     "start_time": "2023-05-01T00:44:03.293945Z",
     "end_time": "2023-05-01T00:44:03.309947Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the tasks\n",
    "\n",
    "DIAGNOSES_KEY = \"conditions\"\n",
    "PROCEDURES_KEY = \"procedures\"\n",
    "INTERVAL_DAYS_KEY = \"days_since_first_visit\"\n",
    "\n",
    "icd9cm = InnerMap.load(\"ICD9CM\")\n",
    "\n",
    "def flatten(l: List):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def patient_level_readmission_prediction(patient, time_window: int = 30, max_length_visits: int = None):\n",
    "    \"\"\"\n",
    "    patient is a <pyhealth.data.Patient> object\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    # # if the patient only has one visit, we drop it\n",
    "    # if len(patient) <= 1:\n",
    "    #     return []\n",
    "\n",
    "    sorted_visits = sorted(patient, key=lambda visit: visit.encounter_time)\n",
    "\n",
    "    # Clip the patient visits to the most recent max_length_visits + 1 if max_length_visits is not None\n",
    "    if max_length_visits is not None:\n",
    "        n_visits = len(sorted_visits)\n",
    "        if n_visits > max_length_visits + 1:\n",
    "            sorted_visits = sorted_visits[n_visits - (max_length_visits + 1):]\n",
    "\n",
    "    feature_visits: List[Visit] = sorted_visits[:-1]\n",
    "    last_visit: Visit = sorted_visits[-1]\n",
    "    second_to_last_visit: Visit = feature_visits[-1]\n",
    "    first_visit: Visit = feature_visits[0]\n",
    "\n",
    "    # step 1 a: define readmission label\n",
    "    time_diff = (last_visit.encounter_time - second_to_last_visit.encounter_time).days\n",
    "    readmission_label = 1 if time_diff <= time_window else 0\n",
    "\n",
    "    # step 1 b: define diagnosis prediction label\n",
    "    diagnosis_label = list(set([icd9cm.get_ancestors(code)[1] for code in last_visit.get_code_list(\"DIAGNOSES_ICD\")]))\n",
    "\n",
    "    # step 2: obtain features\n",
    "    visits_diagnoses = []\n",
    "    visits_procedures = []\n",
    "    visits_intervals = []\n",
    "    for idx, visit in enumerate(feature_visits):\n",
    "        diagnoses = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "        procedures = visit.get_code_list(table=\"PROCEDURES_ICD\")\n",
    "        time_diff_from_first_visit = (visit.encounter_time - first_visit.encounter_time).days\n",
    "\n",
    "        # Exclude visits that are missing either diagnoses or procedures.\n",
    "        # BiteNet can handle missing procedures, but other PyHealth models like RNN\n",
    "        # require all features have a length greater than 0.\n",
    "        if len(diagnoses) * len(procedures) == 0:\n",
    "            continue\n",
    "\n",
    "        visits_diagnoses.append(diagnoses)\n",
    "        visits_procedures.append(procedures)\n",
    "        visits_intervals.append([str(time_diff_from_first_visit)])\n",
    "\n",
    "    unique_diagnoses = list(set(flatten(visits_diagnoses)))\n",
    "\n",
    "    # step 3: exclusion criteria\n",
    "    if len(unique_diagnoses) == 0:\n",
    "        return []\n",
    "\n",
    "    # step 4: assemble the sample\n",
    "    samples.append(\n",
    "        {\n",
    "            \"patient_id\": patient.patient_id,\n",
    "            \"visit_id\": visit.visit_id,\n",
    "            \"diagnoses\": visits_diagnoses,\n",
    "            \"procedures\": visits_procedures,\n",
    "            \"intervals\": visits_intervals,\n",
    "            \"readmission_label\": readmission_label,\n",
    "            \"diagnosis_label\": diagnosis_label\n",
    "        }\n",
    "    )\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:44:04.820239Z",
     "end_time": "2023-05-01T00:44:04.840239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define the models\n",
    "VERY_BIG_NUMBER = 1e30\n",
    "VERY_SMALL_NUMBER = 1e-30\n",
    "VERY_POSITIVE_NUMBER = VERY_BIG_NUMBER\n",
    "VERY_NEGATIVE_NUMBER = -VERY_BIG_NUMBER\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "class MaskDirection(Enum):\n",
    "    FORWARD = 'forward'\n",
    "    BACKWARD = 'backward'\n",
    "    DIAGONAL = 'diagonal'\n",
    "    NONE = 'none'\n",
    "\n",
    "class MaskedLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape: int):\n",
    "        super().__init__()\n",
    "        self.scale = nn.parameter.Parameter(torch.ones(normalized_shape, dtype=torch.float32, device=device))\n",
    "        self.bias = nn.parameter.Parameter(torch.zeros(normalized_shape, dtype=torch.float32, device=device))\n",
    "        self.normalized_shape = normalized_shape\n",
    "\n",
    "    def forward(self, x: torch.Tensor, eps=1e-5):\n",
    "        mean = torch.mean(x, dim=-1, keepdim=True)\n",
    "        variance = torch.mean(torch.square(x - mean), dim=-1, keepdim=True)\n",
    "        norm_x = (x - mean) * torch.rsqrt(variance + eps)\n",
    "        return norm_x * self.scale + self.bias\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, keep: int):\n",
    "        fixed_shape = list(x.size())\n",
    "        start = len(fixed_shape) - keep\n",
    "        left = reduce(mul, [fixed_shape[i] or x.shape[i] for i in range(start)])\n",
    "        out_shape = [left] + [fixed_shape[i] or x.shape[i] for i in range(start, len(fixed_shape))]\n",
    "        return torch.reshape(x, out_shape)\n",
    "\n",
    "\n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, v: torch.Tensor, ref: torch.Tensor, embedding_dim):\n",
    "        batch_size = ref.shape[0]\n",
    "        n_visits = ref.shape[1]\n",
    "        out = torch.reshape(v, [batch_size, n_visits, embedding_dim])\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, embedding_size: int):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_size, embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, mask = inputs\n",
    "        x = self.fc(x)\n",
    "        x[mask] = VERY_NEGATIVE_NUMBER\n",
    "        soft = F.softmax(x, dim=1)\n",
    "        x[mask] = 0\n",
    "        attn_output = torch.sum(soft * x, 1)\n",
    "        return attn_output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, direction, dropout, num_units, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.direction = direction\n",
    "        self.num_units = num_units\n",
    "        self.q_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.k_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.v_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # because of self-attention, queries and keys is equal to inputs\n",
    "        input_tensor, input_mask = inputs\n",
    "        queries = input_tensor\n",
    "        keys = input_tensor\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.q_linear(queries)  # (N, L_q, d)\n",
    "        K = self.k_linear(keys)  # (N, L_k, d)\n",
    "        V = self.v_linear(keys)  # (N, L_k, d)\n",
    "\n",
    "        # print('Q shape: ', Q.get_shape())\n",
    "\n",
    "        # Split and concat\n",
    "        assert self.num_units % self.num_heads == 0\n",
    "        Q_ = torch.cat(torch.split(Q, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_q, d/h)\n",
    "        K_ = torch.cat(torch.split(K, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_k, d/h)\n",
    "        V_ = torch.cat(torch.split(V, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_k, d/h)\n",
    "\n",
    "        # Multiplication\n",
    "        outputs = torch.matmul(Q_, torch.permute(K_, [0, 2, 1]))  # (h*N, L_q, L_k)\n",
    "\n",
    "        # Scale\n",
    "        outputs = outputs / (list(K_.shape)[-1] ** 0.5)  # (h*N, L_q, L_k)\n",
    "\n",
    "        # Key Masking\n",
    "        key_masks = torch.sign(torch.sum(torch.abs(K_), dim=-1))  # (h*N, T_k)\n",
    "        key_masks = torch.unsqueeze(key_masks, 1)  # (h*N, 1, T_k)\n",
    "        key_masks = torch.tile(key_masks, [1, list(Q_.shape)[1], 1])  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Apply masks to outputs\n",
    "        paddings = torch.ones_like(outputs, device=device) * (-2 ** 32 + 1)  # exp mask\n",
    "        outputs = torch.where(key_masks == 0, paddings, outputs)  # (h*N, T_q, T_k)\n",
    "\n",
    "        n_visits = list(input_tensor.shape)[1]\n",
    "        sw_indices = torch.arange(0, n_visits, dtype=torch.int32, device=device)\n",
    "        sw_col, sw_row = torch.meshgrid(sw_indices, sw_indices)\n",
    "        if self.direction == MaskDirection.DIAGONAL:\n",
    "            # shape of (n_visits, n_visits)\n",
    "            attention_mask = (torch.diag(- torch.ones([n_visits], dtype=torch.int32, device=device)) + 1).bool()\n",
    "        elif self.direction == MaskDirection.FORWARD:\n",
    "            attention_mask = torch.greater(sw_row, sw_col)  # shape of (n_visits, n_visits)\n",
    "        else: # MaskDirection.BACKWARD\n",
    "            attention_mask = torch.greater(sw_col, sw_row)  # shape of (n_visits, n_visits)\n",
    "        adder = (1.0 - attention_mask.type(outputs.dtype)) * -10000.0\n",
    "        outputs += adder\n",
    "\n",
    "        # softmax\n",
    "        outputs = F.softmax(outputs, -1)  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Query Masking\n",
    "        query_masks = torch.sign(torch.sum(torch.abs(Q_), dim=-1))  # (h*N, T_q)\n",
    "        query_masks = torch.unsqueeze(query_masks, -1)  # (h*N, T_q, 1)\n",
    "        query_masks = torch.tile(query_masks, [1, 1, list(K_.shape)[1]])  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Apply masks to outputs\n",
    "        outputs = outputs * query_masks\n",
    "\n",
    "        # Dropouts\n",
    "        outputs = self.dropout(outputs)\n",
    "        # Weighted sum\n",
    "        outputs = torch.matmul(outputs, V_)  # ( h*N, T_q, C/h)\n",
    "\n",
    "        # Restore shape\n",
    "        outputs = torch.cat(torch.split(outputs, outputs.shape[0] // self.num_heads, dim=0), dim=2)  # (N, L_q, d)\n",
    "\n",
    "        # input padding\n",
    "        val_mask = torch.unsqueeze(input_mask, -1)\n",
    "        outputs = torch.multiply(outputs, (~val_mask).float())\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class MaskEnc(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int,\n",
    "            num_heads: int,\n",
    "            dropout: float = 0.1,\n",
    "            temporal_mask_direction: MaskDirection = MaskDirection.NONE,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.temporal_mask_direction = temporal_mask_direction\n",
    "\n",
    "        self.attention = MultiHeadAttention(\n",
    "            direction=temporal_mask_direction,\n",
    "            dropout=dropout,\n",
    "            num_units=embedding_dim,\n",
    "            num_heads=num_heads\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embedding_dim, embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.layer_norm1 = MaskedLayerNorm(embedding_dim)\n",
    "        self.layer_norm2 = MaskedLayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, key_padding_mask = inputs\n",
    "\n",
    "        attn_output = self.attention((x, key_padding_mask))\n",
    "        attn_output = self.layer_norm1(x + attn_output)\n",
    "        out = self.fc(attn_output)\n",
    "        out = out * (~key_padding_mask.unsqueeze(-1)).float()\n",
    "        out = self.layer_norm2(out + attn_output)\n",
    "        out = out * (~key_padding_mask.unsqueeze(-1)).float()\n",
    "\n",
    "        return out, key_padding_mask\n",
    "\n",
    "    def _make_temporal_mask(self, n: int) -> Optional[torch.Tensor]:\n",
    "        if self.temporal_mask_direction == MaskDirection.NONE:\n",
    "            return None\n",
    "        if self.temporal_mask_direction == MaskDirection.FORWARD:\n",
    "            return torch.tril(torch.full((n, n), -10000, device=device)).fill_diagonal_(0).float()\n",
    "        if self.temporal_mask_direction == MaskDirection.BACKWARD:\n",
    "            return torch.triu(torch.full((n, n), -10000, device=device)).fill_diagonal_(0).float()\n",
    "        if self.temporal_mask_direction == MaskDirection.DIAGONAL:\n",
    "            return torch.zeros(n, n, device=device).fill_diagonal_(-10000).float()\n",
    "\n",
    "\n",
    "class BiteNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int = 128,\n",
    "            num_heads: int = 4,\n",
    "            dropout: float = 0.1,\n",
    "            n_mask_enc_layers: int = 2,\n",
    "            use_procedures: bool = True,\n",
    "            use_intervals: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_intervals = use_intervals\n",
    "        self.use_procedures = use_procedures\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.unflatten = Unflatten()\n",
    "\n",
    "        def _make_mask_enc_block(temporal_mask_direction: MaskDirection = MaskDirection.NONE):\n",
    "            return MaskEnc(\n",
    "                embedding_dim = embedding_dim,\n",
    "                num_heads = num_heads,\n",
    "                dropout = dropout,\n",
    "                temporal_mask_direction = temporal_mask_direction,\n",
    "            )\n",
    "\n",
    "        self.code_attn = nn.Sequential()\n",
    "        self.visit_attn_fw = nn.Sequential()\n",
    "        self.visit_attn_bw = nn.Sequential()\n",
    "        for _ in range(n_mask_enc_layers):\n",
    "            self.code_attn.append(_make_mask_enc_block(MaskDirection.DIAGONAL))\n",
    "            self.visit_attn_fw.append(_make_mask_enc_block(MaskDirection.FORWARD))\n",
    "            self.visit_attn_bw.append(_make_mask_enc_block(MaskDirection.BACKWARD))\n",
    "\n",
    "        # Attention pooling layers\n",
    "        self.code_attn.append(AttentionPooling(embedding_dim))\n",
    "        self.visit_attn_fw.append(AttentionPooling(embedding_dim))\n",
    "        self.visit_attn_bw.append(AttentionPooling(embedding_dim))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*embedding_dim, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            embedded_codes: torch.Tensor,\n",
    "            embedded_intervals: torch.Tensor,\n",
    "            codes_mask: torch.Tensor,\n",
    "            visits_mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        codes_mask = ~(codes_mask.bool())\n",
    "\n",
    "        # input tensor, reshape 4 dimension to 3\n",
    "        flattened_codes = self.flatten(embedded_codes, 2)\n",
    "\n",
    "        # input mask, reshape 3 dimension to 2\n",
    "        flattened_codes_mask = self.flatten(codes_mask, 1)\n",
    "\n",
    "        code_attn = self.code_attn((flattened_codes, flattened_codes_mask))\n",
    "        code_attn = self.unflatten(code_attn, embedded_codes, self.embedding_dim)\n",
    "\n",
    "        if self.use_intervals:\n",
    "            code_attn += embedded_intervals\n",
    "\n",
    "        visits_mask = ~(visits_mask.bool())\n",
    "\n",
    "        u_fw = self.visit_attn_fw((code_attn, visits_mask))\n",
    "        u_bw = self.visit_attn_bw((code_attn, visits_mask))\n",
    "        u_bi = torch.cat([u_fw, u_bw], dim=-1)\n",
    "\n",
    "        s = self.fc(u_bi)\n",
    "        return s\n",
    "\n",
    "class PyHealthBiteNet(BaseModel):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: SampleDataset,\n",
    "            feature_keys: List[str],\n",
    "            label_key: str,\n",
    "            mode: str,\n",
    "            embedding_dim: int = 128,\n",
    "            n_mask_enc_layers: int = 2,\n",
    "            use_intervals: bool = True,\n",
    "            use_procedures: bool = True,\n",
    "            num_heads: int = 4,\n",
    "            dropout: float = 0.1,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(dataset, feature_keys, label_key, mode)\n",
    "\n",
    "        self.use_intervals = use_intervals\n",
    "        self.use_procedures = use_procedures\n",
    "\n",
    "        # Any BaseModel should have these attributes, as functions like add_feature_transform_layer uses them\n",
    "        self.feat_tokenizers = {}\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        self.linear_layers = nn.ModuleDict()\n",
    "        self.label_tokenizer = self.get_label_tokenizer()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # self.add_feature_transform_layer will create a transformation layer for each feature\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "            self.add_feature_transform_layer(\n",
    "                feature_key, input_info, special_tokens=[\"<pad>\", \"<unk>\"]\n",
    "            )\n",
    "\n",
    "        # final output layer\n",
    "        output_size = self.get_output_size(self.label_tokenizer)\n",
    "        self.bite_net = BiteNet(\n",
    "            embedding_dim = embedding_dim,\n",
    "            num_heads = num_heads,\n",
    "            dropout = dropout,\n",
    "            use_intervals=use_intervals,\n",
    "            use_procedures=use_procedures,\n",
    "            n_mask_enc_layers=n_mask_enc_layers,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(self.embedding_dim, output_size)\n",
    "\n",
    "    def forward(self, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        embeddings = {}\n",
    "        masks = {}\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "\n",
    "            # each patient's feature is represented by [[code1, code2],[code3]]\n",
    "            assert input_info[\"dim\"] == 3 and input_info[\"type\"] == str\n",
    "            feature_vals = kwargs[feature_key]\n",
    "\n",
    "            x = self.feat_tokenizers[feature_key].batch_encode_3d(feature_vals, truncation=(False, False))\n",
    "            x = torch.tensor(x, dtype=torch.long, device=self.device)\n",
    "            pad_idx = self.feat_tokenizers[feature_key].vocabulary(\"<pad>\")\n",
    "            #create the mask\n",
    "            mask = (x != pad_idx).long()\n",
    "            embeds = self.embeddings[feature_key](x)\n",
    "            embeddings[feature_key] = embeds\n",
    "            masks[feature_key] = mask\n",
    "\n",
    "        embedded_codes = embeddings['diagnoses']\n",
    "        codes_mask = masks['diagnoses']\n",
    "        if self.use_procedures:\n",
    "            embedded_codes = torch.cat((embedded_codes, embeddings['procedures']), dim=2)\n",
    "            codes_mask = torch.cat((codes_mask, masks['procedures']), dim=2)\n",
    "\n",
    "        output = self.bite_net(embedded_codes, embeddings['intervals'].squeeze(2), codes_mask, masks['intervals'].squeeze(-1))\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        # obtain y_true, loss, y_prob\n",
    "        y_true = self.prepare_labels(kwargs[self.label_key], self.label_tokenizer)\n",
    "        loss = self.get_loss_function()(logits, y_true)\n",
    "        y_prob = self.prepare_y_prob(logits)\n",
    "\n",
    "        return {\"loss\": loss, \"y_prob\": y_prob, \"y_true\": y_true}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, train_loader, val_loader, test_loader, lr=0.001, monitor=\"pr-auc\"):\n",
    "    trainer = Trainer(model=model, device=device)\n",
    "    trainer.train(\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        epochs=10,\n",
    "        monitor=monitor,\n",
    "        optimizer_class=torch.optim.RMSprop,\n",
    "        optimizer_params = {\"lr\" : lr},\n",
    "        load_best_model_at_last=True\n",
    "    )\n",
    "\n",
    "    # Run inference and evaluate\n",
    "    # option 1: use our built-in evaluation metric\n",
    "    score = trainer.evaluate(test_loader)\n",
    "    print (score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:53:17.613202Z",
     "end_time": "2023-05-01T00:53:17.640199Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples for patient_level_readmission_prediction: 100%|██████████| 7496/7496 [00:03<00:00, 2133.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6930\n"
     ]
    }
   ],
   "source": [
    "# Define the dataset and data loaders\n",
    "# Create the task datasets\n",
    "dataset = mimic3_ds.set_task(task_fn=patient_level_readmission_prediction)\n",
    "print(len(dataset))\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train, val, test = split_by_patient(dataset, [0.8, 0.1, 0.1])\n",
    "\n",
    "train_loader = get_dataloader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = get_dataloader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = get_dataloader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:44:06.471967Z",
     "end_time": "2023-05-01T00:44:10.166967Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:41:17.252196Z",
     "end_time": "2023-05-01T00:42:32.476760Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyHealthBiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1756, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000001D43A62E760>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb45270521c3427ba8c0f270f7ef1afa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camer\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5046\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 65.28it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.3108\n",
      "roc_auc: 0.5620\n",
      "f1: 0.1702\n",
      "loss: 0.4618\n",
      "New best pr_auc score (0.3108) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20cf2b3832db450f9aaaf94e4d973f76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.4783\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 65.28it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.3058\n",
      "roc_auc: 0.5599\n",
      "f1: 0.1690\n",
      "loss: 0.4603\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c69c7630ac94a499bb9fd2e2d905a3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.4686\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 65.67it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.3055\n",
      "roc_auc: 0.5528\n",
      "f1: 0.1633\n",
      "loss: 0.4658\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "744a7cf6544b4c1fa086e69c0a8af6ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.4593\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 65.67it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.3014\n",
      "roc_auc: 0.5379\n",
      "f1: 0.1830\n",
      "loss: 0.4869\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e6e0d4cdaa74c9dbb3664f78873df1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.4469\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 64.71it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.3028\n",
      "roc_auc: 0.5477\n",
      "f1: 0.1690\n",
      "loss: 0.4781\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4003de7860aa4708ada000998e85f0ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.4365\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 65.67it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.2966\n",
      "roc_auc: 0.5378\n",
      "f1: 0.1911\n",
      "loss: 0.4867\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce35d59a2b9b492380081e04e4168348"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.4254\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 64.90it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.2915\n",
      "roc_auc: 0.5354\n",
      "f1: 0.1988\n",
      "loss: 0.4995\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f207ea73fe7e4f658abaf418f6ecd032"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.4098\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 65.67it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.2950\n",
      "roc_auc: 0.5357\n",
      "f1: 0.1899\n",
      "loss: 0.5138\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6337de03f59b4d06855df671ef2a8995"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.3956\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.36it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.2928\n",
      "roc_auc: 0.5387\n",
      "f1: 0.2025\n",
      "loss: 0.5227\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a0478dbee04444a8d529ad91c5d170f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.3826\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.97it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.2890\n",
      "roc_auc: 0.5348\n",
      "f1: 0.2172\n",
      "loss: 0.6436\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 60.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.3729449988885468, 'roc_auc': 0.5987539732994278, 'f1': 0.3254237288135593, 'loss': 0.6153426658023488}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    PyHealthBiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        use_procedures=True,\n",
    "        use_intervals=True\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyHealthBiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1756, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=465, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000001D43AC050D0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81fa42d1472041d2aeedd8a9c09279ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.0946\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.97it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc_samples: 0.3041\n",
      "loss: 0.0903\n",
      "New best pr_auc_samples score (0.3041) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e69bf33f8dd94e36a25960ccac00e42d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.0862\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.62it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc_samples: 0.2999\n",
      "loss: 0.0939\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5c6a5b6a292493f9e786ba53d2e9538"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.0855\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 60.44it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc_samples: 0.3417\n",
      "loss: 0.0907\n",
      "New best pr_auc_samples score (0.3417) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05281effbf654682b545f18e2b6e273e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.0843\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.11it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc_samples: 0.3517\n",
      "loss: 0.0894\n",
      "New best pr_auc_samples score (0.3517) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c645d22fcd0741448b2de26a9c734b47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0836\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 58.36it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc_samples: 0.3591\n",
      "loss: 0.0872\n",
      "New best pr_auc_samples score (0.3591) at epoch-4, step-870\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7630fc46e27d441fabb9580f9b70de1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0829\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 60.77it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc_samples: 0.3699\n",
      "loss: 0.0895\n",
      "New best pr_auc_samples score (0.3699) at epoch-5, step-1044\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7705be460b54fc4a336f4d4bb515874"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0825\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.62it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc_samples: 0.3655\n",
      "loss: 0.0866\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5eb9769515564608ac47371fb680ccfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0820\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 60.94it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc_samples: 0.3740\n",
      "loss: 0.0887\n",
      "New best pr_auc_samples score (0.3740) at epoch-7, step-1392\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af70d15905c349e0a7238b5611e528cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0815\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 61.11it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc_samples: 0.3743\n",
      "loss: 0.0855\n",
      "New best pr_auc_samples score (0.3743) at epoch-8, step-1566\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "371b73972de94bac93681fd330854a70"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0803\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 60.77it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc_samples: 0.3776\n",
      "loss: 0.0868\n",
      "New best pr_auc_samples score (0.3776) at epoch-9, step-1740\n",
      "Loaded best model\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 56.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc_samples': 0.3748846788378517, 'loss': 0.08555971424687993}\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    PyHealthBiteNet(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        use_procedures=True,\n",
    "        use_intervals=False\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.001,\n",
    "    monitor=\"pr_auc_samples\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:53:24.693972Z",
     "end_time": "2023-05-01T00:54:38.203101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (rnn): ModuleDict(\n",
      "    (diagnoses): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "    (procedures): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000211A794E700>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c39a0e26caa54b54a244148081980d32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5060\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 147.66it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.4103\n",
      "roc_auc: 0.6276\n",
      "f1: 0.2275\n",
      "loss: 0.4788\n",
      "New best pr_auc score (0.4103) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35a2dd9827c94598ae7a7d529149d253"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.4188\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 141.03it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.4115\n",
      "roc_auc: 0.6165\n",
      "f1: 0.2712\n",
      "loss: 0.4967\n",
      "New best pr_auc score (0.4115) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebc794e42eb948e48d8cd64b81d36873"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.3401\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 140.13it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.4139\n",
      "roc_auc: 0.6251\n",
      "f1: 0.3021\n",
      "loss: 0.5159\n",
      "New best pr_auc score (0.4139) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7d86e59b14c46c49ac4ac97b08bac62"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.2591\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 147.65it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.3980\n",
      "roc_auc: 0.6171\n",
      "f1: 0.2817\n",
      "loss: 0.5742\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fb97d74b914b4689aaee1093b339c091"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.1863\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 131.74it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.4049\n",
      "roc_auc: 0.6146\n",
      "f1: 0.3529\n",
      "loss: 0.6299\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe575c0d8d9447bfb03ce45de6cfaee4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.1322\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 120.22it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3986\n",
      "roc_auc: 0.6215\n",
      "f1: 0.2909\n",
      "loss: 0.6772\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "839a28a956924d108ae90dec3f114211"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0958\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 146.67it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3949\n",
      "roc_auc: 0.6128\n",
      "f1: 0.3291\n",
      "loss: 0.7314\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a891b77978dc443a9e7b62c4711b6768"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0665\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 144.74it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.3848\n",
      "roc_auc: 0.6095\n",
      "f1: 0.2715\n",
      "loss: 0.8290\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50c106bfcd154010a4d31d5ea8725a4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0481\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 147.65it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.3936\n",
      "roc_auc: 0.6116\n",
      "f1: 0.3226\n",
      "loss: 0.8718\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2d388316062433f9bb0270f7dd3c070"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0369\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 148.65it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.3827\n",
      "roc_auc: 0.6051\n",
      "f1: 0.2918\n",
      "loss: 0.9339\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 161.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.3738644161210829, 'roc_auc': 0.6120972073039742, 'f1': 0.3047619047619048, 'loss': 0.8288188739256426}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    RNN(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.001\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:46:52.089218Z",
     "end_time": "2023-04-29T20:47:14.874291Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (rnn): ModuleDict(\n",
      "    (diagnoses): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "    (procedures): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=465, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000001D43AC050D0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e73e5230a3f441fa703f076d1d2133b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.1048\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 150.69it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc_samples: 0.3754\n",
      "loss: 0.0889\n",
      "New best pr_auc_samples score (0.3754) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "660039dfca2e46458f16d4560bd6ad47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.0818\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 141.03it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc_samples: 0.4102\n",
      "loss: 0.0844\n",
      "New best pr_auc_samples score (0.4102) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e09d9a8a6d5443a79f23220786e26415"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.0776\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 146.67it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc_samples: 0.4215\n",
      "loss: 0.0829\n",
      "New best pr_auc_samples score (0.4215) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e314a36b0fe47179e4200b339d5aa74"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.0749\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 142.86it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc_samples: 0.4342\n",
      "loss: 0.0819\n",
      "New best pr_auc_samples score (0.4342) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c10ffd1891b24083be9ecb62e16d339b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0726\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 139.24it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc_samples: 0.4377\n",
      "loss: 0.0816\n",
      "New best pr_auc_samples score (0.4377) at epoch-4, step-870\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6325bd874cd747c1a47d21f1cdc034c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0705\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 143.79it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc_samples: 0.4433\n",
      "loss: 0.0815\n",
      "New best pr_auc_samples score (0.4433) at epoch-5, step-1044\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "074207c5a4a74292aa0384741f44c002"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0687\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 121.55it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc_samples: 0.4422\n",
      "loss: 0.0816\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea89182cb90f4b08adfbeed7b66ce410"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0669\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 134.15it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc_samples: 0.4442\n",
      "loss: 0.0817\n",
      "New best pr_auc_samples score (0.4442) at epoch-7, step-1392\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb890e9270914c3ab99d992ef91cd668"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0654\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 133.34it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc_samples: 0.4445\n",
      "loss: 0.0819\n",
      "New best pr_auc_samples score (0.4445) at epoch-8, step-1566\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "162ce3abe78547549d3573c7b5d320b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0638\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 119.57it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc_samples: 0.4427\n",
      "loss: 0.0824\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 140.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc_samples': 0.44439526194302753, 'loss': 0.08051219142296097}\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    RNN(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.001,\n",
    "    monitor=\"pr_auc_samples\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:49:13.829220Z",
     "end_time": "2023-05-01T00:49:41.406626Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (retain): ModuleDict(\n",
      "    (diagnoses): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (procedures): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000211A794E700>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da114fef9a3741ed93305ae321406ec4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5355\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 84.29it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.3553\n",
      "roc_auc: 0.5890\n",
      "f1: 0.1775\n",
      "loss: 0.5163\n",
      "New best pr_auc score (0.3553) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19ab54a5c3d24e64a00ce07a0a1fc3d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.3683\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 80.88it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.3871\n",
      "roc_auc: 0.6180\n",
      "f1: 0.2737\n",
      "loss: 0.5194\n",
      "New best pr_auc score (0.3871) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b8653603baa45198d9d87e5b46c6850"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.2285\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 77.19it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.3715\n",
      "roc_auc: 0.6024\n",
      "f1: 0.2526\n",
      "loss: 0.6153\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "636f0e32c1b8480398726c1d5f797817"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.1225\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 78.01it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.3835\n",
      "roc_auc: 0.5939\n",
      "f1: 0.3097\n",
      "loss: 0.6973\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "622878b58c6c49679eb914c3363eb6ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0688\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 79.42it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.3848\n",
      "roc_auc: 0.6013\n",
      "f1: 0.3117\n",
      "loss: 0.8054\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "044414be83e64fee887417ac1bad62f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0419\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 76.39it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3802\n",
      "roc_auc: 0.5960\n",
      "f1: 0.3084\n",
      "loss: 0.9247\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64d18c3bb15e4d83a949b36fb72ad5dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0313\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 80.29it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3778\n",
      "roc_auc: 0.6086\n",
      "f1: 0.3070\n",
      "loss: 0.9865\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dec59a7cbdc547518aa36f45093dcbf5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0186\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 79.71it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.3776\n",
      "roc_auc: 0.5983\n",
      "f1: 0.2857\n",
      "loss: 1.1027\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31f1037a0d4c435a8f0a2cd7ba1e9f40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0181\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 73.83it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.3936\n",
      "roc_auc: 0.6030\n",
      "f1: 0.3004\n",
      "loss: 1.1505\n",
      "New best pr_auc score (0.3936) at epoch-8, step-1566\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f4e9978d31c40aeb47ffbeea1d37c56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0158\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 78.29it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.3926\n",
      "roc_auc: 0.6023\n",
      "f1: 0.3064\n",
      "loss: 1.2158\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 82.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.3606033694496517, 'roc_auc': 0.5797932330827067, 'f1': 0.29729729729729726, 'loss': 1.2300627353516491}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    RETAIN(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:47:49.609222Z",
     "end_time": "2023-04-29T20:48:50.110635Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3374, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1362, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (retain): ModuleDict(\n",
      "    (diagnoses): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (procedures): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=465, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x000001D43AC050D0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "046e1807c8044323bb31990dae349a3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.1180\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 81.18it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc_samples: 0.4010\n",
      "loss: 0.0930\n",
      "New best pr_auc_samples score (0.4010) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cadfd5cc17cb4e77925cb5899192268b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.0811\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 75.34it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc_samples: 0.4227\n",
      "loss: 0.0878\n",
      "New best pr_auc_samples score (0.4227) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eda4c62150344aef9effe0f1e9b02501"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.0747\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 70.29it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc_samples: 0.4304\n",
      "loss: 0.0862\n",
      "New best pr_auc_samples score (0.4304) at epoch-2, step-522\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "47dd6ba8186444feab1709c95224f5b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.0707\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 78.57it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc_samples: 0.4357\n",
      "loss: 0.0863\n",
      "New best pr_auc_samples score (0.4357) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9714af985065472d9c8ad30e614b2a3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0674\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 78.02it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc_samples: 0.4313\n",
      "loss: 0.0869\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a0e4757047944a8bd428e53d3a6114b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0648\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 77.74it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc_samples: 0.4356\n",
      "loss: 0.0875\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9350379029144084b5b36101e026d53c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0626\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 67.69it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc_samples: 0.4325\n",
      "loss: 0.0880\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "042c1af7f7a94992b5056cb68e2bc141"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0604\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 76.39it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc_samples: 0.4332\n",
      "loss: 0.0890\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbda2fc3abb9447ea4357744d47999c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0586\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 76.66it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc_samples: 0.4300\n",
      "loss: 0.0904\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "54c3665d2f914bf4a8e49d42f931893c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0569\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 80.88it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc_samples: 0.4272\n",
      "loss: 0.0914\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 68.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc_samples': 0.4249831201075734, 'loss': 0.09086060625585643}\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    RETAIN(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"diagnosis_label\",\n",
    "        mode = \"multilabel\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    lr=0.001,\n",
    "    monitor=\"pr_auc_samples\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-01T00:51:14.489202Z",
     "end_time": "2023-05-01T00:52:22.434249Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3375, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1363, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (cnn): ModuleDict(\n",
      "    (diagnoses): DeeprLayer(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "    )\n",
      "    (procedures): DeeprLayer(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x00000211A794E700>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "673342986c5e4c0295bf0e0ec5b994b6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-174 ---\n",
      "loss: 0.5101\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 183.33it/s]\n",
      "--- Eval epoch-0, step-174 ---\n",
      "pr_auc: 0.4078\n",
      "roc_auc: 0.6345\n",
      "f1: 0.1863\n",
      "loss: 0.4984\n",
      "New best pr_auc score (0.4078) at epoch-0, step-174\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "464186425d54491c8f1885b8f5649a78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-348 ---\n",
      "loss: 0.3764\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 268.29it/s]\n",
      "--- Eval epoch-1, step-348 ---\n",
      "pr_auc: 0.4154\n",
      "roc_auc: 0.6332\n",
      "f1: 0.2755\n",
      "loss: 0.4897\n",
      "New best pr_auc score (0.4154) at epoch-1, step-348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "41e917c3f5fa498f8212a0856e712d81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-522 ---\n",
      "loss: 0.2655\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 258.82it/s]\n",
      "--- Eval epoch-2, step-522 ---\n",
      "pr_auc: 0.3905\n",
      "roc_auc: 0.6049\n",
      "f1: 0.3258\n",
      "loss: 0.5340\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da8179e0bf92441c88515e0c8f16028a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-696 ---\n",
      "loss: 0.1544\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 249.96it/s]\n",
      "--- Eval epoch-3, step-696 ---\n",
      "pr_auc: 0.4250\n",
      "roc_auc: 0.6310\n",
      "f1: 0.3577\n",
      "loss: 0.5696\n",
      "New best pr_auc score (0.4250) at epoch-3, step-696\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a553e71e82b34f9fb80bc9ad954bb79a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-870 ---\n",
      "loss: 0.0791\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 244.44it/s]\n",
      "--- Eval epoch-4, step-870 ---\n",
      "pr_auc: 0.3979\n",
      "roc_auc: 0.6118\n",
      "f1: 0.2922\n",
      "loss: 0.6220\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7da574cacc34ac7a662d3c5e38123da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1044 ---\n",
      "loss: 0.0389\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 261.87it/s]\n",
      "--- Eval epoch-5, step-1044 ---\n",
      "pr_auc: 0.3990\n",
      "roc_auc: 0.6011\n",
      "f1: 0.2842\n",
      "loss: 0.7871\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec6ddf3d75c0469caaebae5e4ff2a3b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1218 ---\n",
      "loss: 0.0175\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 255.79it/s]\n",
      "--- Eval epoch-6, step-1218 ---\n",
      "pr_auc: 0.3948\n",
      "roc_auc: 0.6088\n",
      "f1: 0.2737\n",
      "loss: 0.8633\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "352248d3b17446648e1e80119d035c39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1392 ---\n",
      "loss: 0.0168\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 255.82it/s]\n",
      "--- Eval epoch-7, step-1392 ---\n",
      "pr_auc: 0.4105\n",
      "roc_auc: 0.6164\n",
      "f1: 0.2932\n",
      "loss: 0.9251\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25cad53f6c2d4a05befd0155688da302"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1566 ---\n",
      "loss: 0.0055\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 255.81it/s]\n",
      "--- Eval epoch-8, step-1566 ---\n",
      "pr_auc: 0.3957\n",
      "roc_auc: 0.6097\n",
      "f1: 0.3136\n",
      "loss: 0.8593\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/174 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91dfe39e991e4f45a2cad324ee804bd3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1740 ---\n",
      "loss: 0.0027\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 252.87it/s]\n",
      "--- Eval epoch-9, step-1740 ---\n",
      "pr_auc: 0.4183\n",
      "roc_auc: 0.6189\n",
      "f1: 0.3349\n",
      "loss: 0.9303\n",
      "Evaluation: 100%|██████████| 22/22 [00:00<00:00, 224.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.39479580130583247, 'roc_auc': 0.6421455424274973, 'f1': 0.303030303030303, 'loss': 0.8376922133294019}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    Deepr(\n",
    "        dataset = dataset,\n",
    "        feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "        label_key = \"readmission_label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128\n",
    "    ).to(device),\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T20:49:23.296202Z",
     "end_time": "2023-04-29T20:49:36.578089Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
