{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Library imports and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T12:53:04.079137Z",
     "end_time": "2023-05-04T12:53:04.113123Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install pyhealth\n",
    "from pyhealth.datasets import MIMIC3Dataset\n",
    "from pyhealth.data import Patient, Visit, Event\n",
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.medcode import InnerMap\n",
    "from tqdm import tqdm\n",
    "from pyhealth.metrics.binary import binary_metrics_fn\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import List, Dict\n",
    "\n",
    "# Set this to the directory with all MIMIC-3 dataset files\n",
    "data_root = \"data\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-VgeMdJDYYK",
    "outputId": "9cb9c08a-9003-4836-a3b2-a23e7cd45b55",
    "ExecuteTime": {
     "start_time": "2023-05-04T11:25:56.656127Z",
     "end_time": "2023-05-04T11:26:01.044125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "mimic3_ds = MIMIC3Dataset(\n",
    "        root=data_root,\n",
    "        tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\"],\n",
    "        dev=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "HQdeU1TLU6m_",
    "outputId": "590623d6-2917-4155-bf0a-5d75a3979c25",
    "ExecuteTime": {
     "start_time": "2023-05-04T11:26:01.046128Z",
     "end_time": "2023-05-04T11:26:01.255124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 46520\n",
      "\t- Number of visits: 58976\n",
      "\t- Number of visits per patient: 1.2678\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0711\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 46520\\n\\t- Number of visits: 58976\\n\\t- Number of visits per patient: 1.2678\\n\\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0711\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataset statistics\n",
    "\n",
    "mimic3_ds.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Find all diagnoses codes\n",
    "# Remove diagnoses codes with fewer than 5 occurences in the dataset\n",
    "\n",
    "all_diagnosis_codes = []\n",
    "for patient_id, patient in mimic3_ds.patients.items():\n",
    "  for i in range(len(patient)):\n",
    "    visit: Visit = patient[i]\n",
    "    conditions = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "    all_diagnosis_codes.extend(conditions)\n",
    "\n",
    "codes = pd.Series(all_diagnosis_codes)\n",
    "diag_code_counts = codes.value_counts()\n",
    "filtered_diag_codes = diag_code_counts[diag_code_counts > 4].index.values\n",
    "n_unique_diag_codes = len(filtered_diag_codes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T11:26:01.258126Z",
     "end_time": "2023-05-04T11:26:01.627125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46520/46520 [01:12<00:00, 644.27it/s]\n"
     ]
    }
   ],
   "source": [
    "MIN_N_VISITS_PER_PATIENT = 2\n",
    "\n",
    "# Filter Dataset to requirements specified in paper\n",
    "\n",
    "filtered_patients = {}\n",
    "for patient_id, patient in tqdm(mimic3_ds.patients.items()):\n",
    "\n",
    "    filtered_patient: Patient = Patient(\n",
    "        patient_id=patient.patient_id,\n",
    "        birth_datetime=patient.birth_datetime,\n",
    "        death_datetime=patient.death_datetime,\n",
    "        gender=patient.gender,\n",
    "        ethnicity=patient.ethnicity\n",
    "    )\n",
    "\n",
    "    for i_visit, visit in enumerate(patient):\n",
    "        filtered_visit: Visit = Visit(\n",
    "            visit_id=visit.visit_id,\n",
    "            patient_id=visit.patient_id,\n",
    "            encounter_time=visit.encounter_time,\n",
    "            discharge_time=visit.discharge_time,\n",
    "            discharge_status=visit.discharge_status\n",
    "        )\n",
    "\n",
    "        diagnoses_codes = visit.get_code_list(\"DIAGNOSES_ICD\")\n",
    "        procedures_codes = visit.get_code_list(\"PROCEDURES_ICD\")\n",
    "        prescriptions_codes = visit.get_code_list(\"PRESCRIPTIONS\")\n",
    "\n",
    "        if len(diagnoses_codes) > 0:\n",
    "            diagnosis_events = visit.event_list_dict[\"DIAGNOSES_ICD\"]\n",
    "            for i_event in range(len(diagnosis_events) - 1, -1, -1):\n",
    "                event: Event = diagnosis_events[i_event]\n",
    "                if event.code not in filtered_diag_codes:\n",
    "                    diagnosis_events.pop(i_event) # Remove the diagnosis code with fewer than the cutoff occurrences\n",
    "\n",
    "            if len(diagnosis_events) == 0: continue # Don't include visits with no diagnoses\n",
    "\n",
    "            filtered_visit.set_event_list(\"DIAGNOSES_ICD\", diagnosis_events)\n",
    "        else:\n",
    "            continue # Don't include visits with no diagnoses\n",
    "\n",
    "        if len(procedures_codes) > 0:\n",
    "           filtered_visit.set_event_list(\"PROCEDURES_ICD\", visit.event_list_dict[\"PROCEDURES_ICD\"])\n",
    "\n",
    "        if len(prescriptions_codes) > 0:\n",
    "            filtered_visit.set_event_list(\"PRESCRIPTIONS\", visit.event_list_dict[\"PRESCRIPTIONS\"])\n",
    "\n",
    "        filtered_patient.add_visit(filtered_visit)\n",
    "\n",
    "    if len(filtered_patient.visits) >= MIN_N_VISITS_PER_PATIENT:\n",
    "        filtered_patients[patient_id] = filtered_patient\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T11:26:01.632123Z",
     "end_time": "2023-05-04T11:27:13.857412Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 7496\n",
      "\t- Number of visits: 19905\n",
      "\t- Number of visits per patient: 2.6554\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0975\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 7496\\n\\t- Number of visits: 19905\\n\\t- Number of visits per patient: 2.6554\\n\\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0975\\n'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic3_ds.patients = filtered_patients\n",
    "mimic3_ds.stat()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T11:27:35.902138Z",
     "end_time": "2023-05-04T11:27:35.976140Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "fgrnO7KkWDBY",
    "ExecuteTime": {
     "start_time": "2023-05-04T13:01:43.504096Z",
     "end_time": "2023-05-04T13:01:43.550991Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the tasks\n",
    "\n",
    "DIAGNOSES_KEY = \"conditions\"\n",
    "PROCEDURES_KEY = \"procedures\"\n",
    "INTERVAL_DAYS_KEY = \"days_since_first_visit\"\n",
    "\n",
    "icd9cm = InnerMap.load(\"ICD9CM\")\n",
    "\n",
    "def flatten(l: List):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def patient_level_readmission_prediction(patient, time_window: int = 30, max_length_visits: int = None):\n",
    "    \"\"\"\n",
    "    patient is a <pyhealth.data.Patient> object\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    sorted_visits = sorted(patient, key=lambda visit: visit.encounter_time)\n",
    "\n",
    "    # Clip the patient visits to the most recent max_length_visits + 1 if max_length_visits is not None\n",
    "    if max_length_visits is not None:\n",
    "        n_visits = len(sorted_visits)\n",
    "        if n_visits > max_length_visits + 1:\n",
    "            sorted_visits = sorted_visits[n_visits - (max_length_visits + 1):]\n",
    "\n",
    "    feature_visits: List[Visit] = sorted_visits[:-1]\n",
    "    last_visit: Visit = sorted_visits[-1]\n",
    "    second_to_last_visit: Visit = feature_visits[-1]\n",
    "    first_visit: Visit = feature_visits[0]\n",
    "\n",
    "    # step 1 a: define readmission label\n",
    "    time_diff = (last_visit.encounter_time - second_to_last_visit.encounter_time).days\n",
    "    readmission_label = 1 if time_diff <= time_window else 0\n",
    "\n",
    "    # step 1 b: define diagnosis prediction label\n",
    "    diagnosis_label = list(set([icd9cm.get_ancestors(code)[1] for code in last_visit.get_code_list(\"DIAGNOSES_ICD\")]))\n",
    "\n",
    "    # step 2: obtain features\n",
    "    visits_diagnoses = []\n",
    "    visits_procedures = []\n",
    "    visits_intervals = []\n",
    "    for idx, visit in enumerate(feature_visits):\n",
    "        diagnoses = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "        procedures = visit.get_code_list(table=\"PROCEDURES_ICD\")\n",
    "        time_diff_from_first_visit = (visit.encounter_time - first_visit.encounter_time).days\n",
    "\n",
    "        # Exclude visits that are missing either diagnoses or procedures.\n",
    "        # BiteNet can handle missing procedures, but other PyHealth models like RNN\n",
    "        # require all features have a length greater than 0.\n",
    "        if len(diagnoses) == 0:\n",
    "            continue\n",
    "\n",
    "        visits_diagnoses.append(diagnoses)\n",
    "        visits_procedures.append(procedures)\n",
    "        visits_intervals.append([str(time_diff_from_first_visit)])\n",
    "\n",
    "    unique_diagnoses = list(set(flatten(visits_diagnoses)))\n",
    "\n",
    "    # step 3: exclusion criteria\n",
    "    if len(unique_diagnoses) == 0:\n",
    "        return []\n",
    "\n",
    "    # step 4: assemble the sample\n",
    "    samples.append(\n",
    "        {\n",
    "            \"patient_id\": patient.patient_id,\n",
    "            \"visit_id\": visit.visit_id,\n",
    "            \"diagnoses\": visits_diagnoses,\n",
    "            \"procedures\": visits_procedures,\n",
    "            \"intervals\": visits_intervals,\n",
    "            \"readmission_label\": readmission_label,\n",
    "            \"diagnosis_label\": diagnosis_label\n",
    "        }\n",
    "    )\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "KS = list(range(5, 31, 5))\n",
    "N_TRIALS=5\n",
    "SEQ_LENS = list(range(6, 17, 2))\n",
    "RESULTS_FILE = \"results2.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T13:11:47.939126Z",
     "end_time": "2023-05-04T13:11:47.975124Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def train_and_inference(model, train_loader, val_loader, test_loader, lr=0.001, monitor=\"pr_auc\", optim = torch.optim.RMSprop):\n",
    "    trainer = Trainer(model=model, device=device)\n",
    "    trainer.train(\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        epochs=10,\n",
    "        monitor=monitor,\n",
    "        optimizer_class=optim,\n",
    "        optimizer_params = {\"lr\" : lr},\n",
    "        load_best_model_at_last=False\n",
    "    )\n",
    "\n",
    "    return trainer.inference(test_loader)\n",
    "\n",
    "def precision_at_k(y_true: np.ndarray, y_prob: np.ndarray):\n",
    "\n",
    "    y_pred: np.ndarray = (y_prob > 0.5).astype(int)\n",
    "    desc_idx: np.ndarray = np.flip(np.argsort(y_prob, axis=-1), axis=-1)\n",
    "\n",
    "    y_true = np.take(y_true, desc_idx).astype(float)\n",
    "    y_pred = np.take(y_pred, desc_idx).astype(float)\n",
    "\n",
    "    precisions: List[float] = []\n",
    "    for k in KS:\n",
    "        precisions.append(\n",
    "            precision_score(y_true[:, :k], y_pred[:, :k], average='samples', labels=[0,1])\n",
    "        )\n",
    "\n",
    "    precisions: Dict[str, float] = {\n",
    "        f\"precision@{k}\": p for k, p in zip(KS, precisions)\n",
    "    }\n",
    "    return precisions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T13:11:48.190128Z",
     "end_time": "2023-05-04T13:11:48.215122Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T13:11:48.910127Z",
     "end_time": "2023-05-04T13:11:48.934132Z"
    }
   },
   "outputs": [],
   "source": [
    "# DxTx with interval embeddings\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=['model_name', 'feature_set', 'seq_len', 'trial', 'pr_auc', 'roc_auc', 'f1'] + [f\"precision@{k}\" for k in KS])\n",
    "\n",
    "def train_and_record_metrics(model_readm, model_diag, model_name, feature_set, seq_len, train_loader, val_loader, test_loader, lr=0.001, trial=None):\n",
    "    global metrics_df\n",
    "\n",
    "    y_true, y_prob, _ = train_and_inference(\n",
    "        model_readm,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        lr=lr\n",
    "    )\n",
    "    binary_metrics = binary_metrics_fn(y_true, y_prob, metrics=[\"pr_auc\", \"roc_auc\", \"f1\"])\n",
    "\n",
    "    y_true, y_prob, _ = train_and_inference(\n",
    "        model_diag,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        test_loader,\n",
    "        lr=lr,\n",
    "        monitor=\"pr_auc_samples\",\n",
    "        optim=torch.optim.RMSprop\n",
    "    )\n",
    "    precisions = precision_at_k(y_true, y_prob)\n",
    "\n",
    "    row = binary_metrics | precisions | {\n",
    "        \"model_name\": model_name,\n",
    "        \"feature_set\": feature_set,\n",
    "        \"seq_len\": seq_len,\n",
    "        \"trial\": trial\n",
    "    }\n",
    "    row = {\n",
    "        k: [v] for k, v in row.items()\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.concat([metrics_df, pd.DataFrame.from_dict(row)], ignore_index=True)\n",
    "\n",
    "    # Save df for checkpoint\n",
    "    metrics_df.to_csv(RESULTS_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5275\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2540\n",
      "roc_auc: 0.6168\n",
      "f1: 0.0000\n",
      "loss: 0.4946\n",
      "New best pr_auc score (0.2540) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.5054\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3228\n",
      "roc_auc: 0.6191\n",
      "f1: 0.0000\n",
      "loss: 0.4798\n",
      "New best pr_auc score (0.3228) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4696\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3294\n",
      "roc_auc: 0.5769\n",
      "f1: 0.2531\n",
      "loss: 0.5720\n",
      "New best pr_auc score (0.3294) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4445\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3315\n",
      "roc_auc: 0.5725\n",
      "f1: 0.2000\n",
      "loss: 0.4973\n",
      "New best pr_auc score (0.3315) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.4127\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3283\n",
      "roc_auc: 0.5797\n",
      "f1: 0.2396\n",
      "loss: 0.5370\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.3792\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3273\n",
      "roc_auc: 0.5673\n",
      "f1: 0.2524\n",
      "loss: 0.5430\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.3417\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3175\n",
      "roc_auc: 0.5488\n",
      "f1: 0.1828\n",
      "loss: 0.5766\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.3146\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3080\n",
      "roc_auc: 0.5463\n",
      "f1: 0.1980\n",
      "loss: 0.6450\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.2847\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.2900\n",
      "roc_auc: 0.5919\n",
      "f1: 0.3323\n",
      "loss: 0.6885\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.2632\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.2796\n",
      "roc_auc: 0.5563\n",
      "f1: 0.2353\n",
      "loss: 0.6823\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1229\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3250\n",
      "loss: 0.1059\n",
      "New best pr_auc_samples score (0.3250) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0967\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3380\n",
      "loss: 0.0914\n",
      "New best pr_auc_samples score (0.3380) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0872\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3531\n",
      "loss: 0.0852\n",
      "New best pr_auc_samples score (0.3531) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0835\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.3706\n",
      "loss: 0.0829\n",
      "New best pr_auc_samples score (0.3706) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0817\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.3730\n",
      "loss: 0.0824\n",
      "New best pr_auc_samples score (0.3730) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0807\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.3808\n",
      "loss: 0.0818\n",
      "New best pr_auc_samples score (0.3808) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0800\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.3860\n",
      "loss: 0.0815\n",
      "New best pr_auc_samples score (0.3860) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0792\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.3958\n",
      "loss: 0.0810\n",
      "New best pr_auc_samples score (0.3958) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0784\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.3995\n",
      "loss: 0.0811\n",
      "New best pr_auc_samples score (0.3995) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0777\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4070\n",
      "loss: 0.0813\n",
      "New best pr_auc_samples score (0.4070) at epoch-9, step-1880\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5272\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2571\n",
      "roc_auc: 0.5605\n",
      "f1: 0.0000\n",
      "loss: 0.4944\n",
      "New best pr_auc score (0.2571) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4951\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3424\n",
      "roc_auc: 0.5718\n",
      "f1: 0.1928\n",
      "loss: 0.4624\n",
      "New best pr_auc score (0.3424) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4744\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3477\n",
      "roc_auc: 0.6202\n",
      "f1: 0.1455\n",
      "loss: 0.4872\n",
      "New best pr_auc score (0.3477) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4426\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3388\n",
      "roc_auc: 0.5864\n",
      "f1: 0.1829\n",
      "loss: 0.4932\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.4115\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3318\n",
      "roc_auc: 0.5800\n",
      "f1: 0.2184\n",
      "loss: 0.5723\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.3843\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3163\n",
      "roc_auc: 0.5710\n",
      "f1: 0.2511\n",
      "loss: 0.5753\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.3548\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3279\n",
      "roc_auc: 0.5910\n",
      "f1: 0.2570\n",
      "loss: 0.5905\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.3186\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3143\n",
      "roc_auc: 0.5909\n",
      "f1: 0.2459\n",
      "loss: 0.6792\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.2875\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3434\n",
      "roc_auc: 0.5622\n",
      "f1: 0.2210\n",
      "loss: 0.7055\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.2691\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3225\n",
      "roc_auc: 0.5441\n",
      "f1: 0.2408\n",
      "loss: 0.7300\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1237\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3177\n",
      "loss: 0.1083\n",
      "New best pr_auc_samples score (0.3177) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0983\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3286\n",
      "loss: 0.0938\n",
      "New best pr_auc_samples score (0.3286) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0884\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3474\n",
      "loss: 0.0867\n",
      "New best pr_auc_samples score (0.3474) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0837\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.3676\n",
      "loss: 0.0836\n",
      "New best pr_auc_samples score (0.3676) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0815\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.3815\n",
      "loss: 0.0822\n",
      "New best pr_auc_samples score (0.3815) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0802\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.3897\n",
      "loss: 0.0813\n",
      "New best pr_auc_samples score (0.3897) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0792\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4064\n",
      "loss: 0.0809\n",
      "New best pr_auc_samples score (0.4064) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0783\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4031\n",
      "loss: 0.0831\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0776\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4105\n",
      "loss: 0.0805\n",
      "New best pr_auc_samples score (0.4105) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0768\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4085\n",
      "loss: 0.0810\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.4989\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3392\n",
      "roc_auc: 0.5927\n",
      "f1: 0.1840\n",
      "loss: 0.4690\n",
      "New best pr_auc score (0.3392) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3960\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3348\n",
      "roc_auc: 0.5890\n",
      "f1: 0.1954\n",
      "loss: 0.4813\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2893\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3353\n",
      "roc_auc: 0.6036\n",
      "f1: 0.2049\n",
      "loss: 0.5070\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1804\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3376\n",
      "roc_auc: 0.5871\n",
      "f1: 0.2100\n",
      "loss: 0.5604\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1006\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3388\n",
      "roc_auc: 0.5851\n",
      "f1: 0.2451\n",
      "loss: 0.6544\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0527\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3261\n",
      "roc_auc: 0.5695\n",
      "f1: 0.2277\n",
      "loss: 0.7531\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0251\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3296\n",
      "roc_auc: 0.5737\n",
      "f1: 0.2385\n",
      "loss: 0.8671\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0116\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3254\n",
      "roc_auc: 0.5792\n",
      "f1: 0.2364\n",
      "loss: 0.9286\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0050\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3394\n",
      "roc_auc: 0.5928\n",
      "f1: 0.2347\n",
      "loss: 1.0335\n",
      "New best pr_auc score (0.3394) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0023\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3338\n",
      "roc_auc: 0.5742\n",
      "f1: 0.2341\n",
      "loss: 1.2158\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1118\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3489\n",
      "loss: 0.0887\n",
      "New best pr_auc_samples score (0.3489) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0848\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3828\n",
      "loss: 0.0851\n",
      "New best pr_auc_samples score (0.3828) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0811\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3962\n",
      "loss: 0.0830\n",
      "New best pr_auc_samples score (0.3962) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0787\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4090\n",
      "loss: 0.0820\n",
      "New best pr_auc_samples score (0.4090) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0769\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4197\n",
      "loss: 0.0812\n",
      "New best pr_auc_samples score (0.4197) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0751\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4254\n",
      "loss: 0.0806\n",
      "New best pr_auc_samples score (0.4254) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0736\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4297\n",
      "loss: 0.0804\n",
      "New best pr_auc_samples score (0.4297) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0721\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4336\n",
      "loss: 0.0804\n",
      "New best pr_auc_samples score (0.4336) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0707\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4335\n",
      "loss: 0.0804\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0695\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4368\n",
      "loss: 0.0805\n",
      "New best pr_auc_samples score (0.4368) at epoch-9, step-1880\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5012\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3071\n",
      "roc_auc: 0.5445\n",
      "f1: 0.1988\n",
      "loss: 0.4892\n",
      "New best pr_auc score (0.3071) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3947\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.2940\n",
      "roc_auc: 0.5285\n",
      "f1: 0.1705\n",
      "loss: 0.5177\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2960\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3052\n",
      "roc_auc: 0.5272\n",
      "f1: 0.2099\n",
      "loss: 0.5588\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1959\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3075\n",
      "roc_auc: 0.5238\n",
      "f1: 0.2277\n",
      "loss: 0.6102\n",
      "New best pr_auc score (0.3075) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1212\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3093\n",
      "roc_auc: 0.5210\n",
      "f1: 0.2297\n",
      "loss: 0.6828\n",
      "New best pr_auc score (0.3093) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0692\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3120\n",
      "roc_auc: 0.5233\n",
      "f1: 0.2365\n",
      "loss: 0.7804\n",
      "New best pr_auc score (0.3120) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0392\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3113\n",
      "roc_auc: 0.5217\n",
      "f1: 0.2376\n",
      "loss: 0.9167\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0216\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3010\n",
      "roc_auc: 0.5132\n",
      "f1: 0.2326\n",
      "loss: 0.9911\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0121\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3121\n",
      "roc_auc: 0.5273\n",
      "f1: 0.2266\n",
      "loss: 1.0825\n",
      "New best pr_auc score (0.3121) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0091\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3119\n",
      "roc_auc: 0.5241\n",
      "f1: 0.2370\n",
      "loss: 1.1700\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1125\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3625\n",
      "loss: 0.0870\n",
      "New best pr_auc_samples score (0.3625) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0840\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3857\n",
      "loss: 0.0837\n",
      "New best pr_auc_samples score (0.3857) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0805\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4016\n",
      "loss: 0.0819\n",
      "New best pr_auc_samples score (0.4016) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0782\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4141\n",
      "loss: 0.0808\n",
      "New best pr_auc_samples score (0.4141) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0764\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4195\n",
      "loss: 0.0800\n",
      "New best pr_auc_samples score (0.4195) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0748\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4299\n",
      "loss: 0.0793\n",
      "New best pr_auc_samples score (0.4299) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0733\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4336\n",
      "loss: 0.0790\n",
      "New best pr_auc_samples score (0.4336) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0719\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4356\n",
      "loss: 0.0786\n",
      "New best pr_auc_samples score (0.4356) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0706\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4381\n",
      "loss: 0.0787\n",
      "New best pr_auc_samples score (0.4381) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0693\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4391\n",
      "loss: 0.0787\n",
      "New best pr_auc_samples score (0.4391) at epoch-9, step-1880\n",
      "BRNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5035\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3018\n",
      "roc_auc: 0.5496\n",
      "f1: 0.1615\n",
      "loss: 0.4842\n",
      "New best pr_auc score (0.3018) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3696\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3138\n",
      "roc_auc: 0.5701\n",
      "f1: 0.1749\n",
      "loss: 0.5159\n",
      "New best pr_auc score (0.3138) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2270\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3078\n",
      "roc_auc: 0.5816\n",
      "f1: 0.1923\n",
      "loss: 0.5465\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1104\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.2900\n",
      "roc_auc: 0.5364\n",
      "f1: 0.1956\n",
      "loss: 0.6679\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0465\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.2909\n",
      "roc_auc: 0.5351\n",
      "f1: 0.1756\n",
      "loss: 0.8035\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0179\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.2923\n",
      "roc_auc: 0.5368\n",
      "f1: 0.1675\n",
      "loss: 0.9682\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0074\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.2962\n",
      "roc_auc: 0.5464\n",
      "f1: 0.1810\n",
      "loss: 1.0781\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0029\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.2938\n",
      "roc_auc: 0.5330\n",
      "f1: 0.2000\n",
      "loss: 1.2273\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0024\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.2907\n",
      "roc_auc: 0.5393\n",
      "f1: 0.1692\n",
      "loss: 1.2975\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0014\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.2942\n",
      "roc_auc: 0.5422\n",
      "f1: 0.2149\n",
      "loss: 1.3627\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1113\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3644\n",
      "loss: 0.0887\n",
      "New best pr_auc_samples score (0.3644) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0840\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3833\n",
      "loss: 0.0850\n",
      "New best pr_auc_samples score (0.3833) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0808\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3989\n",
      "loss: 0.0831\n",
      "New best pr_auc_samples score (0.3989) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0786\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4066\n",
      "loss: 0.0819\n",
      "New best pr_auc_samples score (0.4066) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0767\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4173\n",
      "loss: 0.0809\n",
      "New best pr_auc_samples score (0.4173) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0750\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4241\n",
      "loss: 0.0803\n",
      "New best pr_auc_samples score (0.4241) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0734\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4298\n",
      "loss: 0.0799\n",
      "New best pr_auc_samples score (0.4298) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0720\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4346\n",
      "loss: 0.0797\n",
      "New best pr_auc_samples score (0.4346) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0705\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4362\n",
      "loss: 0.0794\n",
      "New best pr_auc_samples score (0.4362) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0692\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4358\n",
      "loss: 0.0801\n",
      "BRNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5038\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3234\n",
      "roc_auc: 0.5431\n",
      "f1: 0.1939\n",
      "loss: 0.4803\n",
      "New best pr_auc score (0.3234) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3704\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3406\n",
      "roc_auc: 0.5723\n",
      "f1: 0.2273\n",
      "loss: 0.4873\n",
      "New best pr_auc score (0.3406) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2428\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3359\n",
      "roc_auc: 0.5696\n",
      "f1: 0.2422\n",
      "loss: 0.5421\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1327\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3294\n",
      "roc_auc: 0.5505\n",
      "f1: 0.2210\n",
      "loss: 0.6457\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0692\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3455\n",
      "roc_auc: 0.5589\n",
      "f1: 0.2488\n",
      "loss: 0.6780\n",
      "New best pr_auc score (0.3455) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0339\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3281\n",
      "roc_auc: 0.5450\n",
      "f1: 0.2388\n",
      "loss: 0.8120\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0188\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3287\n",
      "roc_auc: 0.5419\n",
      "f1: 0.2596\n",
      "loss: 0.9249\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0097\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3299\n",
      "roc_auc: 0.5396\n",
      "f1: 0.2424\n",
      "loss: 1.0054\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0059\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3255\n",
      "roc_auc: 0.5479\n",
      "f1: 0.2335\n",
      "loss: 1.1051\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0051\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3285\n",
      "roc_auc: 0.5449\n",
      "f1: 0.2415\n",
      "loss: 1.1543\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1158\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3630\n",
      "loss: 0.0897\n",
      "New best pr_auc_samples score (0.3630) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0850\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3860\n",
      "loss: 0.0849\n",
      "New best pr_auc_samples score (0.3860) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0810\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4020\n",
      "loss: 0.0825\n",
      "New best pr_auc_samples score (0.4020) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0786\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4145\n",
      "loss: 0.0811\n",
      "New best pr_auc_samples score (0.4145) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0766\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4247\n",
      "loss: 0.0801\n",
      "New best pr_auc_samples score (0.4247) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0749\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4308\n",
      "loss: 0.0797\n",
      "New best pr_auc_samples score (0.4308) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0734\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4354\n",
      "loss: 0.0794\n",
      "New best pr_auc_samples score (0.4354) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0718\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4391\n",
      "loss: 0.0792\n",
      "New best pr_auc_samples score (0.4391) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0705\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4404\n",
      "loss: 0.0791\n",
      "New best pr_auc_samples score (0.4404) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0691\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4417\n",
      "loss: 0.0793\n",
      "New best pr_auc_samples score (0.4417) at epoch-9, step-1880\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5380\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3352\n",
      "roc_auc: 0.5846\n",
      "f1: 0.2057\n",
      "loss: 0.5038\n",
      "New best pr_auc score (0.3352) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3587\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3453\n",
      "roc_auc: 0.5749\n",
      "f1: 0.2260\n",
      "loss: 0.5425\n",
      "New best pr_auc score (0.3453) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2325\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3275\n",
      "roc_auc: 0.5747\n",
      "f1: 0.2266\n",
      "loss: 0.6216\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1405\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3310\n",
      "roc_auc: 0.5815\n",
      "f1: 0.2326\n",
      "loss: 0.7277\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0883\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3399\n",
      "roc_auc: 0.5761\n",
      "f1: 0.2778\n",
      "loss: 0.8248\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0542\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3255\n",
      "roc_auc: 0.5740\n",
      "f1: 0.2232\n",
      "loss: 0.9627\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0437\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3262\n",
      "roc_auc: 0.5671\n",
      "f1: 0.2597\n",
      "loss: 1.0238\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0392\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3238\n",
      "roc_auc: 0.5742\n",
      "f1: 0.2683\n",
      "loss: 1.0968\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0291\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3283\n",
      "roc_auc: 0.5785\n",
      "f1: 0.2291\n",
      "loss: 1.1470\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0250\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3360\n",
      "roc_auc: 0.5769\n",
      "f1: 0.2597\n",
      "loss: 1.1502\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1309\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3754\n",
      "loss: 0.0933\n",
      "New best pr_auc_samples score (0.3754) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0851\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.4032\n",
      "loss: 0.0878\n",
      "New best pr_auc_samples score (0.4032) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0793\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4200\n",
      "loss: 0.0857\n",
      "New best pr_auc_samples score (0.4200) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0757\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4289\n",
      "loss: 0.0846\n",
      "New best pr_auc_samples score (0.4289) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0730\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4297\n",
      "loss: 0.0844\n",
      "New best pr_auc_samples score (0.4297) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0711\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4349\n",
      "loss: 0.0838\n",
      "New best pr_auc_samples score (0.4349) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0694\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4329\n",
      "loss: 0.0846\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0681\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4359\n",
      "loss: 0.0846\n",
      "New best pr_auc_samples score (0.4359) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0668\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4347\n",
      "loss: 0.0850\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0657\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4341\n",
      "loss: 0.0853\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5415\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3381\n",
      "roc_auc: 0.5734\n",
      "f1: 0.1615\n",
      "loss: 0.4969\n",
      "New best pr_auc score (0.3381) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3774\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3333\n",
      "roc_auc: 0.5500\n",
      "f1: 0.2147\n",
      "loss: 0.5321\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2555\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3327\n",
      "roc_auc: 0.5714\n",
      "f1: 0.2723\n",
      "loss: 0.5958\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1629\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3289\n",
      "roc_auc: 0.5722\n",
      "f1: 0.2818\n",
      "loss: 0.6851\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1047\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.2969\n",
      "roc_auc: 0.5382\n",
      "f1: 0.2531\n",
      "loss: 0.8442\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0769\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.2934\n",
      "roc_auc: 0.5295\n",
      "f1: 0.2276\n",
      "loss: 0.9239\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0513\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.2949\n",
      "roc_auc: 0.5283\n",
      "f1: 0.2344\n",
      "loss: 1.0181\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0459\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3289\n",
      "roc_auc: 0.5510\n",
      "f1: 0.2719\n",
      "loss: 1.0797\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0372\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3217\n",
      "roc_auc: 0.5557\n",
      "f1: 0.2489\n",
      "loss: 1.0901\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0384\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3181\n",
      "roc_auc: 0.5461\n",
      "f1: 0.2787\n",
      "loss: 1.1402\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1332\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3759\n",
      "loss: 0.0941\n",
      "New best pr_auc_samples score (0.3759) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0862\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.4030\n",
      "loss: 0.0877\n",
      "New best pr_auc_samples score (0.4030) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0799\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4156\n",
      "loss: 0.0857\n",
      "New best pr_auc_samples score (0.4156) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0761\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4223\n",
      "loss: 0.0843\n",
      "New best pr_auc_samples score (0.4223) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0738\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4280\n",
      "loss: 0.0834\n",
      "New best pr_auc_samples score (0.4280) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0717\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4308\n",
      "loss: 0.0832\n",
      "New best pr_auc_samples score (0.4308) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0700\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4332\n",
      "loss: 0.0834\n",
      "New best pr_auc_samples score (0.4332) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0687\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4365\n",
      "loss: 0.0831\n",
      "New best pr_auc_samples score (0.4365) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0674\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4359\n",
      "loss: 0.0835\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0663\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4359\n",
      "loss: 0.0836\n",
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): DeeprLayer(\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5300\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3095\n",
      "roc_auc: 0.5403\n",
      "f1: 0.1754\n",
      "loss: 0.5044\n",
      "New best pr_auc score (0.3095) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4106\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3180\n",
      "roc_auc: 0.5532\n",
      "f1: 0.1899\n",
      "loss: 0.5281\n",
      "New best pr_auc score (0.3180) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.3234\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3061\n",
      "roc_auc: 0.5184\n",
      "f1: 0.2105\n",
      "loss: 0.6196\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.2358\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3182\n",
      "roc_auc: 0.5342\n",
      "f1: 0.2569\n",
      "loss: 0.7074\n",
      "New best pr_auc score (0.3182) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1644\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3009\n",
      "roc_auc: 0.5267\n",
      "f1: 0.2328\n",
      "loss: 0.8514\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.1105\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3071\n",
      "roc_auc: 0.5355\n",
      "f1: 0.2469\n",
      "loss: 0.9096\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0726\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.2834\n",
      "roc_auc: 0.5160\n",
      "f1: 0.1927\n",
      "loss: 1.1674\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0465\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.2771\n",
      "roc_auc: 0.5130\n",
      "f1: 0.2069\n",
      "loss: 1.2489\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0330\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.2789\n",
      "roc_auc: 0.5161\n",
      "f1: 0.2195\n",
      "loss: 1.3887\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0199\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.2912\n",
      "roc_auc: 0.5174\n",
      "f1: 0.2478\n",
      "loss: 1.6345\n",
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): DeeprLayer(\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1060\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3949\n",
      "loss: 0.0891\n",
      "New best pr_auc_samples score (0.3949) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0832\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.4135\n",
      "loss: 0.0859\n",
      "New best pr_auc_samples score (0.4135) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0785\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4236\n",
      "loss: 0.0853\n",
      "New best pr_auc_samples score (0.4236) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0756\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4242\n",
      "loss: 0.0847\n",
      "New best pr_auc_samples score (0.4242) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0725\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4296\n",
      "loss: 0.0846\n",
      "New best pr_auc_samples score (0.4296) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0703\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4319\n",
      "loss: 0.0853\n",
      "New best pr_auc_samples score (0.4319) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0684\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4312\n",
      "loss: 0.0864\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0663\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4296\n",
      "loss: 0.0866\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0644\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4213\n",
      "loss: 0.0878\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0627\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4224\n",
      "loss: 0.0888\n",
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): DeeprLayer(\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5362\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3258\n",
      "roc_auc: 0.5424\n",
      "f1: 0.1928\n",
      "loss: 0.4903\n",
      "New best pr_auc score (0.3258) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4198\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3502\n",
      "roc_auc: 0.5830\n",
      "f1: 0.2587\n",
      "loss: 0.5023\n",
      "New best pr_auc score (0.3502) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.3306\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3416\n",
      "roc_auc: 0.5645\n",
      "f1: 0.2198\n",
      "loss: 0.5598\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.2530\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3521\n",
      "roc_auc: 0.5906\n",
      "f1: 0.2766\n",
      "loss: 0.6150\n",
      "New best pr_auc score (0.3521) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1853\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3080\n",
      "roc_auc: 0.5224\n",
      "f1: 0.2069\n",
      "loss: 0.7422\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.1317\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3402\n",
      "roc_auc: 0.5647\n",
      "f1: 0.2787\n",
      "loss: 0.7655\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0955\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3264\n",
      "roc_auc: 0.5333\n",
      "f1: 0.2569\n",
      "loss: 0.9632\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0656\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3210\n",
      "roc_auc: 0.5463\n",
      "f1: 0.2424\n",
      "loss: 1.0572\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0442\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3304\n",
      "roc_auc: 0.5464\n",
      "f1: 0.2624\n",
      "loss: 1.1852\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0313\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3248\n",
      "roc_auc: 0.5548\n",
      "f1: 0.2379\n",
      "loss: 1.3155\n",
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): DeeprLayer(\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A599F9B80>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1062\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.4023\n",
      "loss: 0.0896\n",
      "New best pr_auc_samples score (0.4023) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0831\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.4163\n",
      "loss: 0.0856\n",
      "New best pr_auc_samples score (0.4163) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0787\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4293\n",
      "loss: 0.0843\n",
      "New best pr_auc_samples score (0.4293) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0761\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4335\n",
      "loss: 0.0839\n",
      "New best pr_auc_samples score (0.4335) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0732\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4367\n",
      "loss: 0.0837\n",
      "New best pr_auc_samples score (0.4367) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0712\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4398\n",
      "loss: 0.0848\n",
      "New best pr_auc_samples score (0.4398) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0687\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4371\n",
      "loss: 0.0847\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0670\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4368\n",
      "loss: 0.0851\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0653\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4347\n",
      "loss: 0.0863\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0637\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4358\n",
      "loss: 0.0873\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5304\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2393\n",
      "roc_auc: 0.5612\n",
      "f1: 0.0000\n",
      "loss: 0.5235\n",
      "New best pr_auc score (0.2393) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.5110\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3724\n",
      "roc_auc: 0.5947\n",
      "f1: 0.2174\n",
      "loss: 0.5165\n",
      "New best pr_auc score (0.3724) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4714\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3932\n",
      "roc_auc: 0.6079\n",
      "f1: 0.2340\n",
      "loss: 0.5130\n",
      "New best pr_auc score (0.3932) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4430\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3926\n",
      "roc_auc: 0.5980\n",
      "f1: 0.2857\n",
      "loss: 0.5143\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.4123\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3812\n",
      "roc_auc: 0.6021\n",
      "f1: 0.3214\n",
      "loss: 0.5811\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.3688\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3894\n",
      "roc_auc: 0.6023\n",
      "f1: 0.3167\n",
      "loss: 0.5310\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.3359\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3684\n",
      "roc_auc: 0.5790\n",
      "f1: 0.2857\n",
      "loss: 0.5760\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.3020\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3753\n",
      "roc_auc: 0.5791\n",
      "f1: 0.3576\n",
      "loss: 0.6886\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.2734\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3742\n",
      "roc_auc: 0.5914\n",
      "f1: 0.3049\n",
      "loss: 0.7806\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.2496\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3482\n",
      "roc_auc: 0.5749\n",
      "f1: 0.3333\n",
      "loss: 0.8357\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1222\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3229\n",
      "loss: 0.1066\n",
      "New best pr_auc_samples score (0.3229) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0963\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3316\n",
      "loss: 0.0910\n",
      "New best pr_auc_samples score (0.3316) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0867\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3626\n",
      "loss: 0.0830\n",
      "New best pr_auc_samples score (0.3626) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0828\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.3717\n",
      "loss: 0.0807\n",
      "New best pr_auc_samples score (0.3717) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0811\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.3789\n",
      "loss: 0.0800\n",
      "New best pr_auc_samples score (0.3789) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0799\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.3897\n",
      "loss: 0.0806\n",
      "New best pr_auc_samples score (0.3897) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0791\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.3892\n",
      "loss: 0.0794\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0784\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.3971\n",
      "loss: 0.0799\n",
      "New best pr_auc_samples score (0.3971) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0776\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4068\n",
      "loss: 0.0788\n",
      "New best pr_auc_samples score (0.4068) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0768\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4107\n",
      "loss: 0.0785\n",
      "New best pr_auc_samples score (0.4107) at epoch-9, step-1880\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5287\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2527\n",
      "roc_auc: 0.5426\n",
      "f1: 0.0000\n",
      "loss: 0.5322\n",
      "New best pr_auc score (0.2527) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4991\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3659\n",
      "roc_auc: 0.6017\n",
      "f1: 0.1899\n",
      "loss: 0.4983\n",
      "New best pr_auc score (0.3659) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4767\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3663\n",
      "roc_auc: 0.5802\n",
      "f1: 0.2088\n",
      "loss: 0.4927\n",
      "New best pr_auc score (0.3663) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4626\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3627\n",
      "roc_auc: 0.5757\n",
      "f1: 0.2292\n",
      "loss: 0.5131\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.4415\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3866\n",
      "roc_auc: 0.6033\n",
      "f1: 0.2642\n",
      "loss: 0.5086\n",
      "New best pr_auc score (0.3866) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.4040\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3779\n",
      "roc_auc: 0.5848\n",
      "f1: 0.2593\n",
      "loss: 0.5430\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.3681\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3278\n",
      "roc_auc: 0.5819\n",
      "f1: 0.2867\n",
      "loss: 0.6553\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.3398\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3460\n",
      "roc_auc: 0.5824\n",
      "f1: 0.2835\n",
      "loss: 0.6326\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.3145\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3390\n",
      "roc_auc: 0.5771\n",
      "f1: 0.2605\n",
      "loss: 0.6330\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.2910\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3404\n",
      "roc_auc: 0.5823\n",
      "f1: 0.2212\n",
      "loss: 0.7774\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1218\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3208\n",
      "loss: 0.1035\n",
      "New best pr_auc_samples score (0.3208) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0963\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3317\n",
      "loss: 0.0907\n",
      "New best pr_auc_samples score (0.3317) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0866\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3651\n",
      "loss: 0.0823\n",
      "New best pr_auc_samples score (0.3651) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0825\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.3703\n",
      "loss: 0.0808\n",
      "New best pr_auc_samples score (0.3703) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0809\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.3762\n",
      "loss: 0.0800\n",
      "New best pr_auc_samples score (0.3762) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0801\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.3844\n",
      "loss: 0.0793\n",
      "New best pr_auc_samples score (0.3844) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0793\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.3925\n",
      "loss: 0.0788\n",
      "New best pr_auc_samples score (0.3925) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0785\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.3931\n",
      "loss: 0.0788\n",
      "New best pr_auc_samples score (0.3931) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0778\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4003\n",
      "loss: 0.0784\n",
      "New best pr_auc_samples score (0.4003) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0771\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4025\n",
      "loss: 0.0781\n",
      "New best pr_auc_samples score (0.4025) at epoch-9, step-1880\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5017\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3912\n",
      "roc_auc: 0.5989\n",
      "f1: 0.2270\n",
      "loss: 0.4901\n",
      "New best pr_auc score (0.3912) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3914\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3979\n",
      "roc_auc: 0.6119\n",
      "f1: 0.2408\n",
      "loss: 0.5066\n",
      "New best pr_auc score (0.3979) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2824\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3889\n",
      "roc_auc: 0.6050\n",
      "f1: 0.2673\n",
      "loss: 0.5343\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1754\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3956\n",
      "roc_auc: 0.6109\n",
      "f1: 0.2768\n",
      "loss: 0.5777\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0959\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3831\n",
      "roc_auc: 0.5973\n",
      "f1: 0.2636\n",
      "loss: 0.6934\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0497\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3823\n",
      "roc_auc: 0.6062\n",
      "f1: 0.2703\n",
      "loss: 0.7294\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0238\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3858\n",
      "roc_auc: 0.5958\n",
      "f1: 0.2700\n",
      "loss: 0.8545\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0107\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3896\n",
      "roc_auc: 0.6022\n",
      "f1: 0.2650\n",
      "loss: 0.9812\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0049\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3880\n",
      "roc_auc: 0.5989\n",
      "f1: 0.2905\n",
      "loss: 1.0485\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0029\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3931\n",
      "roc_auc: 0.6048\n",
      "f1: 0.2960\n",
      "loss: 1.1469\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1099\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3562\n",
      "loss: 0.0862\n",
      "New best pr_auc_samples score (0.3562) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0839\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3846\n",
      "loss: 0.0826\n",
      "New best pr_auc_samples score (0.3846) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0807\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3974\n",
      "loss: 0.0805\n",
      "New best pr_auc_samples score (0.3974) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0785\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4085\n",
      "loss: 0.0792\n",
      "New best pr_auc_samples score (0.4085) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0767\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4145\n",
      "loss: 0.0786\n",
      "New best pr_auc_samples score (0.4145) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0751\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4211\n",
      "loss: 0.0779\n",
      "New best pr_auc_samples score (0.4211) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0736\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4273\n",
      "loss: 0.0775\n",
      "New best pr_auc_samples score (0.4273) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0723\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4322\n",
      "loss: 0.0772\n",
      "New best pr_auc_samples score (0.4322) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0710\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4351\n",
      "loss: 0.0772\n",
      "New best pr_auc_samples score (0.4351) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0697\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4367\n",
      "loss: 0.0771\n",
      "New best pr_auc_samples score (0.4367) at epoch-9, step-1880\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5048\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3763\n",
      "roc_auc: 0.5921\n",
      "f1: 0.2088\n",
      "loss: 0.4832\n",
      "New best pr_auc score (0.3763) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4061\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3710\n",
      "roc_auc: 0.5896\n",
      "f1: 0.2246\n",
      "loss: 0.4984\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.3087\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3719\n",
      "roc_auc: 0.5813\n",
      "f1: 0.2353\n",
      "loss: 0.5282\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.2066\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3628\n",
      "roc_auc: 0.5805\n",
      "f1: 0.2312\n",
      "loss: 0.5866\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1298\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3629\n",
      "roc_auc: 0.5800\n",
      "f1: 0.2407\n",
      "loss: 0.6376\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0769\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3717\n",
      "roc_auc: 0.5829\n",
      "f1: 0.2636\n",
      "loss: 0.7156\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0428\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3700\n",
      "roc_auc: 0.5782\n",
      "f1: 0.2385\n",
      "loss: 0.8179\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0247\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3664\n",
      "roc_auc: 0.5755\n",
      "f1: 0.2500\n",
      "loss: 0.9238\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0136\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3698\n",
      "roc_auc: 0.5840\n",
      "f1: 0.2358\n",
      "loss: 1.0038\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0077\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3718\n",
      "roc_auc: 0.5871\n",
      "f1: 0.2562\n",
      "loss: 1.0458\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1150\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3694\n",
      "loss: 0.0859\n",
      "New best pr_auc_samples score (0.3694) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0844\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3876\n",
      "loss: 0.0815\n",
      "New best pr_auc_samples score (0.3876) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0806\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4043\n",
      "loss: 0.0794\n",
      "New best pr_auc_samples score (0.4043) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0781\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4129\n",
      "loss: 0.0784\n",
      "New best pr_auc_samples score (0.4129) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0762\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4234\n",
      "loss: 0.0778\n",
      "New best pr_auc_samples score (0.4234) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0745\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4233\n",
      "loss: 0.0776\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0728\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4306\n",
      "loss: 0.0775\n",
      "New best pr_auc_samples score (0.4306) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0713\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4349\n",
      "loss: 0.0772\n",
      "New best pr_auc_samples score (0.4349) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0699\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4369\n",
      "loss: 0.0772\n",
      "New best pr_auc_samples score (0.4369) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0686\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4381\n",
      "loss: 0.0775\n",
      "New best pr_auc_samples score (0.4381) at epoch-9, step-1880\n",
      "BRNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5055\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3825\n",
      "roc_auc: 0.6147\n",
      "f1: 0.2000\n",
      "loss: 0.4836\n",
      "New best pr_auc score (0.3825) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3676\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3851\n",
      "roc_auc: 0.6149\n",
      "f1: 0.1949\n",
      "loss: 0.5076\n",
      "New best pr_auc score (0.3851) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2258\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3625\n",
      "roc_auc: 0.6032\n",
      "f1: 0.2193\n",
      "loss: 0.5744\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1115\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3773\n",
      "roc_auc: 0.6176\n",
      "f1: 0.2308\n",
      "loss: 0.6633\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0458\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3790\n",
      "roc_auc: 0.6170\n",
      "f1: 0.2364\n",
      "loss: 0.7960\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0197\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3741\n",
      "roc_auc: 0.6247\n",
      "f1: 0.2500\n",
      "loss: 0.8561\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0072\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3719\n",
      "roc_auc: 0.6294\n",
      "f1: 0.2298\n",
      "loss: 1.0106\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0033\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3725\n",
      "roc_auc: 0.6272\n",
      "f1: 0.2521\n",
      "loss: 1.1361\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0036\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3782\n",
      "roc_auc: 0.6225\n",
      "f1: 0.2667\n",
      "loss: 1.2054\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0014\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3742\n",
      "roc_auc: 0.6224\n",
      "f1: 0.2747\n",
      "loss: 1.2981\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1102\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3526\n",
      "loss: 0.0856\n",
      "New best pr_auc_samples score (0.3526) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0840\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3819\n",
      "loss: 0.0816\n",
      "New best pr_auc_samples score (0.3819) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0806\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3974\n",
      "loss: 0.0798\n",
      "New best pr_auc_samples score (0.3974) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0784\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4111\n",
      "loss: 0.0787\n",
      "New best pr_auc_samples score (0.4111) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0765\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4224\n",
      "loss: 0.0778\n",
      "New best pr_auc_samples score (0.4224) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0749\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4288\n",
      "loss: 0.0774\n",
      "New best pr_auc_samples score (0.4288) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0734\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4355\n",
      "loss: 0.0770\n",
      "New best pr_auc_samples score (0.4355) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0719\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4376\n",
      "loss: 0.0770\n",
      "New best pr_auc_samples score (0.4376) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0706\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4397\n",
      "loss: 0.0769\n",
      "New best pr_auc_samples score (0.4397) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0693\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4427\n",
      "loss: 0.0767\n",
      "New best pr_auc_samples score (0.4427) at epoch-9, step-1880\n",
      "BRNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5082\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3807\n",
      "roc_auc: 0.5854\n",
      "f1: 0.1798\n",
      "loss: 0.4893\n",
      "New best pr_auc score (0.3807) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3784\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3696\n",
      "roc_auc: 0.5932\n",
      "f1: 0.1979\n",
      "loss: 0.5099\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2437\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3736\n",
      "roc_auc: 0.5887\n",
      "f1: 0.2268\n",
      "loss: 0.5604\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1328\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3837\n",
      "roc_auc: 0.5838\n",
      "f1: 0.2885\n",
      "loss: 0.6544\n",
      "New best pr_auc score (0.3837) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0670\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3855\n",
      "roc_auc: 0.5969\n",
      "f1: 0.2621\n",
      "loss: 0.7538\n",
      "New best pr_auc score (0.3855) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0331\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3808\n",
      "roc_auc: 0.5934\n",
      "f1: 0.2629\n",
      "loss: 0.8715\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0155\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3739\n",
      "roc_auc: 0.5879\n",
      "f1: 0.2601\n",
      "loss: 0.9455\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0092\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3751\n",
      "roc_auc: 0.5993\n",
      "f1: 0.2557\n",
      "loss: 1.0780\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0049\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3864\n",
      "roc_auc: 0.5870\n",
      "f1: 0.2634\n",
      "loss: 1.3674\n",
      "New best pr_auc score (0.3864) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0049\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3667\n",
      "roc_auc: 0.5890\n",
      "f1: 0.2533\n",
      "loss: 1.2178\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1140\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3701\n",
      "loss: 0.0867\n",
      "New best pr_auc_samples score (0.3701) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0843\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3940\n",
      "loss: 0.0825\n",
      "New best pr_auc_samples score (0.3940) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0806\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4032\n",
      "loss: 0.0804\n",
      "New best pr_auc_samples score (0.4032) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0782\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4121\n",
      "loss: 0.0794\n",
      "New best pr_auc_samples score (0.4121) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0763\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4235\n",
      "loss: 0.0785\n",
      "New best pr_auc_samples score (0.4235) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0747\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4257\n",
      "loss: 0.0780\n",
      "New best pr_auc_samples score (0.4257) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0731\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4313\n",
      "loss: 0.0776\n",
      "New best pr_auc_samples score (0.4313) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0717\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4384\n",
      "loss: 0.0772\n",
      "New best pr_auc_samples score (0.4384) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0704\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4396\n",
      "loss: 0.0772\n",
      "New best pr_auc_samples score (0.4396) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0691\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4422\n",
      "loss: 0.0772\n",
      "New best pr_auc_samples score (0.4422) at epoch-9, step-1880\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5387\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3389\n",
      "roc_auc: 0.5686\n",
      "f1: 0.1573\n",
      "loss: 0.5215\n",
      "New best pr_auc score (0.3389) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3621\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3402\n",
      "roc_auc: 0.5863\n",
      "f1: 0.2020\n",
      "loss: 0.5550\n",
      "New best pr_auc score (0.3402) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2382\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3361\n",
      "roc_auc: 0.5867\n",
      "f1: 0.1854\n",
      "loss: 0.6659\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1397\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3384\n",
      "roc_auc: 0.5808\n",
      "f1: 0.2051\n",
      "loss: 0.7770\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0891\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3575\n",
      "roc_auc: 0.5973\n",
      "f1: 0.2540\n",
      "loss: 0.8311\n",
      "New best pr_auc score (0.3575) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0550\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3522\n",
      "roc_auc: 0.5857\n",
      "f1: 0.2713\n",
      "loss: 1.0037\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0390\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3440\n",
      "roc_auc: 0.5857\n",
      "f1: 0.2114\n",
      "loss: 1.0865\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0363\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3407\n",
      "roc_auc: 0.5801\n",
      "f1: 0.2259\n",
      "loss: 1.1778\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0340\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3341\n",
      "roc_auc: 0.5661\n",
      "f1: 0.2241\n",
      "loss: 1.2842\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0262\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3437\n",
      "roc_auc: 0.5803\n",
      "f1: 0.2578\n",
      "loss: 1.3277\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1293\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3731\n",
      "loss: 0.0912\n",
      "New best pr_auc_samples score (0.3731) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0848\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3999\n",
      "loss: 0.0862\n",
      "New best pr_auc_samples score (0.3999) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0790\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4149\n",
      "loss: 0.0839\n",
      "New best pr_auc_samples score (0.4149) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0753\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4271\n",
      "loss: 0.0829\n",
      "New best pr_auc_samples score (0.4271) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0730\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4312\n",
      "loss: 0.0829\n",
      "New best pr_auc_samples score (0.4312) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0708\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4329\n",
      "loss: 0.0828\n",
      "New best pr_auc_samples score (0.4329) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0692\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4348\n",
      "loss: 0.0826\n",
      "New best pr_auc_samples score (0.4348) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0678\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4368\n",
      "loss: 0.0826\n",
      "New best pr_auc_samples score (0.4368) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0664\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4379\n",
      "loss: 0.0834\n",
      "New best pr_auc_samples score (0.4379) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0653\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4370\n",
      "loss: 0.0839\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5582\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3881\n",
      "roc_auc: 0.6319\n",
      "f1: 0.1564\n",
      "loss: 0.4977\n",
      "New best pr_auc score (0.3881) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3799\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3605\n",
      "roc_auc: 0.6127\n",
      "f1: 0.1837\n",
      "loss: 0.5230\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2462\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3554\n",
      "roc_auc: 0.6129\n",
      "f1: 0.2338\n",
      "loss: 0.5979\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1494\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3410\n",
      "roc_auc: 0.5908\n",
      "f1: 0.2213\n",
      "loss: 0.7369\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0902\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3534\n",
      "roc_auc: 0.6075\n",
      "f1: 0.2500\n",
      "loss: 0.8357\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0619\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3587\n",
      "roc_auc: 0.6123\n",
      "f1: 0.2692\n",
      "loss: 0.9151\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0473\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3508\n",
      "roc_auc: 0.5972\n",
      "f1: 0.2792\n",
      "loss: 1.0097\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0379\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3434\n",
      "roc_auc: 0.5839\n",
      "f1: 0.2609\n",
      "loss: 1.1210\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0292\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3437\n",
      "roc_auc: 0.5911\n",
      "f1: 0.2481\n",
      "loss: 1.1967\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0301\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3428\n",
      "roc_auc: 0.5879\n",
      "f1: 0.2353\n",
      "loss: 1.2706\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1328\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3776\n",
      "loss: 0.0925\n",
      "New best pr_auc_samples score (0.3776) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0863\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.4022\n",
      "loss: 0.0861\n",
      "New best pr_auc_samples score (0.4022) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0797\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4134\n",
      "loss: 0.0840\n",
      "New best pr_auc_samples score (0.4134) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0759\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4197\n",
      "loss: 0.0832\n",
      "New best pr_auc_samples score (0.4197) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0732\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4242\n",
      "loss: 0.0821\n",
      "New best pr_auc_samples score (0.4242) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0713\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4290\n",
      "loss: 0.0818\n",
      "New best pr_auc_samples score (0.4290) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0697\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4282\n",
      "loss: 0.0817\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0683\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4315\n",
      "loss: 0.0820\n",
      "New best pr_auc_samples score (0.4315) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0671\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4327\n",
      "loss: 0.0823\n",
      "New best pr_auc_samples score (0.4327) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0659\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4335\n",
      "loss: 0.0824\n",
      "New best pr_auc_samples score (0.4335) at epoch-9, step-1880\n",
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): DeeprLayer(\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5272\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3584\n",
      "roc_auc: 0.5998\n",
      "f1: 0.1582\n",
      "loss: 0.5056\n",
      "New best pr_auc score (0.3584) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3980\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3541\n",
      "roc_auc: 0.6014\n",
      "f1: 0.2121\n",
      "loss: 0.5423\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.3117\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3445\n",
      "roc_auc: 0.5959\n",
      "f1: 0.2890\n",
      "loss: 0.6040\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.2285\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3587\n",
      "roc_auc: 0.5865\n",
      "f1: 0.2432\n",
      "loss: 0.6776\n",
      "New best pr_auc score (0.3587) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1624\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3585\n",
      "roc_auc: 0.5873\n",
      "f1: 0.2443\n",
      "loss: 0.8139\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.1101\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3553\n",
      "roc_auc: 0.5927\n",
      "f1: 0.2619\n",
      "loss: 0.8729\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0693\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3433\n",
      "roc_auc: 0.5759\n",
      "f1: 0.2794\n",
      "loss: 1.0268\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0439\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3616\n",
      "roc_auc: 0.5788\n",
      "f1: 0.2776\n",
      "loss: 1.2742\n",
      "New best pr_auc score (0.3616) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0314\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3536\n",
      "roc_auc: 0.5967\n",
      "f1: 0.3000\n",
      "loss: 1.3015\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0210\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3759\n",
      "roc_auc: 0.5976\n",
      "f1: 0.2703\n",
      "loss: 1.5355\n",
      "New best pr_auc score (0.3759) at epoch-9, step-1880\n",
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): DeeprLayer(\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1062\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3942\n",
      "loss: 0.0878\n",
      "New best pr_auc_samples score (0.3942) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0828\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.4136\n",
      "loss: 0.0837\n",
      "New best pr_auc_samples score (0.4136) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0783\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4277\n",
      "loss: 0.0827\n",
      "New best pr_auc_samples score (0.4277) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0749\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4298\n",
      "loss: 0.0817\n",
      "New best pr_auc_samples score (0.4298) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0721\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4350\n",
      "loss: 0.0826\n",
      "New best pr_auc_samples score (0.4350) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0703\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4352\n",
      "loss: 0.0830\n",
      "New best pr_auc_samples score (0.4352) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0679\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4311\n",
      "loss: 0.0832\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0663\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4333\n",
      "loss: 0.0845\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0642\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4332\n",
      "loss: 0.0852\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0621\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4301\n",
      "loss: 0.0862\n",
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): DeeprLayer(\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5284\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3718\n",
      "roc_auc: 0.6042\n",
      "f1: 0.1946\n",
      "loss: 0.4920\n",
      "New best pr_auc score (0.3718) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4075\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3620\n",
      "roc_auc: 0.6065\n",
      "f1: 0.2105\n",
      "loss: 0.5293\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.3239\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3625\n",
      "roc_auc: 0.5952\n",
      "f1: 0.2189\n",
      "loss: 0.5928\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.2466\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3553\n",
      "roc_auc: 0.5822\n",
      "f1: 0.2146\n",
      "loss: 0.6622\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1805\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3570\n",
      "roc_auc: 0.5841\n",
      "f1: 0.2407\n",
      "loss: 0.7263\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.1325\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3710\n",
      "roc_auc: 0.5961\n",
      "f1: 0.2424\n",
      "loss: 0.8221\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0918\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3761\n",
      "roc_auc: 0.5962\n",
      "f1: 0.3197\n",
      "loss: 0.9028\n",
      "New best pr_auc score (0.3761) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0650\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3854\n",
      "roc_auc: 0.6087\n",
      "f1: 0.2920\n",
      "loss: 1.0235\n",
      "New best pr_auc score (0.3854) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0421\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3745\n",
      "roc_auc: 0.5941\n",
      "f1: 0.2747\n",
      "loss: 1.1775\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0272\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3953\n",
      "roc_auc: 0.6031\n",
      "f1: 0.3028\n",
      "loss: 1.4843\n",
      "New best pr_auc score (0.3953) at epoch-9, step-1880\n",
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): DeeprLayer(\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A55C8AAC0>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1071\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.4000\n",
      "loss: 0.0884\n",
      "New best pr_auc_samples score (0.4000) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0834\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.4181\n",
      "loss: 0.0838\n",
      "New best pr_auc_samples score (0.4181) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0785\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4243\n",
      "loss: 0.0823\n",
      "New best pr_auc_samples score (0.4243) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0760\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4329\n",
      "loss: 0.0823\n",
      "New best pr_auc_samples score (0.4329) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0734\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4357\n",
      "loss: 0.0826\n",
      "New best pr_auc_samples score (0.4357) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0711\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4354\n",
      "loss: 0.0821\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0690\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4341\n",
      "loss: 0.0832\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0672\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4351\n",
      "loss: 0.0838\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0657\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4356\n",
      "loss: 0.0842\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0635\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4332\n",
      "loss: 0.0852\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5280\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2941\n",
      "roc_auc: 0.6139\n",
      "f1: 0.0000\n",
      "loss: 0.5594\n",
      "New best pr_auc score (0.2941) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4934\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.4200\n",
      "roc_auc: 0.6325\n",
      "f1: 0.2347\n",
      "loss: 0.5080\n",
      "New best pr_auc score (0.4200) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4701\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.4387\n",
      "roc_auc: 0.6338\n",
      "f1: 0.2673\n",
      "loss: 0.4970\n",
      "New best pr_auc score (0.4387) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4399\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.4578\n",
      "roc_auc: 0.6336\n",
      "f1: 0.3214\n",
      "loss: 0.5094\n",
      "New best pr_auc score (0.4578) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.3951\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.4298\n",
      "roc_auc: 0.6267\n",
      "f1: 0.3217\n",
      "loss: 0.5290\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.3550\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.4283\n",
      "roc_auc: 0.6275\n",
      "f1: 0.3719\n",
      "loss: 0.5281\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.3205\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.4213\n",
      "roc_auc: 0.6314\n",
      "f1: 0.3419\n",
      "loss: 0.7065\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.2867\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.4296\n",
      "roc_auc: 0.6349\n",
      "f1: 0.3197\n",
      "loss: 0.6450\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.2601\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.4179\n",
      "roc_auc: 0.6278\n",
      "f1: 0.3826\n",
      "loss: 0.7162\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.2380\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.4163\n",
      "roc_auc: 0.6132\n",
      "f1: 0.3117\n",
      "loss: 0.8457\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1236\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3243\n",
      "loss: 0.1078\n",
      "New best pr_auc_samples score (0.3243) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0965\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3455\n",
      "loss: 0.0895\n",
      "New best pr_auc_samples score (0.3455) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0866\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3571\n",
      "loss: 0.0838\n",
      "New best pr_auc_samples score (0.3571) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0828\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.3872\n",
      "loss: 0.0809\n",
      "New best pr_auc_samples score (0.3872) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0810\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.3923\n",
      "loss: 0.0801\n",
      "New best pr_auc_samples score (0.3923) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0800\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.3916\n",
      "loss: 0.0800\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0793\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.3911\n",
      "loss: 0.0813\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0786\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4141\n",
      "loss: 0.0786\n",
      "New best pr_auc_samples score (0.4141) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0777\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4175\n",
      "loss: 0.0787\n",
      "New best pr_auc_samples score (0.4175) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0770\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4148\n",
      "loss: 0.0793\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5236\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2347\n",
      "roc_auc: 0.5207\n",
      "f1: 0.0000\n",
      "loss: 0.5578\n",
      "New best pr_auc score (0.2347) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.5166\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.2909\n",
      "roc_auc: 0.5775\n",
      "f1: 0.0000\n",
      "loss: 0.5481\n",
      "New best pr_auc score (0.2909) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4865\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.4273\n",
      "roc_auc: 0.6094\n",
      "f1: 0.2574\n",
      "loss: 0.5096\n",
      "New best pr_auc score (0.4273) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4484\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.4387\n",
      "roc_auc: 0.6085\n",
      "f1: 0.2832\n",
      "loss: 0.5288\n",
      "New best pr_auc score (0.4387) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.4121\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.4379\n",
      "roc_auc: 0.6128\n",
      "f1: 0.2991\n",
      "loss: 0.5806\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.3737\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.4247\n",
      "roc_auc: 0.6083\n",
      "f1: 0.2911\n",
      "loss: 0.6272\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.3374\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.4277\n",
      "roc_auc: 0.6123\n",
      "f1: 0.3063\n",
      "loss: 0.7372\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.3040\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.4023\n",
      "roc_auc: 0.6042\n",
      "f1: 0.3182\n",
      "loss: 0.6081\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.2887\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3395\n",
      "roc_auc: 0.6011\n",
      "f1: 0.3125\n",
      "loss: 0.8549\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.2636\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3601\n",
      "roc_auc: 0.5942\n",
      "f1: 0.3127\n",
      "loss: 0.7744\n",
      "BiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1649, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): _BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): PrePostProcessingWrapper(\n",
      "          (module): MultiHeadAttention(\n",
      "            (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (fc): PrePostProcessingWrapper(\n",
      "          (module): Sequential(\n",
      "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Dropout(p=0.1, inplace=False)\n",
      "            (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (layer_norm): LayerNorm()\n",
      "        )\n",
      "        (output_normalization): LayerNorm()\n",
      "      )\n",
      "      (1): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.0005}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1203\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3254\n",
      "loss: 0.1009\n",
      "New best pr_auc_samples score (0.3254) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0937\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3442\n",
      "loss: 0.0871\n",
      "New best pr_auc_samples score (0.3442) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0853\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.3684\n",
      "loss: 0.0829\n",
      "New best pr_auc_samples score (0.3684) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0824\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.3827\n",
      "loss: 0.0815\n",
      "New best pr_auc_samples score (0.3827) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0808\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.3922\n",
      "loss: 0.0807\n",
      "New best pr_auc_samples score (0.3922) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0800\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.3995\n",
      "loss: 0.0804\n",
      "New best pr_auc_samples score (0.3995) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0793\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4083\n",
      "loss: 0.0794\n",
      "New best pr_auc_samples score (0.4083) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0784\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4170\n",
      "loss: 0.0789\n",
      "New best pr_auc_samples score (0.4170) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0776\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4214\n",
      "loss: 0.0787\n",
      "New best pr_auc_samples score (0.4214) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0768\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4294\n",
      "loss: 0.0790\n",
      "New best pr_auc_samples score (0.4294) at epoch-9, step-1880\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.4948\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.4366\n",
      "roc_auc: 0.6337\n",
      "f1: 0.2300\n",
      "loss: 0.5060\n",
      "New best pr_auc score (0.4366) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3926\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.4314\n",
      "roc_auc: 0.6349\n",
      "f1: 0.2654\n",
      "loss: 0.5173\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2841\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.4233\n",
      "roc_auc: 0.6347\n",
      "f1: 0.2545\n",
      "loss: 0.5782\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1769\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.4205\n",
      "roc_auc: 0.6202\n",
      "f1: 0.3019\n",
      "loss: 0.6107\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0984\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.4264\n",
      "roc_auc: 0.6188\n",
      "f1: 0.3016\n",
      "loss: 0.6968\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0509\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.4129\n",
      "roc_auc: 0.6015\n",
      "f1: 0.3042\n",
      "loss: 0.8220\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0243\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.4100\n",
      "roc_auc: 0.6043\n",
      "f1: 0.2921\n",
      "loss: 0.9304\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0125\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.4088\n",
      "roc_auc: 0.5991\n",
      "f1: 0.2810\n",
      "loss: 1.1150\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0059\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.4118\n",
      "roc_auc: 0.5911\n",
      "f1: 0.2857\n",
      "loss: 1.2361\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0027\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.4113\n",
      "roc_auc: 0.5958\n",
      "f1: 0.2966\n",
      "loss: 1.2586\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1125\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3656\n",
      "loss: 0.0883\n",
      "New best pr_auc_samples score (0.3656) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0844\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3934\n",
      "loss: 0.0833\n",
      "New best pr_auc_samples score (0.3934) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0808\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4080\n",
      "loss: 0.0808\n",
      "New best pr_auc_samples score (0.4080) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0784\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4265\n",
      "loss: 0.0788\n",
      "New best pr_auc_samples score (0.4265) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0763\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4365\n",
      "loss: 0.0779\n",
      "New best pr_auc_samples score (0.4365) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0746\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4437\n",
      "loss: 0.0772\n",
      "New best pr_auc_samples score (0.4437) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0731\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4502\n",
      "loss: 0.0769\n",
      "New best pr_auc_samples score (0.4502) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0716\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4532\n",
      "loss: 0.0767\n",
      "New best pr_auc_samples score (0.4532) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0703\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4558\n",
      "loss: 0.0765\n",
      "New best pr_auc_samples score (0.4558) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0689\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4560\n",
      "loss: 0.0766\n",
      "New best pr_auc_samples score (0.4560) at epoch-9, step-1880\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5017\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.4320\n",
      "roc_auc: 0.6340\n",
      "f1: 0.2451\n",
      "loss: 0.5065\n",
      "New best pr_auc score (0.4320) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4003\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.4460\n",
      "roc_auc: 0.6511\n",
      "f1: 0.2500\n",
      "loss: 0.5147\n",
      "New best pr_auc score (0.4460) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.3012\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.4479\n",
      "roc_auc: 0.6404\n",
      "f1: 0.2731\n",
      "loss: 0.5415\n",
      "New best pr_auc score (0.4479) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.2000\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.4216\n",
      "roc_auc: 0.6307\n",
      "f1: 0.2723\n",
      "loss: 0.5992\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1198\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.4272\n",
      "roc_auc: 0.6288\n",
      "f1: 0.3278\n",
      "loss: 0.6738\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0688\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.4209\n",
      "roc_auc: 0.6248\n",
      "f1: 0.2980\n",
      "loss: 0.7560\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0374\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.4154\n",
      "roc_auc: 0.6168\n",
      "f1: 0.2720\n",
      "loss: 0.8427\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0197\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.4174\n",
      "roc_auc: 0.6154\n",
      "f1: 0.2656\n",
      "loss: 1.0117\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0111\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.4268\n",
      "roc_auc: 0.6295\n",
      "f1: 0.3004\n",
      "loss: 1.0778\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0062\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.4206\n",
      "roc_auc: 0.6225\n",
      "f1: 0.2879\n",
      "loss: 1.1417\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1129\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3626\n",
      "loss: 0.0890\n",
      "New best pr_auc_samples score (0.3626) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0846\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3959\n",
      "loss: 0.0837\n",
      "New best pr_auc_samples score (0.3959) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0809\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4103\n",
      "loss: 0.0811\n",
      "New best pr_auc_samples score (0.4103) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0785\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4225\n",
      "loss: 0.0797\n",
      "New best pr_auc_samples score (0.4225) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0766\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4335\n",
      "loss: 0.0788\n",
      "New best pr_auc_samples score (0.4335) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0751\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4424\n",
      "loss: 0.0784\n",
      "New best pr_auc_samples score (0.4424) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0736\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4463\n",
      "loss: 0.0782\n",
      "New best pr_auc_samples score (0.4463) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0721\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4504\n",
      "loss: 0.0779\n",
      "New best pr_auc_samples score (0.4504) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0709\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4528\n",
      "loss: 0.0781\n",
      "New best pr_auc_samples score (0.4528) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0697\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4532\n",
      "loss: 0.0780\n",
      "New best pr_auc_samples score (0.4532) at epoch-9, step-1880\n",
      "BRNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.4972\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.4480\n",
      "roc_auc: 0.6422\n",
      "f1: 0.2463\n",
      "loss: 0.5041\n",
      "New best pr_auc score (0.4480) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3591\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.4440\n",
      "roc_auc: 0.6484\n",
      "f1: 0.2661\n",
      "loss: 0.5313\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2177\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.4530\n",
      "roc_auc: 0.6571\n",
      "f1: 0.2894\n",
      "loss: 0.5714\n",
      "New best pr_auc score (0.4530) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1070\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.4321\n",
      "roc_auc: 0.6382\n",
      "f1: 0.2511\n",
      "loss: 0.7035\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0467\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.4409\n",
      "roc_auc: 0.6427\n",
      "f1: 0.3095\n",
      "loss: 0.7736\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0210\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.4434\n",
      "roc_auc: 0.6453\n",
      "f1: 0.2650\n",
      "loss: 0.9314\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0082\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.4496\n",
      "roc_auc: 0.6546\n",
      "f1: 0.3033\n",
      "loss: 0.9949\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0038\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.4418\n",
      "roc_auc: 0.6496\n",
      "f1: 0.2667\n",
      "loss: 1.1508\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0028\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.4434\n",
      "roc_auc: 0.6366\n",
      "f1: 0.2925\n",
      "loss: 1.2054\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0014\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.4396\n",
      "roc_auc: 0.6473\n",
      "f1: 0.2776\n",
      "loss: 1.3172\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1125\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3702\n",
      "loss: 0.0899\n",
      "New best pr_auc_samples score (0.3702) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0837\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3942\n",
      "loss: 0.0849\n",
      "New best pr_auc_samples score (0.3942) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0803\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4131\n",
      "loss: 0.0826\n",
      "New best pr_auc_samples score (0.4131) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0780\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4256\n",
      "loss: 0.0815\n",
      "New best pr_auc_samples score (0.4256) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0762\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4367\n",
      "loss: 0.0808\n",
      "New best pr_auc_samples score (0.4367) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0745\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4418\n",
      "loss: 0.0803\n",
      "New best pr_auc_samples score (0.4418) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0730\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4437\n",
      "loss: 0.0800\n",
      "New best pr_auc_samples score (0.4437) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0716\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4476\n",
      "loss: 0.0799\n",
      "New best pr_auc_samples score (0.4476) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0702\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4491\n",
      "loss: 0.0798\n",
      "New best pr_auc_samples score (0.4491) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0689\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4516\n",
      "loss: 0.0797\n",
      "New best pr_auc_samples score (0.4516) at epoch-9, step-1880\n",
      "BRNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1, bidirectional=True)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5027\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.4266\n",
      "roc_auc: 0.6164\n",
      "f1: 0.2463\n",
      "loss: 0.5085\n",
      "New best pr_auc score (0.4266) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3805\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.4371\n",
      "roc_auc: 0.6267\n",
      "f1: 0.2715\n",
      "loss: 0.5195\n",
      "New best pr_auc score (0.4371) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2481\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.4450\n",
      "roc_auc: 0.6334\n",
      "f1: 0.2831\n",
      "loss: 0.6039\n",
      "New best pr_auc score (0.4450) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1382\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.4458\n",
      "roc_auc: 0.6363\n",
      "f1: 0.3256\n",
      "loss: 0.6316\n",
      "New best pr_auc score (0.4458) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0697\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.4241\n",
      "roc_auc: 0.6206\n",
      "f1: 0.2988\n",
      "loss: 0.7878\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0338\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.4419\n",
      "roc_auc: 0.6345\n",
      "f1: 0.3484\n",
      "loss: 0.7926\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0175\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.4419\n",
      "roc_auc: 0.6284\n",
      "f1: 0.3345\n",
      "loss: 0.9203\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0081\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.4400\n",
      "roc_auc: 0.6264\n",
      "f1: 0.3407\n",
      "loss: 1.0729\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0067\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.4246\n",
      "roc_auc: 0.6079\n",
      "f1: 0.3128\n",
      "loss: 1.4920\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0044\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.4423\n",
      "roc_auc: 0.6300\n",
      "f1: 0.3491\n",
      "loss: 1.2243\n",
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): GRU(128, 128, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1122\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3647\n",
      "loss: 0.0879\n",
      "New best pr_auc_samples score (0.3647) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0846\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.3859\n",
      "loss: 0.0838\n",
      "New best pr_auc_samples score (0.3859) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0810\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4059\n",
      "loss: 0.0814\n",
      "New best pr_auc_samples score (0.4059) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0787\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4208\n",
      "loss: 0.0800\n",
      "New best pr_auc_samples score (0.4208) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0769\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4296\n",
      "loss: 0.0790\n",
      "New best pr_auc_samples score (0.4296) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0752\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4388\n",
      "loss: 0.0785\n",
      "New best pr_auc_samples score (0.4388) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0738\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4437\n",
      "loss: 0.0781\n",
      "New best pr_auc_samples score (0.4437) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0724\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4453\n",
      "loss: 0.0780\n",
      "New best pr_auc_samples score (0.4453) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0710\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4494\n",
      "loss: 0.0778\n",
      "New best pr_auc_samples score (0.4494) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0697\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4537\n",
      "loss: 0.0777\n",
      "New best pr_auc_samples score (0.4537) at epoch-9, step-1880\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5284\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3940\n",
      "roc_auc: 0.5939\n",
      "f1: 0.1684\n",
      "loss: 0.5437\n",
      "New best pr_auc score (0.3940) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3522\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3893\n",
      "roc_auc: 0.6095\n",
      "f1: 0.2555\n",
      "loss: 0.5828\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2197\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3871\n",
      "roc_auc: 0.6023\n",
      "f1: 0.2912\n",
      "loss: 0.6975\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1234\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3883\n",
      "roc_auc: 0.6042\n",
      "f1: 0.3042\n",
      "loss: 0.7953\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0808\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3788\n",
      "roc_auc: 0.5936\n",
      "f1: 0.2682\n",
      "loss: 0.9550\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0532\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.3860\n",
      "roc_auc: 0.6071\n",
      "f1: 0.2652\n",
      "loss: 1.0195\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0424\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3856\n",
      "roc_auc: 0.6064\n",
      "f1: 0.2686\n",
      "loss: 1.0906\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0324\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3982\n",
      "roc_auc: 0.6111\n",
      "f1: 0.2741\n",
      "loss: 1.2088\n",
      "New best pr_auc score (0.3982) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0254\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3999\n",
      "roc_auc: 0.6163\n",
      "f1: 0.2868\n",
      "loss: 1.2917\n",
      "New best pr_auc score (0.3999) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0278\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3936\n",
      "roc_auc: 0.6089\n",
      "f1: 0.2968\n",
      "loss: 1.3212\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1303\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3830\n",
      "loss: 0.0910\n",
      "New best pr_auc_samples score (0.3830) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0851\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.4142\n",
      "loss: 0.0861\n",
      "New best pr_auc_samples score (0.4142) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0792\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4285\n",
      "loss: 0.0841\n",
      "New best pr_auc_samples score (0.4285) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0755\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4378\n",
      "loss: 0.0830\n",
      "New best pr_auc_samples score (0.4378) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0730\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4430\n",
      "loss: 0.0822\n",
      "New best pr_auc_samples score (0.4430) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0710\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4484\n",
      "loss: 0.0825\n",
      "New best pr_auc_samples score (0.4484) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0693\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4499\n",
      "loss: 0.0828\n",
      "New best pr_auc_samples score (0.4499) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0680\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4508\n",
      "loss: 0.0823\n",
      "New best pr_auc_samples score (0.4508) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0666\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4495\n",
      "loss: 0.0826\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0655\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4471\n",
      "loss: 0.0829\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5507\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3712\n",
      "roc_auc: 0.5787\n",
      "f1: 0.1354\n",
      "loss: 0.5521\n",
      "New best pr_auc score (0.3712) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3773\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3878\n",
      "roc_auc: 0.5889\n",
      "f1: 0.2466\n",
      "loss: 0.5910\n",
      "New best pr_auc score (0.3878) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2545\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.4025\n",
      "roc_auc: 0.6019\n",
      "f1: 0.2915\n",
      "loss: 0.6537\n",
      "New best pr_auc score (0.4025) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1564\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3755\n",
      "roc_auc: 0.5709\n",
      "f1: 0.2772\n",
      "loss: 0.8002\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0962\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.4010\n",
      "roc_auc: 0.5849\n",
      "f1: 0.3011\n",
      "loss: 0.8857\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0680\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.4026\n",
      "roc_auc: 0.5802\n",
      "f1: 0.2915\n",
      "loss: 1.0461\n",
      "New best pr_auc score (0.4026) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0483\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.4077\n",
      "roc_auc: 0.5781\n",
      "f1: 0.3498\n",
      "loss: 1.1458\n",
      "New best pr_auc score (0.4077) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0376\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.4079\n",
      "roc_auc: 0.5898\n",
      "f1: 0.3416\n",
      "loss: 1.1726\n",
      "New best pr_auc score (0.4079) at epoch-7, step-1504\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0313\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.4028\n",
      "roc_auc: 0.5742\n",
      "f1: 0.3239\n",
      "loss: 1.2743\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0294\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3926\n",
      "roc_auc: 0.5712\n",
      "f1: 0.3177\n",
      "loss: 1.3807\n",
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): RETAINLayer(\n",
      "    (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "    (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "    (beta_gru): GRU(128, 128, batch_first=True)\n",
      "    (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.1334\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc_samples: 0.3838\n",
      "loss: 0.0930\n",
      "New best pr_auc_samples score (0.3838) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.0858\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc_samples: 0.4119\n",
      "loss: 0.0861\n",
      "New best pr_auc_samples score (0.4119) at epoch-1, step-376\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.0793\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc_samples: 0.4289\n",
      "loss: 0.0832\n",
      "New best pr_auc_samples score (0.4289) at epoch-2, step-564\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.0756\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc_samples: 0.4368\n",
      "loss: 0.0819\n",
      "New best pr_auc_samples score (0.4368) at epoch-3, step-752\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0732\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc_samples: 0.4416\n",
      "loss: 0.0815\n",
      "New best pr_auc_samples score (0.4416) at epoch-4, step-940\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0713\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc_samples: 0.4458\n",
      "loss: 0.0814\n",
      "New best pr_auc_samples score (0.4458) at epoch-5, step-1128\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0696\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc_samples: 0.4484\n",
      "loss: 0.0812\n",
      "New best pr_auc_samples score (0.4484) at epoch-6, step-1316\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0683\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc_samples: 0.4479\n",
      "loss: 0.0814\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0670\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc_samples: 0.4492\n",
      "loss: 0.0816\n",
      "New best pr_auc_samples score (0.4492) at epoch-8, step-1692\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0659\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc_samples: 0.4502\n",
      "loss: 0.0819\n",
      "New best pr_auc_samples score (0.4502) at epoch-9, step-1880\n",
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): DeeprLayer(\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n",
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5145\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.4174\n",
      "roc_auc: 0.6005\n",
      "f1: 0.2234\n",
      "loss: 0.5464\n",
      "New best pr_auc score (0.4174) at epoch-0, step-188\n",
      "\n",
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3988\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3721\n",
      "roc_auc: 0.5738\n",
      "f1: 0.2677\n",
      "loss: 0.5881\n",
      "\n",
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.3133\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.4023\n",
      "roc_auc: 0.6002\n",
      "f1: 0.2655\n",
      "loss: 0.6483\n",
      "\n",
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.2261\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3904\n",
      "roc_auc: 0.5874\n",
      "f1: 0.2979\n",
      "loss: 0.7546\n",
      "\n",
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1586\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3912\n",
      "roc_auc: 0.5882\n",
      "f1: 0.3460\n",
      "loss: 0.9014\n",
      "\n",
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.1105\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.4087\n",
      "roc_auc: 0.5888\n",
      "f1: 0.3000\n",
      "loss: 1.1804\n",
      "\n",
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0700\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.4021\n",
      "roc_auc: 0.5858\n",
      "f1: 0.3310\n",
      "loss: 1.2614\n",
      "\n",
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0527\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.3897\n",
      "roc_auc: 0.5792\n",
      "f1: 0.3333\n",
      "loss: 1.3938\n",
      "\n",
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0297\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.4110\n",
      "roc_auc: 0.5896\n",
      "f1: 0.3429\n",
      "loss: 1.5210\n",
      "\n",
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0226\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.4030\n",
      "roc_auc: 0.5877\n",
      "f1: 0.3123\n",
      "loss: 1.7428\n",
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3428, 128, padding_idx=0)\n",
      "    (procedures): Embedding(1358, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (model): DeeprLayer(\n",
      "    (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=467, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A570B6190>\n",
      "Monitor: pr_auc_samples\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from bitenet import BiteNet\n",
    "from baseline import RNN, BRNN, RETAIN, Deepr\n",
    "\n",
    "for seq_len in SEQ_LENS:\n",
    "\n",
    "    dataset = mimic3_ds.set_task(\n",
    "        task_fn=lambda p: patient_level_readmission_prediction(p, max_length_visits=seq_len)\n",
    "    )\n",
    "\n",
    "    for trial in range(N_TRIALS):\n",
    "\n",
    "        train, val, test = split_by_patient(dataset, [0.8, 0.1, 0.1])\n",
    "\n",
    "        train_loader = get_dataloader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = get_dataloader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        test_loader = get_dataloader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        #################### BITENET ####################\n",
    "        train_and_record_metrics(\n",
    "            model_readm=BiteNet(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "                label_key = \"readmission_label\",\n",
    "                mode = \"binary\",\n",
    "            ).to(device),\n",
    "            model_diag=BiteNet(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"procedures\", \"intervals\"],\n",
    "                label_key = \"diagnosis_label\",\n",
    "                mode = \"multilabel\",\n",
    "            ).to(device),\n",
    "            model_name=\"bitenet\",\n",
    "            feature_set=\"dxtx\",\n",
    "            seq_len=seq_len,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            lr=0.0005,\n",
    "            trial=trial\n",
    "        )\n",
    "\n",
    "        train_and_record_metrics(\n",
    "            model_readm=BiteNet(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "                label_key = \"readmission_label\",\n",
    "                mode = \"binary\",\n",
    "            ).to(device),\n",
    "            model_diag=BiteNet(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "                label_key = \"diagnosis_label\",\n",
    "                mode = \"multilabel\",\n",
    "            ).to(device),\n",
    "            model_name=\"bitenet\",\n",
    "            feature_set=\"dx\",\n",
    "            seq_len=seq_len,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            lr=0.0005,\n",
    "            trial=trial\n",
    "        )\n",
    "\n",
    "        #################### RNN ####################\n",
    "        train_and_record_metrics(\n",
    "                model_readm=RNN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "                label_key = \"readmission_label\",\n",
    "                mode = \"binary\",\n",
    "            ).to(device),\n",
    "            model_diag=RNN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "                label_key = \"diagnosis_label\",\n",
    "                mode = \"multilabel\",\n",
    "            ).to(device),\n",
    "            model_name=\"rnn\",\n",
    "            feature_set=\"dxtx\",\n",
    "            seq_len=seq_len,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            trial=trial\n",
    "        )\n",
    "\n",
    "        train_and_record_metrics(\n",
    "                model_readm=RNN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\"],\n",
    "                label_key = \"readmission_label\",\n",
    "                mode = \"binary\",\n",
    "            ).to(device),\n",
    "            model_diag=RNN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\"],\n",
    "                label_key = \"diagnosis_label\",\n",
    "                mode = \"multilabel\",\n",
    "            ).to(device),\n",
    "            model_name=\"rnn\",\n",
    "            feature_set=\"dx\",\n",
    "            seq_len=seq_len,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            trial=trial\n",
    "        )\n",
    "\n",
    "        #################### BRNN ####################\n",
    "        train_and_record_metrics(\n",
    "                model_readm=BRNN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "                label_key = \"readmission_label\",\n",
    "                mode = \"binary\",\n",
    "                bidirectional=True\n",
    "            ).to(device),\n",
    "            model_diag=RNN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "                label_key = \"diagnosis_label\",\n",
    "                mode = \"multilabel\",\n",
    "                bidirectional=True\n",
    "            ).to(device),\n",
    "            model_name=\"brnn\",\n",
    "            feature_set=\"dxtx\",\n",
    "            seq_len=seq_len,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            trial=trial\n",
    "        )\n",
    "\n",
    "        train_and_record_metrics(\n",
    "                model_readm=BRNN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\"],\n",
    "                label_key = \"readmission_label\",\n",
    "                mode = \"binary\",\n",
    "                bidirectional=True\n",
    "            ).to(device),\n",
    "            model_diag=RNN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\"],\n",
    "                label_key = \"diagnosis_label\",\n",
    "                mode = \"multilabel\",\n",
    "                bidirectional=True\n",
    "            ).to(device),\n",
    "            model_name=\"brnn\",\n",
    "            feature_set=\"dx\",\n",
    "            seq_len=seq_len,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            trial=trial\n",
    "        )\n",
    "\n",
    "        #################### RETAIN ####################\n",
    "        train_and_record_metrics(\n",
    "                model_readm=RETAIN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "                label_key = \"readmission_label\",\n",
    "                mode = \"binary\"\n",
    "            ).to(device),\n",
    "            model_diag=RETAIN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "                label_key = \"diagnosis_label\",\n",
    "                mode = \"multilabel\"\n",
    "            ).to(device),\n",
    "            model_name=\"retain\",\n",
    "            feature_set=\"dxtx\",\n",
    "            seq_len=seq_len,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            trial=trial\n",
    "        )\n",
    "\n",
    "        train_and_record_metrics(\n",
    "                model_readm=RETAIN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\"],\n",
    "                label_key = \"readmission_label\",\n",
    "                mode = \"binary\"\n",
    "            ).to(device),\n",
    "            model_diag=RETAIN(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\"],\n",
    "                label_key = \"diagnosis_label\",\n",
    "                mode = \"multilabel\"\n",
    "            ).to(device),\n",
    "            model_name=\"retain\",\n",
    "            feature_set=\"dx\",\n",
    "            seq_len=seq_len,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            trial=trial\n",
    "        )\n",
    "\n",
    "        #################### Deepr ####################\n",
    "        train_and_record_metrics(\n",
    "                model_readm=Deepr(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "                label_key = \"readmission_label\",\n",
    "                mode = \"binary\"\n",
    "            ).to(device),\n",
    "            model_diag=Deepr(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\", \"procedures\"],\n",
    "                label_key = \"diagnosis_label\",\n",
    "                mode = \"multilabel\"\n",
    "            ).to(device),\n",
    "            model_name=\"deepr\",\n",
    "            feature_set=\"dxtx\",\n",
    "            seq_len=seq_len,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            trial=trial\n",
    "        )\n",
    "\n",
    "        train_and_record_metrics(\n",
    "                model_readm=Deepr(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\"],\n",
    "                label_key = \"readmission_label\",\n",
    "                mode = \"binary\"\n",
    "            ).to(device),\n",
    "            model_diag=Deepr(\n",
    "                dataset = dataset,\n",
    "                feature_keys = [\"diagnoses\"],\n",
    "                label_key = \"diagnosis_label\",\n",
    "                mode = \"multilabel\"\n",
    "            ).to(device),\n",
    "            model_name=\"deepr\",\n",
    "            feature_set=\"dx\",\n",
    "            seq_len=seq_len,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            test_loader=test_loader,\n",
    "            trial=trial\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T13:04:34.134126Z",
     "end_time": "2023-05-04T13:08:05.248126Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name feature_set seq_len    pr_auc   roc_auc        f1  precision@5   \n",
      "0    bitenet        dxtx       6  0.375744  0.591116  0.304348     0.418667  \\\n",
      "1    bitenet        dxtx       8  0.358171  0.574900  0.229167     0.000000   \n",
      "2    bitenet        dxtx      10  0.357258  0.596695  0.296610     0.880222   \n",
      "3    bitenet        dxtx      12  0.385917  0.622832  0.270492     0.961333   \n",
      "4    bitenet        dxtx      14  0.264675  0.529203  0.184615     0.184778   \n",
      "\n",
      "   precision@10  precision@15  precision@20  precision@25  precision@30  \n",
      "0      0.636000      0.754667      0.828000      0.864000      0.882667  \n",
      "1      0.000000      0.000000      0.000000      0.000000      0.000000  \n",
      "2      0.860667      0.860000      0.849778      0.840222      0.834444  \n",
      "3      0.964000      0.965333      1.000000      1.000000      1.000000  \n",
      "4      0.239667      0.259444      0.272000      0.278556      0.284000  \n"
     ]
    }
   ],
   "source": [
    "print(metrics_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T12:41:54.246125Z",
     "end_time": "2023-05-04T12:41:54.257123Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
