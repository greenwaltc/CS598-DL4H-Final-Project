{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Google Cloud authentication and data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=mA4KTl8iW7ExFCgiSIGV20WPRGNlqP&access_type=offline&code_challenge=xuy5gjuf9GwNlmobryR0GgFOlCXznHfpqWf2kC4oOvM&code_challenge_method=S256\n",
      "\n",
      "\n",
      "You are now logged in as [camerongreenwalt@gmail.com].\n",
      "Your current project is [dl4h-final-project-383605].  You can change this setting by running:\n",
      "  $ gcloud config set project PROJECT_ID\n",
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=VhRb04TAkTK1P44NMUbqMETl8LbKmJ&access_type=offline&code_challenge=kI_eC118DoXyOitFkk97dyveJMvPc3wJ6vZzl6sMbeE&code_challenge_method=S256\n",
      "\n",
      "\n",
      "Credentials saved to file: [C:\\Users\\camer\\AppData\\Roaming\\gcloud\\application_default_credentials.json]\n",
      "\n",
      "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
      "\n",
      "Quota project \"dl4h-final-project-383605\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n",
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth login\n",
    "! gcloud auth application-default login\n",
    "! gcloud config set project dl4h-final-project-383605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pCHvVcifGcdr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-api-python-client in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (2.86.0)\n",
      "Requirement already satisfied: google-cloud-storage in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (2.17.3)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (4.1.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (0.1.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-python-client) (2.11.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-cloud-storage) (2.28.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-cloud-storage) (2.3.2)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-cloud-storage) (2.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.59.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (4.22.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (5.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (1.16.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.19.0->google-api-python-client) (0.5.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade google-api-python-client google-cloud-storage\n",
    "from google.cloud import storage\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Replace these values with your project and bucket as needed\n",
    "project_id = \"dl4h-final-project-383605\"\n",
    "mimic3_bucket = \"mimiciii-1.4.physionet.org\"\n",
    "\n",
    "storage_client = storage.Client(project=project_id)\n",
    "bucket = storage_client.bucket(mimic3_bucket)\n",
    "data_folder = \"data\"\n",
    "for blob in bucket.list_blobs():\n",
    "    if \"CHARTEVENTS\" in blob.name:\n",
    "        continue\n",
    "\n",
    "    gz_path = f\"{data_folder}/{blob.name}\"\n",
    "    blob.download_to_filename(gz_path)\n",
    "\n",
    "    with gzip.open(gz_path, 'rb') as f_in:\n",
    "        with open(gz_path.replace(\".gz\", \"\"), 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    os.remove(gz_path)\n",
    "\n",
    "# # Extract all the files\n",
    "# ! gunzip {data_folder}/*.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall torch torchvision torchaudio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Library imports and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:06:09.229193Z",
     "end_time": "2023-04-29T19:06:28.987194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyhealth in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (1.1.3)\n",
      "Requirement already satisfied: networkx>=2.6.3 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyhealth) (3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyhealth) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pyhealth) (2.0.0+cu118)\n",
      "Requirement already satisfied: pandas>=1.3.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyhealth) (2.0.1)\n",
      "Requirement already satisfied: rdkit>=2022.03.4 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyhealth) (2022.9.5)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pyhealth) (1.2.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pandas>=1.3.2->pyhealth) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from pandas>=1.3.2->pyhealth) (1.24.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pandas>=1.3.2->pyhealth) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from pandas>=1.3.2->pyhealth) (2.8.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from rdkit>=2022.03.4->pyhealth) (9.3.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from scikit-learn>=0.24.2->pyhealth) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from scikit-learn>=0.24.2->pyhealth) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from scikit-learn>=0.24.2->pyhealth) (3.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.8.0->pyhealth) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.8.0->pyhealth) (4.4.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.8.0->pyhealth) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch>=1.8.0->pyhealth) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from tqdm->pyhealth) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\camer\\pycharmprojects\\cs598-dl4h-final-project\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.3.2->pyhealth) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from jinja2->torch>=1.8.0->pyhealth) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\camer\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from sympy->torch>=1.8.0->pyhealth) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "C:\\Users\\camer\\PycharmProjects\\CS598-DL4H-Final-Project\\venv\\lib\\site-packages\\pyhealth\\trainer.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    }
   ],
   "source": [
    "! pip install pyhealth\n",
    "from pyhealth.datasets import MIMIC3Dataset, SampleDataset\n",
    "from pyhealth.data import Patient, Visit, Event\n",
    "import pandas as pd\n",
    "from pyhealth.datasets import split_by_patient, get_dataloader\n",
    "from pyhealth.models import BaseModel, RNN, RETAIN, Deepr\n",
    "from pyhealth.trainer import Trainer\n",
    "from pyhealth.metrics.binary import binary_metrics_fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Dict, Optional\n",
    "from enum import Enum\n",
    "from functools import reduce\n",
    "from operator import mul\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set this to the directory with all MIMIC-3 dataset files\n",
    "data_root = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s-VgeMdJDYYK",
    "outputId": "9cb9c08a-9003-4836-a3b2-a23e7cd45b55",
    "ExecuteTime": {
     "start_time": "2023-04-29T19:07:07.568180Z",
     "end_time": "2023-04-29T19:07:11.860179Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "mimic3_ds = MIMIC3Dataset(\n",
    "        root=data_root,\n",
    "        tables=[\"DIAGNOSES_ICD\", \"PROCEDURES_ICD\"],\n",
    "        dev=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "HQdeU1TLU6m_",
    "outputId": "590623d6-2917-4155-bf0a-5d75a3979c25",
    "ExecuteTime": {
     "start_time": "2023-04-29T19:07:16.710274Z",
     "end_time": "2023-04-29T19:07:16.917151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 46520\n",
      "\t- Number of visits: 58976\n",
      "\t- Number of visits per patient: 1.2678\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0711\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 46520\\n\\t- Number of visits: 58976\\n\\t- Number of visits per patient: 1.2678\\n\\t- Number of events per visit in DIAGNOSES_ICD: 11.0384\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0711\\n'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print dataset statistics\n",
    "\n",
    "mimic3_ds.stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Find all diagnoses codes\n",
    "# Remove diagnoses codes with fewer than 5 occurences in the dataset\n",
    "\n",
    "all_diagnosis_codes = []\n",
    "for patient_id, patient in mimic3_ds.patients.items():\n",
    "  for i in range(len(patient)):\n",
    "    visit: Visit = patient[i]\n",
    "    conditions = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "    all_diagnosis_codes.extend(conditions)\n",
    "\n",
    "codes = pd.Series(all_diagnosis_codes)\n",
    "diag_code_counts = codes.value_counts()\n",
    "filtered_diag_codes = diag_code_counts[diag_code_counts > 4].index.values\n",
    "num_unique_diag_codes = len(filtered_diag_codes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:07:20.205235Z",
     "end_time": "2023-04-29T19:07:20.581271Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7496/7496 [00:28<00:00, 266.93it/s]\n"
     ]
    }
   ],
   "source": [
    "MIN_NUM_VISITS_PER_PATIENT = 2\n",
    "\n",
    "filtered_patients = {}\n",
    "for patient_id, patient in tqdm(mimic3_ds.patients.items()):\n",
    "\n",
    "    filtered_patient: Patient = Patient(\n",
    "        patient_id=patient.patient_id,\n",
    "        birth_datetime=patient.birth_datetime,\n",
    "        death_datetime=patient.death_datetime,\n",
    "        gender=patient.gender,\n",
    "        ethnicity=patient.ethnicity\n",
    "    )\n",
    "\n",
    "    for i_visit, visit in enumerate(patient):\n",
    "        filtered_visit: Visit = Visit(\n",
    "            visit_id=visit.visit_id,\n",
    "            patient_id=visit.patient_id,\n",
    "            encounter_time=visit.encounter_time,\n",
    "            discharge_time=visit.discharge_time,\n",
    "            discharge_status=visit.discharge_status\n",
    "        )\n",
    "\n",
    "        diagnoses_codes = visit.get_code_list(\"DIAGNOSES_ICD\")\n",
    "        procedures_codes = visit.get_code_list(\"PROCEDURES_ICD\")\n",
    "\n",
    "        if len(diagnoses_codes) > 0:\n",
    "            diagnosis_events = visit.event_list_dict[\"DIAGNOSES_ICD\"]\n",
    "            for i_event in range(len(diagnosis_events) - 1, -1, -1):\n",
    "                event: Event = diagnosis_events[i_event]\n",
    "                if event.code not in filtered_diag_codes:\n",
    "                    diagnosis_events.pop(i_event) # Remove the diagnosis code with fewer than the cutoff occurrences\n",
    "\n",
    "            if len(diagnosis_events) == 0: continue # Don't include visits with no diagnoses\n",
    "\n",
    "            filtered_visit.set_event_list(\"DIAGNOSES_ICD\", diagnosis_events)\n",
    "        else:\n",
    "            continue # Don't include visits with no diagnoses\n",
    "\n",
    "        if len(procedures_codes) > 0:\n",
    "           filtered_visit.set_event_list(\"PROCEDURES_ICD\", visit.event_list_dict[\"PROCEDURES_ICD\"])\n",
    "\n",
    "        filtered_patient.add_visit(filtered_visit)\n",
    "\n",
    "    if len(filtered_patient.visits) >= MIN_NUM_VISITS_PER_PATIENT:\n",
    "        filtered_patients[patient_id] = filtered_patient\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:10:54.540303Z",
     "end_time": "2023-04-29T19:11:22.642196Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistics of base dataset (dev=False):\n",
      "\t- Dataset: MIMIC3Dataset\n",
      "\t- Number of patients: 7496\n",
      "\t- Number of visits: 19905\n",
      "\t- Number of visits per patient: 2.6554\n",
      "\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\n",
      "\t- Number of events per visit in PROCEDURES_ICD: 4.0975\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\nStatistics of base dataset (dev=False):\\n\\t- Dataset: MIMIC3Dataset\\n\\t- Number of patients: 7496\\n\\t- Number of visits: 19905\\n\\t- Number of visits per patient: 2.6554\\n\\t- Number of events per visit in DIAGNOSES_ICD: 12.9735\\n\\t- Number of events per visit in PROCEDURES_ICD: 4.0975\\n'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic3_ds.patients = filtered_patients\n",
    "mimic3_ds.stat()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:11:25.093225Z",
     "end_time": "2023-04-29T19:11:25.159223Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fgrnO7KkWDBY",
    "ExecuteTime": {
     "start_time": "2023-04-29T19:11:44.037632Z",
     "end_time": "2023-04-29T19:11:44.048152Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the tasks\n",
    "\n",
    "DIAGNOSES_KEY = \"conditions\"\n",
    "PROCEDURES_KEY = \"procedures\"\n",
    "INTERVAL_DAYS_KEY = \"days_since_first_visit\"\n",
    "\n",
    "def flatten(l: List):\n",
    "    return [item for sublist in l for item in sublist]\n",
    "\n",
    "def patient_level_readmission_prediction(patient, time_window: int = 30, max_length_visits: int = None):\n",
    "    \"\"\"\n",
    "    patient is a <pyhealth.data.Patient> object\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "\n",
    "    # # if the patient only has one visit, we drop it\n",
    "    # if len(patient) <= 1:\n",
    "    #     return []\n",
    "\n",
    "    sorted_visits = sorted(patient, key=lambda visit: visit.encounter_time)\n",
    "\n",
    "    # Clip the patient visits to the most recent max_length_visits + 1 if max_length_visits is not None\n",
    "    if max_length_visits is not None:\n",
    "        n_visits = len(sorted_visits)\n",
    "        if n_visits > max_length_visits + 1:\n",
    "            sorted_visits = sorted_visits[n_visits - (max_length_visits + 1):]\n",
    "\n",
    "    feature_visits: List[Visit] = sorted_visits[:-1]\n",
    "    last_visit: Visit = sorted_visits[-1]\n",
    "    second_to_last_visit: Visit = feature_visits[-1]\n",
    "    first_visit: Visit = feature_visits[0]\n",
    "\n",
    "    # step 1: define label\n",
    "    time_diff = (last_visit.encounter_time - second_to_last_visit.encounter_time).days\n",
    "    readmission_label = 1 if time_diff <= time_window else 0\n",
    "\n",
    "    # step 2: obtain features\n",
    "    visits_diagnoses = []\n",
    "    visits_procedures = []\n",
    "    visits_intervals = []\n",
    "    for idx, visit in enumerate(feature_visits):\n",
    "        diagnoses = visit.get_code_list(table=\"DIAGNOSES_ICD\")\n",
    "        procedures = visit.get_code_list(table=\"PROCEDURES_ICD\")\n",
    "        time_diff_from_first_visit = (visit.encounter_time - first_visit.encounter_time).days\n",
    "\n",
    "        if len(diagnoses) == 0:\n",
    "            continue\n",
    "\n",
    "        visits_diagnoses.append(diagnoses)\n",
    "        visits_procedures.append(procedures)\n",
    "        visits_intervals.append([str(time_diff_from_first_visit)])\n",
    "\n",
    "    unique_diagnoses = list(set(flatten(visits_diagnoses)))\n",
    "\n",
    "    # step 3: exclusion criteria\n",
    "    if len(unique_diagnoses) == 0:\n",
    "        return []\n",
    "\n",
    "    # step 4: assemble the sample\n",
    "    samples.append(\n",
    "        {\n",
    "            \"patient_id\": patient.patient_id,\n",
    "            \"visit_id\": visit.visit_id,\n",
    "            \"diagnoses\": visits_diagnoses,\n",
    "            \"procedures\": visits_procedures,\n",
    "            \"intervals\": visits_intervals,\n",
    "            \"label\": readmission_label,\n",
    "        }\n",
    "    )\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "IMD0MvgA8e8Z",
    "outputId": "11b7f21f-9f3b-419c-ee21-69ec1e3e02fe",
    "ExecuteTime": {
     "start_time": "2023-04-29T19:11:44.427154Z",
     "end_time": "2023-04-29T19:11:44.733169Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating samples for patient_level_readmission_prediction: 100%|██████████| 7496/7496 [00:00<00:00, 54715.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7496\n"
     ]
    }
   ],
   "source": [
    "# Create the task datasets\n",
    "mimic3_dxtx = mimic3_ds.set_task(task_fn=patient_level_readmission_prediction)\n",
    "print(len(mimic3_dxtx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train, val, test = split_by_patient(mimic3_dxtx, [0.8, 0.1, 0.1])\n",
    "\n",
    "train_loader = get_dataloader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = get_dataloader(val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = get_dataloader(test, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:11:45.906058Z",
     "end_time": "2023-04-29T19:11:45.929079Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:32:44.255222Z",
     "end_time": "2023-04-29T19:32:44.358231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'loss': tensor(0.7187, device='cuda:0',\n        grad_fn=<BinaryCrossEntropyWithLogitsBackward0>),\n 'y_prob': tensor([[0.5304],\n         [0.5232],\n         [0.5188],\n         [0.5250],\n         [0.5200],\n         [0.5270],\n         [0.5211],\n         [0.5236],\n         [0.5268],\n         [0.5233],\n         [0.5215],\n         [0.5238],\n         [0.5421],\n         [0.5246],\n         [0.5195],\n         [0.5147],\n         [0.5242],\n         [0.5218],\n         [0.5230],\n         [0.5236],\n         [0.5169],\n         [0.5177],\n         [0.5298],\n         [0.5245],\n         [0.5210],\n         [0.5209],\n         [0.5161],\n         [0.5250],\n         [0.5211],\n         [0.5304],\n         [0.5211],\n         [0.5244]], device='cuda:0', grad_fn=<SigmoidBackward0>),\n 'y_true': tensor([[1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.],\n         [0.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]], device='cuda:0')}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the models\n",
    "VERY_BIG_NUMBER = 1e30\n",
    "VERY_SMALL_NUMBER = 1e-30\n",
    "VERY_POSITIVE_NUMBER = VERY_BIG_NUMBER\n",
    "VERY_NEGATIVE_NUMBER = -VERY_BIG_NUMBER\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "class MaskDirection(Enum):\n",
    "    FORWARD = 'forward'\n",
    "    BACKWARD = 'backward'\n",
    "    DIAGONAL = 'diagonal'\n",
    "    NONE = 'none'\n",
    "\n",
    "class MaskedLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape: int):\n",
    "        super().__init__()\n",
    "        self.scale = nn.parameter.Parameter(torch.ones(normalized_shape, dtype=torch.float32, device=device))\n",
    "        self.bias = nn.parameter.Parameter(torch.zeros(normalized_shape, dtype=torch.float32, device=device))\n",
    "        self.normalized_shape = normalized_shape\n",
    "\n",
    "    def forward(self, x: torch.Tensor, eps=1e-5):\n",
    "        mean = torch.mean(x, dim=-1, keepdim=True)\n",
    "        variance = torch.mean(torch.square(x - mean), dim=-1, keepdim=True)\n",
    "        norm_x = (x - mean) * torch.rsqrt(variance + eps)\n",
    "        return norm_x * self.scale + self.bias\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, keep: int):\n",
    "        fixed_shape = list(x.size())\n",
    "        start = len(fixed_shape) - keep\n",
    "        left = reduce(mul, [fixed_shape[i] or x.shape[i] for i in range(start)])\n",
    "        out_shape = [left] + [fixed_shape[i] or x.shape[i] for i in range(start, len(fixed_shape))]\n",
    "        return torch.reshape(x, out_shape)\n",
    "\n",
    "\n",
    "class Unflatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, v: torch.Tensor, ref: torch.Tensor, embedding_dim):\n",
    "        batch_size = ref.shape[0]\n",
    "        n_visits = ref.shape[1]\n",
    "        out = torch.reshape(v, [batch_size, n_visits, embedding_dim])\n",
    "        return out\n",
    "\n",
    "\n",
    "class AttentionPooling(nn.Module):\n",
    "    def __init__(self, embedding_size: int):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_size, embedding_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_size, embedding_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, mask = inputs\n",
    "        x = self.fc(x)\n",
    "        x[mask] = VERY_NEGATIVE_NUMBER\n",
    "        soft = F.softmax(x, dim=1)\n",
    "        x[mask] = 0\n",
    "        attn_output = torch.sum(soft * x, 1)\n",
    "        return attn_output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, direction, dropout, num_units, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.direction = direction\n",
    "        self.num_units = num_units\n",
    "        self.q_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.k_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.v_linear = nn.Linear(num_units, num_units, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # because of self-attention, queries and keys is equal to inputs\n",
    "        input_tensor, input_mask = inputs\n",
    "        queries = input_tensor\n",
    "        keys = input_tensor\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.q_linear(queries)  # (N, L_q, d)\n",
    "        K = self.k_linear(keys)  # (N, L_k, d)\n",
    "        V = self.v_linear(keys)  # (N, L_k, d)\n",
    "\n",
    "        # print('Q shape: ', Q.get_shape())\n",
    "\n",
    "        # Split and concat\n",
    "        assert self.num_units % self.num_heads == 0\n",
    "        Q_ = torch.cat(torch.split(Q, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_q, d/h)\n",
    "        K_ = torch.cat(torch.split(K, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_k, d/h)\n",
    "        V_ = torch.cat(torch.split(V, self.num_units // self.num_heads, dim=2), dim=0)  # (h*N, L_k, d/h)\n",
    "\n",
    "        # Multiplication\n",
    "        outputs = torch.matmul(Q_, torch.permute(K_, [0, 2, 1]))  # (h*N, L_q, L_k)\n",
    "\n",
    "        # Scale\n",
    "        outputs = outputs / (list(K_.shape)[-1] ** 0.5)  # (h*N, L_q, L_k)\n",
    "\n",
    "        # Key Masking\n",
    "        key_masks = torch.sign(torch.sum(torch.abs(K_), dim=-1))  # (h*N, T_k)\n",
    "        key_masks = torch.unsqueeze(key_masks, 1)  # (h*N, 1, T_k)\n",
    "        key_masks = torch.tile(key_masks, [1, list(Q_.shape)[1], 1])  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Apply masks to outputs\n",
    "        paddings = torch.ones_like(outputs, device=device) * (-2 ** 32 + 1)  # exp mask\n",
    "        outputs = torch.where(key_masks == 0, paddings, outputs)  # (h*N, T_q, T_k)\n",
    "\n",
    "        n_visits = list(input_tensor.shape)[1]\n",
    "        sw_indices = torch.arange(0, n_visits, dtype=torch.int32, device=device)\n",
    "        sw_col, sw_row = torch.meshgrid(sw_indices, sw_indices)\n",
    "        if self.direction == MaskDirection.DIAGONAL:\n",
    "            # shape of (n_visits, n_visits)\n",
    "            attention_mask = (torch.diag(- torch.ones([n_visits], dtype=torch.int32, device=device)) + 1).bool()\n",
    "        elif self.direction == MaskDirection.FORWARD:\n",
    "            attention_mask = torch.greater(sw_row, sw_col)  # shape of (n_visits, n_visits)\n",
    "        else: # MaskDirection.BACKWARD\n",
    "            attention_mask = torch.greater(sw_col, sw_row)  # shape of (n_visits, n_visits)\n",
    "        adder = (1.0 - attention_mask.type(outputs.dtype)) * -10000.0\n",
    "        outputs += adder\n",
    "\n",
    "        # softmax\n",
    "        outputs = F.softmax(outputs, -1)  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Query Masking\n",
    "        query_masks = torch.sign(torch.sum(torch.abs(Q_), dim=-1))  # (h*N, T_q)\n",
    "        query_masks = torch.unsqueeze(query_masks, -1)  # (h*N, T_q, 1)\n",
    "        query_masks = torch.tile(query_masks, [1, 1, list(K_.shape)[1]])  # (h*N, T_q, T_k)\n",
    "\n",
    "        # Apply masks to outputs\n",
    "        outputs = outputs * query_masks\n",
    "\n",
    "        # Dropouts\n",
    "        outputs = self.dropout(outputs)\n",
    "        # Weighted sum\n",
    "        outputs = torch.matmul(outputs, V_)  # ( h*N, T_q, C/h)\n",
    "\n",
    "        # Restore shape\n",
    "        outputs = torch.cat(torch.split(outputs, outputs.shape[0] // self.num_heads, dim=0), dim=2)  # (N, L_q, d)\n",
    "\n",
    "        # input padding\n",
    "        val_mask = torch.unsqueeze(input_mask, -1)\n",
    "        outputs = torch.multiply(outputs, (~val_mask).float())\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class MaskEnc(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int,\n",
    "            num_heads: int,\n",
    "            dropout: float = 0.1,\n",
    "            temporal_mask_direction: MaskDirection = MaskDirection.NONE,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.temporal_mask_direction = temporal_mask_direction\n",
    "\n",
    "        self.attention = MultiHeadAttention(\n",
    "            direction=temporal_mask_direction,\n",
    "            dropout=dropout,\n",
    "            num_units=embedding_dim,\n",
    "            num_heads=num_heads\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embedding_dim, embedding_dim)\n",
    "        )\n",
    "\n",
    "        self.layer_norm1 = MaskedLayerNorm(embedding_dim)\n",
    "        self.layer_norm2 = MaskedLayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, key_padding_mask = inputs\n",
    "\n",
    "        attn_output = self.attention((x, key_padding_mask))\n",
    "        attn_output = self.layer_norm1(x + attn_output)\n",
    "        out = self.fc(attn_output)\n",
    "        out = out * (~key_padding_mask.unsqueeze(-1)).float()\n",
    "        out = self.layer_norm2(out + attn_output)\n",
    "        out = out * (~key_padding_mask.unsqueeze(-1)).float()\n",
    "\n",
    "        return out, key_padding_mask\n",
    "\n",
    "    def _make_temporal_mask(self, n: int) -> Optional[torch.Tensor]:\n",
    "        if self.temporal_mask_direction == MaskDirection.NONE:\n",
    "            return None\n",
    "        if self.temporal_mask_direction == MaskDirection.FORWARD:\n",
    "            return torch.tril(torch.full((n, n), -10000, device=device)).fill_diagonal_(0).float()\n",
    "        if self.temporal_mask_direction == MaskDirection.BACKWARD:\n",
    "            return torch.triu(torch.full((n, n), -10000, device=device)).fill_diagonal_(0).float()\n",
    "        if self.temporal_mask_direction == MaskDirection.DIAGONAL:\n",
    "            return torch.zeros(n, n, device=device).fill_diagonal_(-10000).float()\n",
    "\n",
    "\n",
    "class BiteNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim: int = 128,\n",
    "            num_heads: int = 4,\n",
    "            dropout: float = 0.1,\n",
    "            n_mask_enc_layers: int = 2,\n",
    "            use_procedures: bool = True,\n",
    "            use_intervals: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_intervals = use_intervals\n",
    "        self.use_procedures = use_procedures\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.flatten = Flatten()\n",
    "        self.unflatten = Unflatten()\n",
    "\n",
    "        def _make_mask_enc_block(temporal_mask_direction: MaskDirection = MaskDirection.NONE):\n",
    "            return MaskEnc(\n",
    "                embedding_dim = embedding_dim,\n",
    "                num_heads = num_heads,\n",
    "                dropout = dropout,\n",
    "                temporal_mask_direction = temporal_mask_direction,\n",
    "            )\n",
    "\n",
    "        self.code_attn = nn.Sequential()\n",
    "        self.visit_attn_fw = nn.Sequential()\n",
    "        self.visit_attn_bw = nn.Sequential()\n",
    "        for _ in range(n_mask_enc_layers):\n",
    "            self.code_attn.append(_make_mask_enc_block(MaskDirection.DIAGONAL))\n",
    "            self.visit_attn_fw.append(_make_mask_enc_block(MaskDirection.FORWARD))\n",
    "            self.visit_attn_bw.append(_make_mask_enc_block(MaskDirection.BACKWARD))\n",
    "\n",
    "        # Attention pooling layers\n",
    "        self.code_attn.append(AttentionPooling(embedding_dim))\n",
    "        self.visit_attn_fw.append(AttentionPooling(embedding_dim))\n",
    "        self.visit_attn_bw.append(AttentionPooling(embedding_dim))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*embedding_dim, embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            embedded_codes: torch.Tensor,\n",
    "            embedded_intervals: torch.Tensor,\n",
    "            codes_mask: torch.Tensor,\n",
    "            visits_mask: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        codes_mask = ~(codes_mask.bool())\n",
    "\n",
    "        # input tensor, reshape 4 dimension to 3\n",
    "        flattened_codes = self.flatten(embedded_codes, 2)\n",
    "\n",
    "        # input mask, reshape 3 dimension to 2\n",
    "        flattened_codes_mask = self.flatten(codes_mask, 1)\n",
    "\n",
    "        code_attn = self.code_attn((flattened_codes, flattened_codes_mask))\n",
    "        code_attn = self.unflatten(code_attn, embedded_codes, self.embedding_dim)\n",
    "\n",
    "        if self.use_intervals:\n",
    "            code_attn += embedded_intervals\n",
    "\n",
    "        visits_mask = ~(visits_mask.bool())\n",
    "\n",
    "        u_fw = self.visit_attn_fw((code_attn, visits_mask))\n",
    "        u_bw = self.visit_attn_bw((code_attn, visits_mask))\n",
    "        u_bi = torch.cat([u_fw, u_bw], dim=-1)\n",
    "\n",
    "        s = self.fc(u_bi)\n",
    "        return s\n",
    "\n",
    "class PyHealthBiteNet(BaseModel):\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: SampleDataset,\n",
    "            feature_keys: List[str],\n",
    "            label_key: str,\n",
    "            mode: str,\n",
    "            embedding_dim: int = 128,\n",
    "            n_mask_enc_layers: int = 2,\n",
    "            use_intervals: bool = True,\n",
    "            use_procedures: bool = True,\n",
    "            num_heads: int = 4,\n",
    "            dropout: float = 0.1,\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(dataset, feature_keys, label_key, mode)\n",
    "\n",
    "        self.use_intervals = use_intervals\n",
    "        self.use_procedures = use_procedures\n",
    "\n",
    "        # Any BaseModel should have these attributes, as functions like add_feature_transform_layer uses them\n",
    "        self.feat_tokenizers = {}\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        self.linear_layers = nn.ModuleDict()\n",
    "        self.label_tokenizer = self.get_label_tokenizer()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # self.add_feature_transform_layer will create a transformation layer for each feature\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "            self.add_feature_transform_layer(\n",
    "                feature_key, input_info, special_tokens=[\"<pad>\", \"<unk>\"]\n",
    "            )\n",
    "\n",
    "        # final output layer\n",
    "        output_size = self.get_output_size(self.label_tokenizer)\n",
    "        self.bite_net = BiteNet(\n",
    "            embedding_dim = embedding_dim,\n",
    "            num_heads = num_heads,\n",
    "            dropout = dropout,\n",
    "            use_intervals=use_intervals,\n",
    "            use_procedures=use_procedures,\n",
    "            n_mask_enc_layers=n_mask_enc_layers,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(self.embedding_dim, output_size)\n",
    "\n",
    "    def forward(self, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        embeddings = {}\n",
    "        masks = {}\n",
    "        for feature_key in self.feature_keys:\n",
    "            input_info = self.dataset.input_info[feature_key]\n",
    "\n",
    "            # each patient's feature is represented by [[code1, code2],[code3]]\n",
    "            assert input_info[\"dim\"] == 3 and input_info[\"type\"] == str\n",
    "            feature_vals = kwargs[feature_key]\n",
    "\n",
    "            x = self.feat_tokenizers[feature_key].batch_encode_3d(feature_vals, truncation=(False, False))\n",
    "            x = torch.tensor(x, dtype=torch.long, device=self.device)\n",
    "            pad_idx = self.feat_tokenizers[feature_key].vocabulary(\"<pad>\")\n",
    "            #create the mask\n",
    "            mask = (x != pad_idx).long()\n",
    "            embeds = self.embeddings[feature_key](x)\n",
    "            embeddings[feature_key] = embeds\n",
    "            masks[feature_key] = mask\n",
    "\n",
    "        embedded_codes = embeddings['diagnoses']\n",
    "        codes_mask = masks['diagnoses']\n",
    "        if self.use_procedures:\n",
    "            embedded_codes = torch.cat((embedded_codes, embeddings['procedures']), dim=2)\n",
    "            codes_mask = torch.cat((codes_mask, masks['procedures']), dim=2)\n",
    "\n",
    "        output = self.bite_net(embedded_codes, embeddings['intervals'].squeeze(2), codes_mask, masks['intervals'].squeeze(-1))\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        # obtain y_true, loss, y_prob\n",
    "        y_true = self.prepare_labels(kwargs[self.label_key], self.label_tokenizer)\n",
    "        loss = self.get_loss_function()(logits, y_true)\n",
    "        y_prob = self.prepare_y_prob(logits)\n",
    "\n",
    "        return {\"loss\": loss, \"y_prob\": y_prob, \"y_true\": y_true}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model, lr=0.001):\n",
    "    trainer = Trainer(model=model, device=device)\n",
    "    trainer.train(\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        epochs=10,\n",
    "        monitor=\"pr_auc\",\n",
    "        optimizer_class=torch.optim.RMSprop,\n",
    "        optimizer_params = {\"lr\" : lr},\n",
    "        load_best_model_at_last=False\n",
    "    )\n",
    "\n",
    "    # Run inference and evaluate\n",
    "    # option 1: use our built-in evaluation metric\n",
    "    score = trainer.evaluate(test_loader)\n",
    "    print (score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:37:14.243723Z",
     "end_time": "2023-04-29T19:37:14.254724Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:43:47.301218Z",
     "end_time": "2023-04-29T19:44:57.655792Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyHealthBiteNet(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3437, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1925, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (bite_net): BiteNet(\n",
      "    (flatten): Flatten()\n",
      "    (unflatten): Unflatten()\n",
      "    (code_attn): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_fw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (visit_attn_bw): Sequential(\n",
      "      (0): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (1): MaskEnc(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (q_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (k_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (v_linear): Linear(in_features=128, out_features=128, bias=False)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Dropout(p=0.1, inplace=False)\n",
      "          (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (layer_norm1): MaskedLayerNorm()\n",
      "        (layer_norm2): MaskedLayerNorm()\n",
      "      )\n",
      "      (2): AttentionPooling(\n",
      "        (fc): Sequential(\n",
      "          (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A29145190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11766e9adb594d36b48df8b036597d4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5189\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 68.97it/s]\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2834\n",
      "roc_auc: 0.5309\n",
      "f1: 0.0921\n",
      "loss: 0.4891\n",
      "New best pr_auc score (0.2834) at epoch-0, step-188\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "214f55b8902e4d208b4dab99e3dfad39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4952\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 68.77it/s]\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.2772\n",
      "roc_auc: 0.5401\n",
      "f1: 0.1266\n",
      "loss: 0.4826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f8e9fb6812148758e081a6c1ecfa87a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.4875\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 69.37it/s]\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.2767\n",
      "roc_auc: 0.5282\n",
      "f1: 0.1266\n",
      "loss: 0.4826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce320e54bede4038b8f57f6238f24cb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.4789\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 70.80it/s]\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3106\n",
      "roc_auc: 0.5580\n",
      "f1: 0.1290\n",
      "loss: 0.4727\n",
      "New best pr_auc score (0.3106) at epoch-3, step-752\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd12be0e913e42d7bf69b9792d6412ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.4788\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 70.80it/s]\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.3052\n",
      "roc_auc: 0.5810\n",
      "f1: 0.1290\n",
      "loss: 0.4872\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3407534244fd4f9ba4d59532cc3c5a17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.4770\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 71.01it/s]\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.2677\n",
      "roc_auc: 0.4987\n",
      "f1: 0.1942\n",
      "loss: 0.5934\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ef01c36469745f69fab22c11161cbcb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.4774\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 70.59it/s]\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.3025\n",
      "roc_auc: 0.5512\n",
      "f1: 0.1282\n",
      "loss: 0.4837\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ac557337ce441cc9343c4e82a198968"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.4789\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 71.01it/s]\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.2706\n",
      "roc_auc: 0.4876\n",
      "f1: 0.1290\n",
      "loss: 0.4762\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef3838d910a440e08f2137832ae7846f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.4720\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 70.56it/s]\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.3131\n",
      "roc_auc: 0.5579\n",
      "f1: 0.1290\n",
      "loss: 0.4735\n",
      "New best pr_auc score (0.3131) at epoch-8, step-1692\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c418b52292f4d61acaa8683ae6e8a70"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.4713\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 70.59it/s]\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.3095\n",
      "roc_auc: 0.5769\n",
      "f1: 0.1282\n",
      "loss: 0.4719\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 72.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.3778531516576786, 'roc_auc': 0.6012818593910366, 'f1': 0.20338983050847456, 'loss': 0.49731560548146564}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    PyHealthBiteNet(\n",
    "        dataset = mimic3_dxtx,\n",
    "        feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "        label_key = \"label\",\n",
    "        mode = \"binary\",\n",
    "        use_procedures=False,\n",
    "        use_intervals=True\n",
    "    ).to(device),\n",
    "    lr=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3437, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1925, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (rnn): ModuleDict(\n",
      "    (diagnoses): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "    (intervals): RNNLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (rnn): GRU(128, 128, batch_first=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A29145190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c40763f9eb364770bbd0dd880435a518"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.4988\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 190.48it/s]\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3068\n",
      "roc_auc: 0.5625\n",
      "f1: 0.1161\n",
      "loss: 0.4817\n",
      "New best pr_auc score (0.3068) at epoch-0, step-188\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "999fd6bc9bf44b37ae0e51015838199a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4296\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 146.76it/s]\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.3208\n",
      "roc_auc: 0.5718\n",
      "f1: 0.1429\n",
      "loss: 0.4931\n",
      "New best pr_auc score (0.3208) at epoch-1, step-376\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5b76a359860424cbee6988f86f438dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.3555\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 165.40it/s]\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3110\n",
      "roc_auc: 0.5586\n",
      "f1: 0.1967\n",
      "loss: 0.5252\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8636ad578cff4de58a3be4529de22ed1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.2766\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 144.58it/s]\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.2811\n",
      "roc_auc: 0.5179\n",
      "f1: 0.1935\n",
      "loss: 0.5947\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8516f866b5b049678929b61a18111399"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.2086\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 177.78it/s]\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.2648\n",
      "roc_auc: 0.5005\n",
      "f1: 0.1828\n",
      "loss: 0.6979\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ffb3f54fcc943b09ff279605094da60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.1586\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 142.01it/s]\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.2736\n",
      "roc_auc: 0.5133\n",
      "f1: 0.1700\n",
      "loss: 0.7096\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f2dd7235a6c485392c2e84290f071a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.1116\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 167.16it/s]\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.2735\n",
      "roc_auc: 0.5175\n",
      "f1: 0.2000\n",
      "loss: 0.7981\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5f018ea2c3b484f9f44fd1db29ab166"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0913\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 137.93it/s]\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.2582\n",
      "roc_auc: 0.5032\n",
      "f1: 0.1509\n",
      "loss: 0.8403\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "045f5573eace49dbafccd0ade13bbb65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0651\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 179.11it/s]\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.2634\n",
      "roc_auc: 0.5131\n",
      "f1: 0.2072\n",
      "loss: 0.9225\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f408482e4fd44fa8ddfb6583b439913"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0524\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 162.16it/s]\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.2671\n",
      "roc_auc: 0.5179\n",
      "f1: 0.2083\n",
      "loss: 0.9673\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 170.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.3683714989631231, 'roc_auc': 0.5946373588778652, 'f1': 0.32388663967611336, 'loss': 0.8670114278793335}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    RNN(\n",
    "        dataset = mimic3_dxtx,\n",
    "        feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "        label_key = \"label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:41:12.738226Z",
     "end_time": "2023-04-29T19:41:35.449846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RETAIN(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3437, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1925, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (retain): ModuleDict(\n",
      "    (diagnoses): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (intervals): RETAINLayer(\n",
      "      (dropout_layer): Dropout(p=0.1, inplace=False)\n",
      "      (alpha_gru): GRU(128, 128, batch_first=True)\n",
      "      (beta_gru): GRU(128, 128, batch_first=True)\n",
      "      (alpha_li): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (beta_li): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A29145190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee335a17e0174e2d9c9aab41de446fae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5295\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 91.95it/s]\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.2481\n",
      "roc_auc: 0.5266\n",
      "f1: 0.0764\n",
      "loss: 0.5041\n",
      "New best pr_auc score (0.2481) at epoch-0, step-188\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e4fb291a02c46c4a3d91c0524a7997a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.4015\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 91.92it/s]\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.2421\n",
      "roc_auc: 0.5039\n",
      "f1: 0.0899\n",
      "loss: 0.5428\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e5dcda04de749519401bb8f45ede04d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2672\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 89.22it/s]\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.2460\n",
      "roc_auc: 0.5046\n",
      "f1: 0.1398\n",
      "loss: 0.6413\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98dd727273f643258144b3d62d9d832b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1595\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 91.95it/s]\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.2417\n",
      "roc_auc: 0.5074\n",
      "f1: 0.1463\n",
      "loss: 0.7576\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73963807ed224a92b8c958eba5855ec3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.1014\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 86.96it/s]\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.2506\n",
      "roc_auc: 0.5173\n",
      "f1: 0.1964\n",
      "loss: 0.8584\n",
      "New best pr_auc score (0.2506) at epoch-4, step-940\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d80dfe8c1724bc9b08932b350ddaa78"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0644\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 84.21it/s]\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.2439\n",
      "roc_auc: 0.5198\n",
      "f1: 0.1825\n",
      "loss: 0.9678\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9680838e156945cea650942c95eef25e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0493\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 88.24it/s]\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.2589\n",
      "roc_auc: 0.5325\n",
      "f1: 0.2000\n",
      "loss: 1.0366\n",
      "New best pr_auc score (0.2589) at epoch-6, step-1316\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f546847b91d42418966ba76254b70df"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0371\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 81.63it/s]\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.2555\n",
      "roc_auc: 0.5274\n",
      "f1: 0.1622\n",
      "loss: 1.1201\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93ce3068aec440faa1c4a10519e0f5e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0271\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 89.22it/s]\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.2671\n",
      "roc_auc: 0.5279\n",
      "f1: 0.2000\n",
      "loss: 1.2043\n",
      "New best pr_auc score (0.2671) at epoch-8, step-1692\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9b9574b69ce4b3eb4aac562bdf48c1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0302\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 87.91it/s]\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.2713\n",
      "roc_auc: 0.5314\n",
      "f1: 0.1875\n",
      "loss: 1.2548\n",
      "New best pr_auc score (0.2713) at epoch-9, step-1880\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 81.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.4041025190058409, 'roc_auc': 0.6019714334587754, 'f1': 0.3148936170212766, 'loss': 1.1822359549502532}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    RETAIN(\n",
    "        dataset = mimic3_dxtx,\n",
    "        feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "        label_key = \"label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:41:43.702165Z",
     "end_time": "2023-04-29T19:42:47.408963Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deepr(\n",
      "  (embeddings): ModuleDict(\n",
      "    (diagnoses): Embedding(3438, 128, padding_idx=0)\n",
      "    (intervals): Embedding(1926, 128, padding_idx=0)\n",
      "  )\n",
      "  (linear_layers): ModuleDict()\n",
      "  (cnn): ModuleDict(\n",
      "    (diagnoses): DeeprLayer(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "    )\n",
      "    (intervals): DeeprLayer(\n",
      "      (conv): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Metrics: None\n",
      "Device: cuda\n",
      "\n",
      "Training:\n",
      "Batch size: 32\n",
      "Optimizer: <class 'torch.optim.rmsprop.RMSprop'>\n",
      "Optimizer params: {'lr': 0.001}\n",
      "Weight decay: 0.0\n",
      "Max grad norm: None\n",
      "Val dataloader: <torch.utils.data.dataloader.DataLoader object at 0x0000014A29145190>\n",
      "Monitor: pr_auc\n",
      "Monitor criterion: max\n",
      "Epochs: 10\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 0 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "292a2889549f48ebb2320afd0b046f35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-0, step-188 ---\n",
      "loss: 0.5008\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 190.80it/s]\n",
      "--- Eval epoch-0, step-188 ---\n",
      "pr_auc: 0.3224\n",
      "roc_auc: 0.5854\n",
      "f1: 0.1154\n",
      "loss: 0.4771\n",
      "New best pr_auc score (0.3224) at epoch-0, step-188\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 1 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20d85634dc5f4fffb519f0c7f47a1aff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-1, step-376 ---\n",
      "loss: 0.3939\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 289.17it/s]\n",
      "--- Eval epoch-1, step-376 ---\n",
      "pr_auc: 0.2954\n",
      "roc_auc: 0.5693\n",
      "f1: 0.1258\n",
      "loss: 0.5470\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 2 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd5b112010c14d75b2e2589b50f76713"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-2, step-564 ---\n",
      "loss: 0.2847\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 289.16it/s]\n",
      "--- Eval epoch-2, step-564 ---\n",
      "pr_auc: 0.3094\n",
      "roc_auc: 0.5673\n",
      "f1: 0.2000\n",
      "loss: 0.5277\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 3 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e6fcafb7cea4404bd419758c51bf74b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-3, step-752 ---\n",
      "loss: 0.1705\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 292.69it/s]\n",
      "--- Eval epoch-3, step-752 ---\n",
      "pr_auc: 0.3022\n",
      "roc_auc: 0.5762\n",
      "f1: 0.1628\n",
      "loss: 0.6022\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 4 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d098805e6374c988268215642687e80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-4, step-940 ---\n",
      "loss: 0.0915\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 269.68it/s]\n",
      "--- Eval epoch-4, step-940 ---\n",
      "pr_auc: 0.2901\n",
      "roc_auc: 0.5571\n",
      "f1: 0.1477\n",
      "loss: 0.6947\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 5 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfa643ac04324359872353f3b5ede916"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-5, step-1128 ---\n",
      "loss: 0.0454\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 260.87it/s]\n",
      "--- Eval epoch-5, step-1128 ---\n",
      "pr_auc: 0.2928\n",
      "roc_auc: 0.5533\n",
      "f1: 0.2222\n",
      "loss: 0.7252\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 6 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8995f5a5da304286b4aef470dcee51d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-6, step-1316 ---\n",
      "loss: 0.0231\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 279.07it/s]\n",
      "--- Eval epoch-6, step-1316 ---\n",
      "pr_auc: 0.2967\n",
      "roc_auc: 0.5602\n",
      "f1: 0.2647\n",
      "loss: 0.7818\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 7 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59d4e32cbbf5458ca29c33042ebd31f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-7, step-1504 ---\n",
      "loss: 0.0129\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 266.67it/s]\n",
      "--- Eval epoch-7, step-1504 ---\n",
      "pr_auc: 0.2871\n",
      "roc_auc: 0.5553\n",
      "f1: 0.1846\n",
      "loss: 0.9428\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 8 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa6e38ea1f7b4c4bba2b1c86a735fc2e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-8, step-1692 ---\n",
      "loss: 0.0103\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 255.33it/s]\n",
      "--- Eval epoch-8, step-1692 ---\n",
      "pr_auc: 0.2928\n",
      "roc_auc: 0.5669\n",
      "f1: 0.1944\n",
      "loss: 0.9705\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "Epoch 9 / 10:   0%|          | 0/188 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3662ac2c1c3e4328a9121cf8bea2fb05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Train epoch-9, step-1880 ---\n",
      "loss: 0.0040\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 252.62it/s]\n",
      "--- Eval epoch-9, step-1880 ---\n",
      "pr_auc: 0.2920\n",
      "roc_auc: 0.5607\n",
      "f1: 0.1466\n",
      "loss: 1.1256\n",
      "Evaluation: 100%|██████████| 24/24 [00:00<00:00, 258.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pr_auc': 0.38703224930622393, 'roc_auc': 0.6251496749914471, 'f1': 0.26540284360189575, 'loss': 1.0660237806538742}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(\n",
    "    Deepr(\n",
    "        dataset = mimic3_dxtx,\n",
    "        feature_keys = [\"diagnoses\", \"intervals\"],\n",
    "        label_key = \"label\",\n",
    "        mode = \"binary\",\n",
    "        embedding_dim=128\n",
    "    ).to(device)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T19:43:16.256772Z",
     "end_time": "2023-04-29T19:43:31.501358Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
